{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "i3zTtXci_H_T",
   "metadata": {
    "id": "i3zTtXci_H_T"
   },
   "source": [
    "# FACTR_03 ‚Äî ASR + (optional) Diarize/Align ‚Äî **CPU-safe**\n",
    "\n",
    "**Version:** 2.0 (2025-09-07)\n",
    "\n",
    "This notebook is designed to run reliably on free Colab (CPU only). It avoids CUDA/cuDNN crashes and still produces `UTTERANCES.parquet` for Notebook 04.\n",
    "\n",
    "Pipeline:\n",
    "1. Safe Mode ‚Üí force CPU + cap threads\n",
    "2. Install minimal, stable CPU dependencies (faster-whisper)\n",
    "3. Load `AUDIO_PATH` from `FACTR_02` handoff JSON\n",
    "4. Transcribe on CPU (faster-whisper)\n",
    "5. *(Optional)* Align & Diarize via WhisperX (graceful fallback)\n",
    "6. Save `data/processed/UTTERANCES.parquet` to Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "riiiK9fC_N9Q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C9wyPx-w_H_U",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe mode set: CPU only, threads capped.\n"
     ]
    }
   ],
   "source": [
    "# --- SAFEMODE: force CPU, tame native threads (prevents crashes) ---\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # force CPU\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "print(\"‚úÖ Safe mode set: CPU only, threads capped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x_p4sP7c_H_V",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.8/1.8 MB 12.0 MB/s eta 0:00:00\n",
      "Python 3.12.11 | Platform Linux-6.1.123+-x86_64-with-glibc2.35\n",
      "onnxruntime 1.19.2\n",
      "faster_whisper 1.1.1\n",
      "ctranslate2 4.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "# Keep pip modern (below the 25.3 breaking change)\n",
    "pip install -q --upgrade \"pip<25.3\" wheel\n",
    "\n",
    "# CPU-only trio for faster-whisper\n",
    "pip install -q \"ctranslate2==4.4.0\" \"onnxruntime==1.19.2\" \"faster-whisper==1.1.1\"\n",
    "\n",
    "# Optional utilities used later\n",
    "pip install -q pandas pyarrow \"matplotlib<3.9\" \"scikit-learn<1.6\" yt-dlp\n",
    "\n",
    "python - <<'PY'\n",
    "import platform, sys\n",
    "print(\"Python\", sys.version.split()[0], \"| Platform\", platform.platform())\n",
    "import onnxruntime, faster_whisper, ctranslate2\n",
    "print(\"onnxruntime\", onnxruntime.__version__)\n",
    "print(\"faster_whisper\", faster_whisper.__version__)\n",
    "print(\"ctranslate2\", ctranslate2.__version__)\n",
    "PY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p6yLWH3E_H_V",
   "metadata": {
    "id": "p6yLWH3E_H_V"
   },
   "source": [
    "## Load AUDIO_PATH from FACTR_02 handoff\n",
    "FACTR_02 writes `data/processed/LAST_INGEST.json` with `audio_path`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JpFNBaKW_H_V",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO_PATH: /content/drive/MyDrive/FATCR/data/processed/speFWRuuJNs_16k_mono.wav\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "HANDOFF = \"/content/drive/MyDrive/FATCR/data/processed/LAST_INGEST.json\"\n",
    "assert os.path.exists(HANDOFF), \"LAST_INGEST.json not found. Run FACTR_02 first.\"\n",
    "with open(HANDOFF, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "AUDIO_PATH = meta[\"audio_path\"]\n",
    "print(\"AUDIO_PATH:\", AUDIO_PATH)\n",
    "assert os.path.exists(AUDIO_PATH) and os.path.getsize(AUDIO_PATH) > 10_000, \"Bad AUDIO_PATH.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AcQn_P7A_H_V",
   "metadata": {
    "id": "AcQn_P7A_H_V"
   },
   "source": [
    "## CPU transcription with faster-whisper\n",
    "Small English model is fast on CPU. Adjust `model_size` if you want higher quality (e.g., `medium.en`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "axvMjAVf_H_W",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb934884d95499b93ea139a4fc1b20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a66a223e734b28ab5c7ce2d0cacb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f444c80e16de46928d6e40fac84f6c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/484M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d986631e00f2480ba91a470ee7b69783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "‚úÖ ASR segments: 1242\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size   = \"small.en\"     # or \"medium.en\" if you can afford time\n",
    "compute_type = \"int8\"         # best for CPU; \"int8_float16\" also OK\n",
    "device       = \"cpu\"          # keep CPU to avoid cuDNN\n",
    "\n",
    "fw = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
    "segments_gen, info = fw.transcribe(\n",
    "    AUDIO_PATH,\n",
    "    language=\"en\",           # skip detection\n",
    "    vad_filter=False,\n",
    "    beam_size=1,\n",
    ")\n",
    "print(\"Detected language:\", info.language)\n",
    "\n",
    "# Convert to WhisperX-like dict\n",
    "asr_segments = []\n",
    "for s in segments_gen:\n",
    "    seg = {\n",
    "        \"start\": float(s.start) if s.start is not None else None,\n",
    "        \"end\":   float(s.end)   if s.end   is not None else None,\n",
    "        \"text\":  (s.text or \"\").strip(),\n",
    "    }\n",
    "    if getattr(s, \"words\", None):\n",
    "        seg[\"words\"] = [\n",
    "            {\"start\": float(w.start) if w.start is not None else None,\n",
    "             \"end\":   float(w.end)   if w.end   is not None else None,\n",
    "             \"word\":  w.word}\n",
    "            for w in s.words\n",
    "        ]\n",
    "    asr_segments.append(seg)\n",
    "asr = {\"segments\": asr_segments, \"language\": info.language or \"en\"}\n",
    "print(f\"‚úÖ ASR segments: {len(asr_segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fpa03v9e_H_W",
   "metadata": {
    "id": "Fpa03v9e_H_W"
   },
   "source": [
    "## (Optional) Alignment & Diarization with WhisperX (graceful fallback)\n",
    "- Stays on CPU. If imports or models fail, we fall back to plain ASR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-IhEn-r_H_W",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Alignment skipped: No module named 'whisperx'\n"
     ]
    }
   ],
   "source": [
    "USE_ALIGNMENT = True\n",
    "USE_DIAR      = False         # diarization is heavier; enable if needed\n",
    "HUGGINGFACE_TOKEN = \"\"       # paste your HF token if you enable diarization\n",
    "\n",
    "asr_aligned = asr\n",
    "diar_out = None\n",
    "\n",
    "if USE_ALIGNMENT:\n",
    "    try:\n",
    "        import whisperx\n",
    "        align_model, metadata = whisperx.load_align_model(\n",
    "            language_code=asr[\"language\"], device=\"cpu\"\n",
    "        )\n",
    "        asr_aligned = whisperx.align(asr[\"segments\"], align_model, metadata, AUDIO_PATH, \"cpu\")\n",
    "        print(\"‚úÖ Alignment ok.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Alignment skipped:\", e)\n",
    "        asr_aligned = asr\n",
    "\n",
    "if USE_DIAR:\n",
    "    try:\n",
    "        import whisperx\n",
    "        diar = whisperx.DiarizationPipeline(device=\"cpu\", use_auth_token=(HUGGINGFACE_TOKEN or None))\n",
    "        diar_out = diar(AUDIO_PATH)\n",
    "        print(\"‚úÖ Diarization ok.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Diarization skipped:\", e)\n",
    "        diar_out = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kgUJjHZy_H_W",
   "metadata": {
    "id": "kgUJjHZy_H_W"
   },
   "source": [
    "## Save UTTERANCES.parquet for FACTR_04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wPV2jdOl_H_W",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ wrote /content/drive/MyDrive/FATCR/data/processed/UTTERANCES.parquet rows: 1242\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "rows = []\n",
    "segments = asr_aligned.get(\"segments\", asr[\"segments\"])\n",
    "for seg in segments:\n",
    "    rows.append({\n",
    "        \"video_id\": os.path.basename(AUDIO_PATH),\n",
    "        \"t_start\": seg.get(\"start\"),\n",
    "        \"t_end\":   seg.get(\"end\"),\n",
    "        \"speaker\": seg.get(\"speaker\", \"SPEAKER_00\"),\n",
    "        \"text\":    (seg.get(\"text\") or \"\").strip(),\n",
    "    })\n",
    "df_utts = pd.DataFrame(rows)\n",
    "out_parquet = \"/content/drive/MyDrive/FATCR/data/processed/UTTERANCES.parquet\"\n",
    "os.makedirs(os.path.dirname(out_parquet), exist_ok=True)\n",
    "df_utts.to_parquet(out_parquet, index=False)\n",
    "print(\"‚úÖ wrote\", out_parquet, \"rows:\", len(df_utts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dBkoxxe_H_W",
   "metadata": {
    "id": "8dBkoxxe_H_W"
   },
   "source": [
    "---\n",
    "**Notes**\n",
    "- Keep running on CPU for stability. Once pipeline is proven, you can experiment with GPU on Pro by removing the CPU force and installing CUDA-matching torch/torchaudio before whisperx.\n",
    "- If you only need transcripts, set `USE_ALIGNMENT=False` and `USE_DIAR=False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05T7fyWFTicd",
   "metadata": {
    "id": "05T7fyWFTicd"
   },
   "source": [
    "## Snapshot + pointer JSON (for FACTR_03 handoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-h11uFKPTlWP",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FACTR_03 snapshot\n",
      "   Rows: 1242\n",
      "   Total speech duration (approx): 1762.2 sec\n",
      "   Max end time: 1786.16 sec\n",
      "üìù Snapshot saved -> snapshots/FACTR03_SNAPSHOT_1757837986.json\n",
      "üîó Pointer JSON saved -> data/processed/LAST_ASR.json\n"
     ]
    }
   ],
   "source": [
    "# === FACTR_03 Snapshot (rows, duration, versions) ===\n",
    "import os, json, time, platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = \"/content/drive/MyDrive/FATCR\"\n",
    "UTT  = f\"{ROOT}/data/processed/UTTERANCES.parquet\"\n",
    "SNAP_DIR = f\"{ROOT}/snapshots\"\n",
    "PTR_PATH  = f\"{ROOT}/data/processed/LAST_ASR.json\"\n",
    "\n",
    "assert os.path.exists(UTT), f\"Missing {UTT}. Run FACTR_03 transcription first.\"\n",
    "\n",
    "# Load file\n",
    "df = pd.read_parquet(UTT)\n",
    "rows = len(df)\n",
    "\n",
    "# Calculate durations\n",
    "t_start = pd.to_numeric(df.get(\"t_start\", pd.Series(dtype=float)), errors=\"coerce\")\n",
    "t_end   = pd.to_numeric(df.get(\"t_end\"  , pd.Series(dtype=float)), errors=\"coerce\")\n",
    "seg_dur = (t_end - t_start).clip(lower=0)\n",
    "total_duration_sec = float(np.nan_to_num(seg_dur.sum(), nan=0.0))\n",
    "max_time_sec       = float(np.nan_to_num(t_end.max(), nan=0.0))\n",
    "\n",
    "print(\"‚úÖ FACTR_03 snapshot\")\n",
    "print(\"   Rows:\", rows)\n",
    "print(\"   Total speech duration (approx):\", round(total_duration_sec, 2), \"sec\")\n",
    "print(\"   Max end time:\", round(max_time_sec, 2), \"sec\")\n",
    "\n",
    "# Environment/versions\n",
    "snap = {\n",
    "    \"ts\"     : time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"python\" : platform.python_version(),\n",
    "    \"pandas\" : pd.__version__,\n",
    "    \"numpy\"  : np.__version__,\n",
    "    \"rows\"   : int(rows),\n",
    "    \"dur_s\"  : round(total_duration_sec, 3),\n",
    "    \"max_t\"  : round(max_time_sec, 3),\n",
    "}\n",
    "\n",
    "# Save snapshot (auditable trail)\n",
    "os.makedirs(SNAP_DIR, exist_ok=True)\n",
    "snap_path = f\"{SNAP_DIR}/FACTR03_SNAPSHOT_{int(time.time())}.json\"\n",
    "with open(snap_path, \"w\") as f:\n",
    "    json.dump(snap, f, indent=2)\n",
    "print(\"üìù Snapshot saved ->\", os.path.relpath(snap_path, ROOT))\n",
    "\n",
    "# Save pointer JSON (safe to push)\n",
    "os.makedirs(os.path.dirname(PTR_PATH), exist_ok=True)\n",
    "with open(PTR_PATH, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"ts\"    : snap[\"ts\"],\n",
    "        \"rows\"  : rows,\n",
    "        \"dur_s\" : snap[\"dur_s\"],\n",
    "        \"path\"  : os.path.relpath(UTT, ROOT),\n",
    "    }, f, indent=2)\n",
    "print(\"üîó Pointer JSON saved ->\", os.path.relpath(PTR_PATH, ROOT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9NHboQntTpoF",
   "metadata": {
    "id": "9NHboQntTpoF"
   },
   "source": [
    "## Git push helper (for FACTR_03 outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjOU9YnkTtTB",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Repo status:\n",
      "Refresh index: 100% (6/6), done.\n",
      "## \u001b[32mmain\u001b[m...\u001b[31morigin/main\u001b[m [ahead \u001b[32m1\u001b[m]\n",
      " \u001b[31mM\u001b[m notebooks/FACTR_03_ASR+Diarize_v2025-09-07_1.0.ipynb\n",
      "\u001b[31m??\u001b[m data/\n",
      "\n",
      "üîÑ Pulling latest (rebase)‚Ä¶\n",
      "error: cannot pull with rebase: You have unstaged changes.\n",
      "error: please commit or stash them.\n",
      "\n",
      "‚ûï Staging relevant files‚Ä¶\n",
      "\n",
      "‚úèÔ∏è Commit: FACTR_03: add snapshot + pointer\n",
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@b7374f05d615.(none)')\n",
      "\n",
      "‚¨ÜÔ∏è Pushing to main‚Ä¶\n",
      "Everything up-to-date\n",
      "\n",
      "‚úÖ Push complete.\n"
     ]
    }
   ],
   "source": [
    "# === FACTR push (commit notebook + pointer JSON + snapshots) ===\n",
    "from google.colab import userdata\n",
    "import urllib.parse, os, subprocess, shlex\n",
    "\n",
    "ROOT = \"/content/drive/MyDrive/FATCR\"\n",
    "os.chdir(ROOT)\n",
    "\n",
    "print(\"üìÇ Repo status:\")\n",
    "!git status -sb\n",
    "\n",
    "# Pull to avoid divergence\n",
    "print(\"\\nüîÑ Pulling latest (rebase)‚Ä¶\")\n",
    "pat = userdata.get(\"GITHUB_PAT\")\n",
    "assert pat, \"Missing GITHUB_PAT in Colab Secrets.\"\n",
    "enc_pat = urllib.parse.quote(pat, safe=\"\")\n",
    "PULL_URL = f\"https://LukmaanViscomi:{enc_pat}@github.com/LukmaanViscomi/FATCR.git\"\n",
    "!git pull --rebase {PULL_URL} main || true\n",
    "\n",
    "# Stage notebooks + snapshots + pointer JSON\n",
    "print(\"\\n‚ûï Staging relevant files‚Ä¶\")\n",
    "!git add notebooks snapshots data/processed/LAST_ASR.json README.md .gitignore 2>/dev/null || true\n",
    "\n",
    "# Commit if changes exist\n",
    "changed = subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"]).returncode != 0\n",
    "if changed:\n",
    "    msg = \"FACTR_03: add snapshot + pointer\"\n",
    "    print(\"\\n‚úèÔ∏è Commit:\", msg)\n",
    "    !git commit -m {shlex.quote(msg)}\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è Nothing new to commit.\")\n",
    "\n",
    "# Push using PAT\n",
    "print(\"\\n‚¨ÜÔ∏è Pushing to main‚Ä¶\")\n",
    "!git push {PULL_URL} HEAD:main\n",
    "\n",
    "print(\"\\n‚úÖ Push complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
