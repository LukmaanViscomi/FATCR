{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1lmftW2Knc_"
   },
   "source": [
    "# FACTR_02_KB_Ingest_lang.ipynb (updated)\n",
    "\n",
    "This notebook builds the unified FACTR knowledge base (KB) from normalised sources:\n",
    "\n",
    "1. Load `MANIFEST.json` produced by `FACTR_01_Primary_Source_Import_Helper.ipynb`.\n",
    "2. Merge all `_normalized/*.jsonl` files into `KB_passages.jsonl`.\n",
    "3. Encode passages into `KB_embeddings.npy` + `KB_embeddings.meta.json`.\n",
    "4. Build FAISS indexes for:\n",
    "   - `KB_all.faiss` (all sources),\n",
    "   - `KB_islam.faiss` (Islam-only),\n",
    "   - `KB_christian.faiss` (Christianity-only).\n",
    "5. Provide a `kb_search()` helper for interactive testing.\n",
    ":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNSBxWRu2JQ1"
   },
   "source": [
    "Confirm itâ€™s actually using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djd57ofEKrh7"
   },
   "source": [
    "## ðŸ”¹ Code cell 1 â€“ Config & load MANIFEST.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using manifest: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/MANIFEST.json\n",
      "Sources: 8\n",
      " - quran_en lang= en genre= scripture\n",
      " - quran_ar lang= ar genre= scripture\n",
      " - bible_web_en lang= en genre= scripture\n",
      " - hadith_9books_en lang= en genre= hadith\n",
      " - tafsir_ibn_kathir_en lang= en genre= tafsir\n",
      " - tafsir_al_qurtubi_ar lang= ar genre= tafsir\n",
      " - christian_commentaries_patristic lang= en genre= commentary\n",
      " - christian_creeds lang= en genre= creed\n"
     ]
    }
   ],
   "source": [
    "# Step 1 â€” Configuration and MANIFEST loading\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directories (adjust ROOT if your Drive path is different)\n",
    "ROOT = \"/content/drive/MyDrive/FATCR\"\n",
    "DATA_DIR = f\"{ROOT}/data/processed\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "RAW_ROOT = Path(ROOT) / \"data/raw/kb\"\n",
    "NORM_DIR = RAW_ROOT / \"_normalized\"\n",
    "\n",
    "KB_PASS = Path(DATA_DIR) / \"KB_passages.jsonl\"\n",
    "KB_EMB  = Path(DATA_DIR) / \"KB_embeddings.npy\"\n",
    "KB_META = Path(DATA_DIR) / \"KB_embeddings.meta.json\"\n",
    "\n",
    "manifest_path = NORM_DIR / \"MANIFEST.json\"\n",
    "manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Using manifest:\", manifest_path)\n",
    "print(\"Sources:\", len(manifest))\n",
    "for m in manifest:\n",
    "    print(\" -\", m[\"name\"], \"lang=\", m.get(\"lang\"), \"genre=\", m.get(\"genre\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owATx5jUKwTx"
   },
   "source": [
    "## ðŸ”¹ Code cell 2 â€“ Merge all normalised files â†’ KB_passages.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KB] Ingesting quran_en from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/quran_en.jsonl\n",
      "[KB] Ingesting quran_ar from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/quran_ar.jsonl\n",
      "[KB] Ingesting bible_web_en from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/bible_web_en.jsonl\n",
      "[KB] Ingesting hadith_9books_en from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/hadith_9books_en.jsonl\n",
      "[KB] Ingesting tafsir_ibn_kathir_en from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/tafsir_ibn_kathir_en.jsonl\n",
      "[KB] Ingesting tafsir_al_qurtubi_ar from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/tafsir_al_qurtubi_ar.jsonl\n",
      "[KB] Ingesting christian_commentaries_patristic from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\n",
      "[KB] Ingesting christian_creeds from /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/christian_creeds.jsonl\n",
      "[KB] Wrote 162712 passages to /content/drive/MyDrive/FATCR/data/processed/KB_passages.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Step 2 â€” Merge all normalised files into KB_passages.jsonl\n",
    "\n",
    "ROOT_PATH = Path(ROOT)\n",
    "\n",
    "def build_kb_passages(manifest, out_path: Path):\n",
    "    total = 0\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
    "        for entry in manifest:\n",
    "            src_path = ROOT_PATH / entry[\"path\"]\n",
    "            print(f\"[KB] Ingesting {entry['name']} from {src_path}\")\n",
    "            with src_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    rec = json.loads(line)\n",
    "                    # Attach high-level metadata if missing\n",
    "                    rec.setdefault(\"tradition\", entry.get(\"tradition\"))\n",
    "                    rec.setdefault(\"genre\", entry.get(\"genre\"))\n",
    "                    rec.setdefault(\"lang\", entry.get(\"lang\"))\n",
    "                    rec.setdefault(\"source_name\", entry[\"name\"])\n",
    "                    rec.setdefault(\"source_collection\", entry.get(\"collection\"))\n",
    "                    rec.setdefault(\"source_file\", entry[\"path\"])\n",
    "                    json.dump(rec, out_f, ensure_ascii=False)\n",
    "                    out_f.write(\"\\n\")\n",
    "                    total += 1\n",
    "    print(f\"[KB] Wrote {total} passages to {out_path}\")\n",
    "    return total\n",
    "\n",
    "_ = build_kb_passages(manifest, KB_PASS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfeNEYr5K1Cu"
   },
   "source": [
    "## ðŸ”¹ Code cell 3 â€“ Build embeddings (KB_embeddings.npy + meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1854e7bb6e4c4fa22052a3ee4e0127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dc790ac24749a0ae0d43b75bf89889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b45f976aab2487dbdf749b2ca7a142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabad68327a1477cb57804b6960fdd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b9705f004147c5bd5a26f25b79fbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab90e9e2a7e747ac80e63d5e12135781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296d0cf3aea64403bbd569d188095538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6593cc65bc4b669e728e107f606031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0397c3f4d84561be9e6e2966ad183c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9119161203d442dbac46f7e01415ef00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages to embed: 162712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7a5acfd68d45cabcaae4b569dceb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: /content/drive/MyDrive/FATCR/data/processed/KB_embeddings.npy\n",
      "Saved embedding meta to: /content/drive/MyDrive/FATCR/data/processed/KB_embeddings.meta.json\n"
     ]
    }
   ],
   "source": [
    "# Step 3 â€” Build sentence embeddings for all KB passages\n",
    "\n",
    "!pip install -q sentence-transformers\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "texts = []\n",
    "with KB_PASS.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rec = json.loads(line)\n",
    "        texts.append(rec[\"text\"])\n",
    "\n",
    "print(\"Passages to embed:\", len(texts))\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "emb = model.encode(\n",
    "    texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,  # cosine similarity via inner product\n",
    ")\n",
    "emb = emb.astype(\"float32\")\n",
    "\n",
    "np.save(KB_EMB, emb)\n",
    "\n",
    "meta = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"count\": int(len(texts)),\n",
    "    \"dim\": int(emb.shape[1]),\n",
    "    \"normalized\": True,\n",
    "}\n",
    "KB_META.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved embeddings to:\", KB_EMB)\n",
    "print(\"Saved embedding meta to:\", KB_META)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqOTdSbyK5uv"
   },
   "source": [
    "## ðŸ”¹ Code cell 4 â€“ Build FAISS indexes + LAST_KB.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hâœ“ KB_all: 162712 vectors â†’ /content/drive/MyDrive/FATCR/data/processed/KB_all.faiss\n",
      "âœ“ KB_islam: 100186 vectors â†’ /content/drive/MyDrive/FATCR/data/processed/KB_islam.faiss\n",
      "âœ“ KB_christian: 62526 vectors â†’ /content/drive/MyDrive/FATCR/data/processed/KB_christian.faiss\n",
      "âœ“ Updated /content/drive/MyDrive/FATCR/data/processed/LAST_KB.json\n"
     ]
    }
   ],
   "source": [
    "# Step 4 â€” Build FAISS indexes for ALL, ISLAM-only, and CHRISTIAN-only\n",
    "\n",
    "!pip install -q faiss-cpu\n",
    "\n",
    "import faiss\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "\n",
    "# Load rows + embeddings\n",
    "rows = [json.loads(l) for l in KB_PASS.open(\"r\", encoding=\"utf-8\") if l.strip()]\n",
    "emb = np.load(str(KB_EMB)).astype(\"float32\")\n",
    "meta = json.loads(KB_META.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "assert len(rows) == emb.shape[0], f\"rows/emb size mismatch: {len(rows)} vs {emb.shape[0]}\"\n",
    "\n",
    "was_normalized = bool(meta.get(\"normalized\", True))\n",
    "if was_normalized:\n",
    "    faiss.normalize_L2(emb)\n",
    "\n",
    "d = emb.shape[1]\n",
    "index_factory = lambda: (faiss.IndexFlatIP(d) if was_normalized else faiss.IndexFlatL2(d))\n",
    "\n",
    "def build_subset(name, mask):\n",
    "    mask = np.asarray(mask, dtype=bool)\n",
    "    idxs = np.where(mask)[0]\n",
    "    sub_emb = emb[idxs]\n",
    "    idx = index_factory()\n",
    "    idx.add(sub_emb)\n",
    "\n",
    "    faiss_path = Path(DATA_DIR) / f\"{name}.faiss\"\n",
    "    map_path   = Path(DATA_DIR) / f\"{name}.map.jsonl\"\n",
    "\n",
    "    faiss.write_index(idx, str(faiss_path))\n",
    "\n",
    "    with map_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for pos, src_idx in enumerate(idxs):\n",
    "            json.dump({\"pos\": int(pos), \"kb_row\": int(src_idx)}, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(f\"âœ“ {name}: {len(idxs)} vectors â†’ {faiss_path}\")\n",
    "    return faiss_path, map_path\n",
    "\n",
    "all_mask    = np.ones(len(rows), dtype=bool)\n",
    "islam_mask  = np.array([r.get(\"tradition\") == \"Islam\"        for r in rows], dtype=bool)\n",
    "christ_mask = np.array([r.get(\"tradition\") == \"Christianity\" for r in rows], dtype=bool)\n",
    "\n",
    "fa_all,    map_all    = build_subset(\"KB_all\",       all_mask)\n",
    "fa_islam,  map_islam  = build_subset(\"KB_islam\",     islam_mask)\n",
    "fa_christ, map_christ = build_subset(\"KB_christian\", christ_mask)\n",
    "\n",
    "LAST_KB = {\n",
    "    \"time\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\"),\n",
    "    \"dim\": d,\n",
    "    \"normalized\": was_normalized,\n",
    "    \"model\": meta.get(\"model_name\"),\n",
    "    \"artefacts\": {\n",
    "        \"all\":       {\"faiss\": os.path.relpath(str(fa_all),   ROOT), \"map\": os.path.relpath(str(map_all),   ROOT)},\n",
    "        \"islam\":     {\"faiss\": os.path.relpath(str(fa_islam), ROOT), \"map\": os.path.relpath(str(map_islam), ROOT)},\n",
    "        \"christian\": {\"faiss\": os.path.relpath(str(fa_christ),ROOT), \"map\": os.path.relpath(str(map_christ),ROOT)},\n",
    "        \"passages\":  os.path.relpath(str(KB_PASS), ROOT),\n",
    "    },\n",
    "}\n",
    "\n",
    "LAST_KB_PATH = Path(DATA_DIR) / \"LAST_KB.json\"\n",
    "LAST_KB_PATH.write_text(json.dumps(LAST_KB, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"âœ“ Updated\", LAST_KB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olVXi4pMK9TW"
   },
   "source": [
    "## ðŸ”¹ Code cell 5 â€“ kb_search() helper + smoke tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deea7de038c640789f049a508daa7f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ec6cef3019422d9c04afd243e38ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e3a52368d427e8a774bac5e975e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97087b03f33437aacf443e91274fe3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc748649dfd46818f6c4bae6fe7cf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c4d5d014094884876c1c8dcd421cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156542adee154e609d6b2f631ce35dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26e9abb6bfa4c44a156d5a66182aa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7ba92cd44f41b39b6e864fc2866f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fbf293b862488db4bb0e1ad22d28e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'cup of blessing which we bless'  | subset='all'\n",
      " 1. score=0.7423 [Islam/scripture] Qur'an 54:35\n",
      "     A blessing from Us. Thus We reward the thankful.\n",
      " 2. score=0.6961 [Islam/scripture] Qur'an 76:5\n",
      "     But the righteous will drink from a cup whose mixture is aroma.\n",
      " 3. score=0.6636 [Islam/scripture] Qur'an 78:36\n",
      "     A reward from your Lord, a fitting gift.\n",
      " 4. score=0.6532 [Christianity/commentary] 1 Corinthians 10:16\n",
      "     And adds, \"The cup of blessing which we bless, is it not the communion of the blood of Christ? \". But if this indeed do not attain salvation, then neither did tâ€¦\n",
      " 5. score=0.6429 [Islam/scripture] Qur'an 93:11\n",
      "     But proclaim the blessings of your Lord.\n",
      "\n",
      "Query: 'one God in Trinity and Trinity in unity'  | subset='christian'\n",
      " 1. score=0.8073 [Christianity/creed] Athanasian Creed (Quicumque vult) (Latin Western creed (c. 5thâ€“6th C)) Â¶2\n",
      "     Now the universal faith is this: that we worship one God in Trinity, and Trinity in unity, neither confusing the persons nor dividing the divine being. For the â€¦\n",
      " 2. score=0.7961 [Christianity/creed] Athanasian Creed (Quicumque vult) (Latin Western creed (c. 5thâ€“6th C)) Â¶6\n",
      "     So there is one Father, not three Fathers; one Son, not three Sons; one Holy Spirit, not three Holy Spirits. And in this Trinity none is before or after anotherâ€¦\n",
      " 3. score=0.7828 [Christianity/commentary] Deuteronomy 6:4\n",
      "     That Trinity is one God. Not that Father, Son and Holy Spirit are identically the same. But the Father is Father, the Son is Son, and the Holy Spirit is Holy Spâ€¦\n",
      " 4. score=0.6959 [Christianity/commentary] Psalms 33:6\n",
      "     Nothing in the Trinity can be called greater or less, for there is but one fount of deity, who upholds the universe by his word and reason and sanctifies â€œby thâ€¦\n",
      " 5. score=0.6794 [Christianity/commentary] Romans 11:36\n",
      "     Paul is referring to the Trinity when he says this.\n"
     ]
    }
   ],
   "source": [
    "# Step 5 â€” kb_search() helper for interactive testing\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Reload rows & metadata (in case the notebook was resumed)\n",
    "rows = [json.loads(l) for l in KB_PASS.open(\"r\", encoding=\"utf-8\") if l.strip()]\n",
    "meta = json.loads(KB_META.read_text(encoding=\"utf-8\"))\n",
    "LAST_KB = json.loads(LAST_KB_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(meta[\"model_name\"])\n",
    "was_normalized = bool(meta.get(\"normalized\", True))\n",
    "\n",
    "INDEX_CACHE = {}\n",
    "\n",
    "def _load_index(subset: str = \"all\"):\n",
    "    subset = subset.lower()\n",
    "    if subset not in INDEX_CACHE:\n",
    "        art = LAST_KB[\"artefacts\"][subset]\n",
    "        faiss_path = Path(ROOT) / art[\"faiss\"]\n",
    "        map_path   = Path(ROOT) / art[\"map\"]\n",
    "        idx = faiss.read_index(str(faiss_path))\n",
    "\n",
    "        mapping = []\n",
    "        with map_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                d = json.loads(line)\n",
    "                mapping.append(d[\"kb_row\"])\n",
    "        mapping = np.array(mapping, dtype=int)\n",
    "        INDEX_CACHE[subset] = (idx, mapping)\n",
    "    return INDEX_CACHE[subset]\n",
    "\n",
    "def kb_search(query: str, top_k: int = 5, subset: str = \"all\"):\n",
    "    \"\"\"Search the KB for a natural-language query.\n",
    "\n",
    "    subset: 'all', 'islam', or 'christian'.\n",
    "    \"\"\"\n",
    "    idx, mapping = _load_index(subset)\n",
    "    q_emb = model.encode(\n",
    "        [query],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=was_normalized\n",
    "    ).astype(\"float32\")\n",
    "    if was_normalized:\n",
    "        faiss.normalize_L2(q_emb)\n",
    "\n",
    "    D, I = idx.search(q_emb, top_k)\n",
    "    print(f\"\\nQuery: {query!r}  | subset='{subset}'\")\n",
    "    for rank, (score, pos) in enumerate(zip(D[0], I[0]), start=1):\n",
    "        if pos == -1:\n",
    "            continue\n",
    "        row_idx = int(mapping[pos])\n",
    "        rec = rows[row_idx]\n",
    "        txt = rec[\"text\"].replace(\"\\n\", \" \")\n",
    "        snippet = (txt[:160] + \"â€¦\") if len(txt) > 160 else txt\n",
    "        print(f\"{rank:2d}. score={float(score):.4f} \"\n",
    "              f\"[{rec.get('tradition','?')}/{rec.get('genre','?')}] \"\n",
    "              f\"{rec.get('ref', rec.get('group_key',''))}\")\n",
    "        print(\"    \", snippet)\n",
    "\n",
    "# Example smoke tests (you can comment these out later)\n",
    "kb_search(\"cup of blessing which we bless\", top_k=5, subset=\"all\")\n",
    "kb_search(\"one God in Trinity and Trinity in unity\", top_k=5, subset=\"christian\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
