{"cells":[{"cell_type":"markdown","id":"eoRI5uPbYK2_","metadata":{"id":"eoRI5uPbYK2_"},"source":["# FACTR ‚Äî ASR (faster-whisper) + Diarize/Align (WhisperX)\n","**Version:** v2025-09-07_1.0  \n","**Purpose:** Turn AUDIO_PATH into UTTERANCES.parquet with speakers \u0026 timestamps.\n"]},{"cell_type":"markdown","id":"owl1cFyceYKl","metadata":{"id":"owl1cFyceYKl"},"source":["# Why these pins / choices?\n","\n","We avoid the old ‚ÄúTranscriptionOptions(..., multilingual=‚Ä¶)‚Äù mismatch by not calling WhisperX‚Äôs ASR; instead we use faster-whisper for ASR and keep WhisperX just for alignment \u0026 diarization, which works cleanly with:\n","\n","faster-whisper==1.1.1\n","\n","ctranslate2==4.4.0\n","\n","onnxruntime==1.19.2\n","\n","whisperx@git + pyannote.audio==3.3.2\n","\n","The ASR model list tries medium.en then falls back to small.en; on CPU it uses small.en.\n","\n","compute_type=\"int8_float16\" (GPU) or \"int8\" (CPU) keeps VRAM/RAM in check and reduces OOMs.\n","\n","vad_filter=False avoids pulling an extra VAD model; diarization handles speaker turns anyway."]},{"cell_type":"code","execution_count":null,"id":"qDQfEoDwk8GY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":969,"status":"ok","timestamp":1757544324294,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"qDQfEoDwk8GY","outputId":"56220159-0376-4c3f-961d-658fb3aa31d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"v8Dsawwidvij","metadata":{"id":"v8Dsawwidvij"},"source":["## üîß Section 0 ‚Äî One-cell setup (installs \u0026 sanity print)"]},{"cell_type":"code","execution_count":null,"id":"yTNX6u1edzHU","metadata":{"colab":{"background_save":true},"id":"yTNX6u1edzHU"},"outputs":[{"name":"stdout","output_type":"stream","text":["pyannote-metrics 4.0.0 has requirement numpy\u003e=2.2.2, but you have numpy 2.0.2.\n","torchvision 0.20.1 has requirement torch==2.5.1, but you have torch 2.8.0.\n","google-colab 1.0.0 has requirement pandas==2.2.2, but you have pandas 2.3.2.\n","google-colab 1.0.0 has requirement requests==2.32.4, but you have requests 2.32.5.\n","grpcio-status 1.71.2 has requirement protobuf\u003c6.0dev,\u003e=5.26.1, but you have protobuf 6.32.0.\n","tensorflow 2.19.0 has requirement protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0.\n","dask-cudf-cu12 25.6.0 has requirement pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2.\n","cudf-cu12 25.6.0 has requirement pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2.\n","bigframes 2.18.0 has requirement rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0.\n","google-ai-generativelanguage 0.6.15 has requirement protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 6.32.0.\n","datasets 4.0.0 has requirement fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0.\n","gcsfs 2025.3.0 has requirement fsspec==2025.3.0, but you have fsspec 2025.9.0.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyannote-metrics 4.0.0 requires numpy\u003e=2.2.2, but you have numpy 2.0.2 which is incompatible.\n","pyannote-pipeline 4.0.0 requires filelock\u003e=3.17.0, but you have filelock 3.13.1 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","pytensor 2.31.7 requires filelock\u003e=3.15, but you have filelock 3.13.1 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires numpy\u003c2.2.0,\u003e=1.26.0, but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy\u003c2.3,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","numba 0.60.0 requires numpy\u003c2.1,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.5.1 requires sympy==1.13.1; python_version \u003e= \"3.9\", but you have sympy 1.14.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf\u003c6.0dev,\u003e=5.26.1, but you have protobuf 6.32.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires numpy\u003c2.2.0,\u003e=1.26.0, but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy\u003c2.3,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","numba 0.60.0 requires numpy\u003c2.1,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 6.32.0 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n","  DEPRECATION: Building 'julius' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'julius'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.8.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf\u003c6.0dev,\u003e=5.26.1, but you have protobuf 6.32.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires numpy\u003c2.2.0,\u003e=1.26.0, but you have numpy 2.3.3 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy\u003c2.3,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","numba 0.60.0 requires numpy\u003c2.1,\u003e=1.22, but you have numpy 2.3.3 which is incompatible.\n","google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 6.32.0 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyannote-metrics 4.0.0 requires numpy\u003e=2.2.2, but you have numpy 2.0.2 which is incompatible.\n","torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.8.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyannote-metrics 4.0.0 requires numpy\u003e=2.2.2, but you have numpy 2.0.2 which is incompatible.\n","torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.8.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n"]}],"source":["%%bash\n","set -euo pipefail\n","\n","# 0) Keep pip modern (but below the 25.3 change)\n","pip install -q --upgrade \"pip\u003c25.3\" wheel\n","\n","# 1) Baseline scientific stack (match what faster-whisper/onnxruntime expect)\n","pip install -q --upgrade --force-reinstall --no-cache-dir \\\n","  \"numpy==2.0.2\" \"pandas==2.2.3\" \"pyarrow\u003e=15,\u003c17\" \"jedi\u003e=0.16\"\n","\n","# 2) PyTorch trio (Colab will auto-pick a CUDA build if a GPU is attached)\n","pip install -q --upgrade --force-reinstall --no-cache-dir \\\n","  \"torch==2.5.1\" \"torchvision==0.20.1\" \"torchaudio==2.5.1\"\n","\n","# 3) ASR stack (faster-whisper + onnxruntime, versions that play nicely together)\n","pip install -q --upgrade --force-reinstall --no-cache-dir \\\n","  \"faster-whisper==1.1.1\" \"ctranslate2==4.4.0\" \"onnxruntime==1.19.2\"\n","\n","# 4) WhisperX + pyannote\n","pip install -q --upgrade --force-reinstall --no-cache-dir \\\n","  \"git+https://github.com/m-bain/whisperx.git\" \"pyannote.audio==3.3.2\"\n","\n","# 5) Utilities\n","pip install -q --upgrade librosa soundfile matplotlib\n","\n","# ‚úÖ 6) Re-pin NumPy last to avoid accidental upgrades during deps resolution\n","pip install -q --upgrade --force-reinstall --no-cache-dir \"numpy==2.0.2\"\n","\n","# Show real breakages (warnings here are ok)\n","pip check || true\n"]},{"cell_type":"code","execution_count":null,"id":"FO4H05vGd2ge","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6058,"status":"ok","timestamp":1757541039596,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"FO4H05vGd2ge","outputId":"ed186cbb-ccef-430e-e70c-78a3433612bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python: 3.12.11\n","CUDA available: False\n","Torch: 2.8.0+cu126\n","NumPy: 2.0.2\n","Pandas: 2.2.2\n","faster_whisper   1.2.0\n","ctranslate2      4.4.0\n","onnxruntime      1.22.1\n","whisperx         git\n","pyannote.audio   not importable -\u003e operator torchvision::nms does not exist\n"]}],"source":["# --- Print versions so we can diff future runs quickly ---\n","import sys, importlib, torch, numpy as np, pandas as pd\n","mods = [\"faster_whisper\",\"ctranslate2\",\"onnxruntime\",\"whisperx\",\"pyannote.audio\"]\n","print(\"Python:\", sys.version.split()[0])\n","print(\"CUDA available:\", torch.cuda.is_available())\n","print(\"Torch:\", torch.__version__)\n","print(\"NumPy:\", np.__version__)\n","print(\"Pandas:\", pd.__version__)\n","for m in mods:\n","    try:\n","        mod = importlib.import_module(m if m!=\"pyannote.audio\" else \"pyannote.audio\")\n","        print(f\"{m:16s}\", getattr(mod, \"__version__\", \"git\"))\n","    except Exception as e:\n","        print(f\"{m:16s}\", \"not importable -\u003e\", e)\n"]},{"cell_type":"markdown","id":"idWpT4Myd5Le","metadata":{"id":"idWpT4Myd5Le"},"source":["## üì• Section 1 ‚Äî Load the audio path from 02 (handoff)"]},{"cell_type":"code","execution_count":null,"id":"Om0fqJU3d67y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1757541039648,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"Om0fqJU3d67y","outputId":"9518a5ec-5c03-481e-955a-86c9a35a2746"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUDIO_PATH: /content/drive/MyDrive/FATCR/data/processed/speFWRuuJNs_16k_mono.wav\n"]}],"source":["import json, os\n","\n","# Expect this file from FACTR_02\n","HANDOFF = \"/content/drive/MyDrive/FATCR/data/processed/LAST_INGEST.json\"\n","assert os.path.exists(HANDOFF), \"LAST_INGEST.json not found (run FACTR_02 first).\"\n","\n","with open(HANDOFF, \"r\") as f:\n","    meta = json.load(f)\n","\n","# --- Fix: make AUDIO_PATH absolute ---\n","repo_root = \"/content/drive/MyDrive/FATCR\"\n","AUDIO_PATH = os.path.join(repo_root, meta[\"audio_path\"])\n","print(\"AUDIO_PATH:\", AUDIO_PATH)\n","\n","assert os.path.exists(AUDIO_PATH) and os.path.getsize(AUDIO_PATH) \u003e 10_000, \"Bad AUDIO_PATH.\"\n","\n"]},{"cell_type":"markdown","id":"1i2vEjcZd_O6","metadata":{"id":"1i2vEjcZd_O6"},"source":["## üéôÔ∏è Section 2 ‚Äî ASR with faster-whisper (OOM-safe)"]},{"cell_type":"code","execution_count":null,"id":"hTof86tyeAYb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":2140674,"status":"ok","timestamp":1757543180324,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"hTof86tyeAYb","outputId":"011c542a-4a61-4579-f998-5b2c381f87cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚Üí loading small.en in faster-whisper on cpu (int8)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cdbdd0ba6c744e4a4782b64eb988bf6","version_major":2,"version_minor":0},"text/plain":["model.bin:   0%|          | 0.00/484M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcc294979f4b4e7a9f1897df4a44b48e","version_major":2,"version_minor":0},"text/plain":["config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"294985991152465fa13568486100d651","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9afcb728ec8949e993b5679506274fd2","version_major":2,"version_minor":0},"text/plain":["vocabulary.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ASR segments: 1115 | detected language: en\n"]}],"source":["from faster_whisper import WhisperModel\n","import torch, gc\n","\n","HAS_CUDA = torch.cuda.is_available()\n","DEVICE = \"cuda\" if HAS_CUDA else \"cpu\"\n","compute_type = \"int8_float16\" if HAS_CUDA else \"int8\"  # conservative \u0026 OOM-friendly\n","\n","arch_candidates = [\"medium.en\", \"small.en\"] if HAS_CUDA else [\"small.en\"]\n","\n","fw_model = None\n","last_err = None\n","\n","for name in arch_candidates:\n","    try:\n","        print(f\"‚Üí loading {name} in faster-whisper on {DEVICE} ({compute_type})\")\n","        fw_model = WhisperModel(name, device=DEVICE, compute_type=compute_type)\n","        break\n","    except Exception as e:\n","        print(\"‚ö†Ô∏è load failed:\", e)\n","        last_err = e\n","        gc.collect()\n","        torch.cuda.empty_cache() if HAS_CUDA else None\n","\n","if fw_model is None:\n","    raise RuntimeError(f\"Could not load a faster-whisper model. Last error: {last_err}\")\n","\n","# Do the transcription (disable VAD to avoid extra model load; diarization will handle speech turns)\n","segments_gen, info = fw_model.transcribe(\n","    AUDIO_PATH,\n","    language=\"en\",           # set language if known to skip detection\n","    beam_size=5,\n","    vad_filter=False,        # True enables Silero-VAD; keep False unless you want pre-filtering\n",")\n","\n","# Convert to a simple list of segments\n","asr_segments = []\n","for s in segments_gen:\n","    asr_segments.append({\n","        \"start\": float(s.start) if s.start is not None else None,\n","        \"end\":   float(s.end)   if s.end   is not None else None,\n","        \"text\": (s.text or \"\").strip()\n","    })\n","\n","print(f\"ASR segments: {len(asr_segments)} | detected language: {info.language or 'en'}\")\n"]},{"cell_type":"code","execution_count":null,"id":"35eF0KABxnF8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13625,"status":"ok","timestamp":1757543842991,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"35eF0KABxnF8","outputId":"7ba1042e-f1bc-46e0-ab1c-c22a48aa9fee"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"has_cuda\": false}\n"]}],"source":["%%bash\n","set -euo pipefail\n","\n","# Detect GPU\n","python - \u003c\u003c'PY'\n","import torch, json, sys\n","print(json.dumps({\"has_cuda\": torch.cuda.is_available()}))\n","PY\n"]},{"cell_type":"code","execution_count":null,"id":"vn6sr1nlxw_J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66851,"status":"ok","timestamp":1757543932688,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"vn6sr1nlxw_J","outputId":"2e6e37c5-4bd6-450d-bc3b-5570ad6b4100"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyannote-metrics 4.0.0 requires numpy\u003e=2.2.2, but you have numpy 2.1.2 which is incompatible.\n","pyannote-pipeline 4.0.0 requires filelock\u003e=3.17.0, but you have filelock 3.13.1 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","typeguard 4.4.4 requires typing_extensions\u003e=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n","pytensor 2.31.7 requires filelock\u003e=3.15, but you have filelock 3.13.1 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas\u003c2.2.4dev0,\u003e=2.0, but you have pandas 2.3.2 which is incompatible.\n","bigframes 2.18.0 requires rich\u003c14,\u003e=12.4.4, but you have rich 14.1.0 which is incompatible.\n","numba 0.60.0 requires numpy\u003c2.1,\u003e=1.22, but you have numpy 2.1.2 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n"]}],"source":["%%bash\n","set -euo pipefail\n","# Install the CPU builds explicitly\n","pip install -q --force-reinstall --no-cache-dir \\\n","  torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n","  --index-url https://download.pytorch.org/whl/cpu\n"]},{"cell_type":"code","execution_count":null,"id":"_UJz4bZyyQYz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9435,"status":"ok","timestamp":1757544005352,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"_UJz4bZyyQYz","outputId":"73d1ccf8-041c-4a43-e20d-98358d25878c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch: 2.5.1+cpu | CUDA available: False\n","Torchaudio: 2.5.1+cpu\n","Torchvision: 0.20.1+cpu\n"]}],"source":["import torch\n","print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n","try:\n","    import torchaudio, torchvision\n","    print(\"Torchaudio:\", torchaudio.__version__)\n","    print(\"Torchvision:\", torchvision.__version__)\n","except Exception as e:\n","    print(\"Import error:\", repr(e))\n"]},{"cell_type":"markdown","id":"88C9EtKfeE1a","metadata":{"id":"88C9EtKfeE1a"},"source":["## üìè Section 3 ‚Äî (Optional) alignment with WhisperX"]},{"cell_type":"code","execution_count":null,"id":"7DdCUHtoeGLA","metadata":{"id":"7DdCUHtoeGLA"},"outputs":[],"source":["import whisperx\n","\n","align_model, metadata = whisperx.load_align_model(\n","    language_code=(info.language or \"en\"),\n","    device=DEVICE\n",")\n","asr_aligned = whisperx.align(asr_segments, align_model, metadata, AUDIO_PATH, DEVICE)\n"]},{"cell_type":"code","execution_count":null,"id":"hQOml4DbzMHB","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"elapsed":34,"status":"error","timestamp":1757544239126,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"hQOml4DbzMHB","outputId":"e817eda7-8938-4cab-bca4-8f8045b5c31a"},"outputs":[{"ename":"NameError","evalue":"name 'DEVICE' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2752613998.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m align_model, metadata = whisperx.load_align_model(\n\u001b[1;32m     12\u001b[0m     \u001b[0mlanguage_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 13\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"]}],"source":["import whisperx\n","\n","# Pick the language: use 'info.language' if available, else default to English\n","language_code = \"en\"\n","try:\n","    if \"info\" in globals() and getattr(info, \"language\", None):\n","        language_code = info.language\n","except Exception:\n","    pass\n","\n","align_model, metadata = whisperx.load_align_model(\n","    language_code=language_code,\n","    device=DEVICE\n",")\n","\n","asr_aligned = whisperx.align(asr_segments, align_model, metadata, AUDIO_PATH, DEVICE)\n","print(\"‚úÖ Alignment complete with language:\", language_code)\n"]},{"cell_type":"markdown","id":"cXj7A9KleJy0","metadata":{"id":"cXj7A9KleJy0"},"source":["## üó£Ô∏è Section 4 ‚Äî Diarization with WhisperX"]},{"cell_type":"code","execution_count":null,"id":"IWJXSHLzeK2T","metadata":{"id":"IWJXSHLzeK2T"},"outputs":[],"source":["# If you have a HF token for diarization models, add it here (optional)\n","HUGGINGFACE_TOKEN = \"\"  # e.g. \"hf_xxx\"; leave empty to use public pipeline\n","\n","if HUGGINGFACE_TOKEN:\n","    diar = whisperx.DiarizationPipeline(device=DEVICE, use_auth_token=HUGGINGFACE_TOKEN)\n","else:\n","    diar = whisperx.DiarizationPipeline(device=DEVICE)\n","\n","diar_out = diar(AUDIO_PATH)\n","\n","# Assign speakers to aligned words/segments\n","asr_spk = whisperx.assign_word_speakers(diar_out, asr_aligned)\n","print(\"Diarization done.\")\n"]},{"cell_type":"markdown","id":"fknVGvQrePE_","metadata":{"id":"fknVGvQrePE_"},"source":["## üíæ Section 5 ‚Äî Save as UTTERANCES.parquet"]},{"cell_type":"code","execution_count":null,"id":"5yPMeqWheQaa","metadata":{"id":"5yPMeqWheQaa"},"outputs":[],"source":["import pandas as pd, os\n","\n","rows = []\n","for seg in asr_spk[\"segments\"]:\n","    rows.append({\n","        \"video_id\": os.path.basename(AUDIO_PATH),\n","        \"t_start\":  seg.get(\"start\"),\n","        \"t_end\":    seg.get(\"end\"),\n","        \"speaker\":  seg.get(\"speaker\", \"SPEAKER_00\"),\n","        \"text\":     (seg.get(\"text\") or \"\").strip()\n","    })\n","\n","df_utts = pd.DataFrame(rows)\n","os.makedirs(\"data/processed\", exist_ok=True)\n","OUT_PARQUET = \"data/processed/UTTERANCES.parquet\"\n","df_utts.to_parquet(OUT_PARQUET, index=False)\n","print(f\"‚úÖ wrote {OUT_PARQUET} with\", len(df_utts), \"rows\")\n","df_utts.head()\n"]},{"cell_type":"markdown","id":"QBauMo5Pe19g","metadata":{"id":"QBauMo5Pe19g"},"source":["## 6) Snapshot + hand-off pointer (JSON)"]},{"cell_type":"code","execution_count":null,"id":"bo06u_Xye4oD","metadata":{"id":"bo06u_Xye4oD"},"outputs":[],"source":["# === 6) Snapshot + hand-off pointer ===\n","import json, time, platform, os, sys\n","import torch, pandas as pd\n","\n","# Basic metrics\n","dur_sec = float(df_utts[\"t_end\"].fillna(0).max() or 0)\n","row_count = int(len(df_utts))\n","\n","# Try to read versions safely\n","def safe_ver(modname):\n","    try:\n","        m = __import__(modname)\n","        return getattr(m, \"__version__\", \"git\")\n","    except Exception:\n","        return \"n/a\"\n","\n","snap = {\n","    \"ts\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n","    \"platform\": platform.platform(),\n","    \"python\": sys.version.split()[0],\n","    \"cuda_available\": torch.cuda.is_available(),\n","    \"device\": DEVICE,\n","    \"compute_type\": compute_type,\n","    \"asr_model\": getattr(fw_model, \"_model_name\", \"unknown\"),  # faster-whisper keeps name here\n","    \"whisperx\": safe_ver(\"whisperx\"),\n","    \"faster_whisper\": safe_ver(\"faster_whisper\"),\n","    \"ctranslate2\": safe_ver(\"ctranslate2\"),\n","    \"onnxruntime\": safe_ver(\"onnxruntime\"),\n","    \"pyannote_audio\": safe_ver(\"pyannote.audio\"),\n","    \"audio_path\": AUDIO_PATH,\n","    \"utterances_parquet\": OUT_PARQUET,\n","    \"rows\": row_count,\n","    \"duration_sec\": round(dur_sec, 2),\n","}\n","\n","os.makedirs(\"snapshots\", exist_ok=True)\n","snap_path = f\"snapshots/ASR_SNAPSHOT_{int(time.time())}.json\"\n","with open(snap_path, \"w\") as f:\n","    json.dump(snap, f, indent=2)\n","print(\"üóÇÔ∏è Snapshot:\", snap_path)\n","\n","# Hand-off pointer for downstream notebooks\n","handoff = {\n","    \"when\": snap[\"ts\"],\n","    \"audio_path\": AUDIO_PATH,\n","    \"utterances_parquet\": OUT_PARQUET,\n","    \"rows\": row_count,\n","    \"note\": \"Use 'utterances_parquet' for FACTR_04_Claims+Embeddings\",\n","}\n","with open(\"data/processed/LAST_ASR.json\", \"w\") as f:\n","    json.dump(handoff, f, indent=2)\n","print(\"üìù Wrote data/processed/LAST_ASR.json\")\n"]},{"cell_type":"markdown","id":"m_A5QSe7e-40","metadata":{"id":"m_A5QSe7e-40"},"source":["## 7) Optional: git-push helper (uses GITHUB_PAT in Colab Secrets)\n","\n","This commits your notebook, the snapshot, and the hand-off JSON.\n","If the parquet is \u003e 20 MB, it avoids pushing it and commits only the pointer to keep the repo lean."]},{"cell_type":"code","execution_count":null,"id":"_er8Phzxe_6e","metadata":{"id":"_er8Phzxe_6e"},"outputs":[],"source":["# === 7) Optional push to GitHub (needs GITHUB_PAT in Colab Secrets) ===\n","from google.colab import userdata\n","import urllib.parse, subprocess, os, shlex\n","\n","REPO_DIR = \"/content/drive/MyDrive/FATCR\"\n","os.chdir(REPO_DIR)\n","\n","def run(cmd):\n","    print(\"$\", cmd)\n","    return subprocess.run(shlex.split(cmd), check=False)\n","\n","print(\"üìÇ Repo status before push:\")\n","run(\"git status -sb\")\n","\n","pat = userdata.get(\"GITHUB_PAT\")\n","if not pat:\n","    print(\"‚ÑπÔ∏è No GITHUB_PAT in Colab Secrets ‚Äî skipping push.\")\n","else:\n","    enc_pat = urllib.parse.quote(pat, safe=\"\")\n","    REMOTE_URL = f\"https://LukmaanViscomi:{enc_pat}@github.com/LukmaanViscomi/FATCR.git\"\n","\n","    # Always pull latest (rebase) to reduce non-fast-forward issues\n","    print(\"\\nüîÑ Pulling latest (rebase, autostash)‚Ä¶\")\n","    run(f\"git pull --rebase --autostash {REMOTE_URL} main\")\n","\n","    # Decide whether to add the parquet (skip if very large)\n","    parquet_size = os.path.getsize(OUT_PARQUET) if os.path.exists(OUT_PARQUET) else 0\n","    add_parquet = parquet_size \u003c= 20 * 1024 * 1024  # 20 MB\n","\n","    # Stage files\n","    paths = [\n","        \"notebooks\",                 # your notebooks\n","        \"snapshots\",                 # ASR snapshot\n","        \"data/processed/LAST_ASR.json\",\n","    ]\n","    if add_parquet:\n","        paths.append(OUT_PARQUET)    # add parquet if small enough\n","    else:\n","        print(f\"‚ÑπÔ∏è {OUT_PARQUET} is {parquet_size/1e6:.1f} MB; skipping to keep repo small.\")\n","\n","    run(\"git add \" + \" \".join(shlex.quote(p) for p in paths) + \" .gitignore\")\n","\n","    # Commit only if there are staged changes\n","    changed = subprocess.run([\"git\",\"diff\",\"--cached\",\"--quiet\"]).returncode != 0\n","    if changed:\n","        msg = \"ASR+diarize results (snapshot + pointer)\"\n","        print(\"\\n‚úèÔ∏è Committing:\", msg)\n","        run(f'git commit -m \"{msg}\"')\n","        print(\"\\n‚¨ÜÔ∏è Pushing to main‚Ä¶\")\n","        run(f\"git push {REMOTE_URL} HEAD:main\")\n","        print(\"\\n‚úÖ Push complete.\")\n","    else:\n","        print(\"\\n‚ÑπÔ∏è Nothing to commit.\")\n"]},{"cell_type":"code","execution_count":null,"id":"pHUvWqBtYK3D","metadata":{"id":"pHUvWqBtYK3D"},"outputs":[],"source":["# Config (tune these safely)\n","class CFG:\n","    DEVICE = \"cuda\"   # \"cuda\" or \"cpu\"\n","    ASR_MODEL = \"small.en\"   # try \"medium.en\" later\n","    CHUNK_LENGTH = 20        # seconds\n","    BEAM_SIZE = 3\n","    WORD_TIMESTAMPS = True\n","    USE_ALIGNMENT = True\n","    USE_DIARIZATION = True\n","    HUGGINGFACE_TOKEN = \"\"   # optional\n","print(vars(CFG))\n"]},{"cell_type":"code","execution_count":null,"id":"-PhUQO4dYK3E","metadata":{"id":"-PhUQO4dYK3E"},"outputs":[],"source":["# ASR -\u003e Diarize -\u003e Align -\u003e Save parquet\n","import os, gc, torch, pandas as pd\n","from faster_whisper import WhisperModel\n","import whisperx\n","\n","assert \"AUDIO_PATH\" in globals() and AUDIO_PATH and os.path.exists(AUDIO_PATH), \"AUDIO_PATH missing (run Ingest).\"\n","\n","# Cap native threads to avoid RAM spikes\n","os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n","os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n","os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n","os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n","\n","HAS_CUDA = torch.cuda.is_available() and (CFG.DEVICE == \"cuda\")\n","DEVICE = \"cuda\" if HAS_CUDA else \"cpu\"\n","compute_type = \"int8_float16\" if HAS_CUDA else \"int8\"\n","\n","print(f\"‚Üí loading {CFG.ASR_MODEL} in faster-whisper on {DEVICE} ({compute_type})\")\n","fw = WhisperModel(CFG.ASR_MODEL, device=DEVICE, compute_type=compute_type)\n","\n","segments_gen, info = fw.transcribe(\n","    AUDIO_PATH,\n","    language=\"en\",\n","    beam_size=CFG.BEAM_SIZE,\n","    vad_filter=False,   # let WhisperX diarization handle VAD\n","    chunk_length=CFG.CHUNK_LENGTH,\n","    word_timestamps=CFG.WORD_TIMESTAMPS,\n",")\n","\n","asr_segments = []\n","for s in segments_gen:\n","    seg = {\"start\": float(s.start) if s.start is not None else None,\n","           \"end\": float(s.end) if s.end is not None else None,\n","           \"text\": (s.text or \"\").strip()}\n","    if getattr(s, \"words\", None):\n","        seg[\"words\"] = [{\"start\": float(w.start) if w.start is not None else None,\n","                         \"end\": float(w.end) if w.end is not None else None,\n","                         \"word\": w.word} for w in s.words]\n","    asr_segments.append(seg)\n","asr = {\"segments\": asr_segments, \"language\": (info.language or \"en\")}\n","print(f\"ASR segments: {len(asr_segments)} | language: {asr['language']}\")\n","\n","# Diarization\n","if CFG.USE_DIARIZATION:\n","    try:\n","        from whisperx.diarize import DiarizationPipeline\n","    except Exception:\n","        from whisperx import DiarizationPipeline\n","    diar = DiarizationPipeline(device=DEVICE, use_auth_token=(CFG.HUGGINGFACE_TOKEN or None))\n","    diar_out = diar(AUDIO_PATH)\n","else:\n","    diar_out = {\"segments\": []}\n","\n","# Alignment\n","if CFG.USE_ALIGNMENT:\n","    try:\n","        align_model, metadata = whisperx.load_align_model(language_code=asr[\"language\"], device=DEVICE)\n","        asr_aligned = whisperx.align(asr[\"segments\"], align_model, metadata, AUDIO_PATH, DEVICE)\n","    except AttributeError:\n","        from whisperx.alignment import load_align_model, align\n","        align_model, metadata = load_align_model(language_code=asr[\"language\"], device=DEVICE)\n","        asr_aligned = align(asr[\"segments\"], align_model, metadata, AUDIO_PATH, DEVICE)\n","else:\n","    asr_aligned = {\"segments\": asr[\"segments\"]}\n","\n","# Assign speakers\n","asr_spk = whisperx.assign_word_speakers(diar_out, asr_aligned)\n","\n","rows = [{\n","    \"video_id\": os.path.basename(AUDIO_PATH),\n","    \"t_start\": s.get(\"start\"),\n","    \"t_end\": s.get(\"end\"),\n","    \"speaker\": s.get(\"speaker\", \"SPEAKER_00\"),\n","    \"text\": (s.get(\"text\") or \"\").strip(),\n","} for s in asr_spk[\"segments\"]]\n","\n","df = pd.DataFrame(rows)\n","df.to_parquet(\"UTTERANCES.parquet\", index=False)\n","print(\"‚úÖ wrote UTTERANCES.parquet with\", len(df), \"rows\")\n","try:\n","    display(df.head(10))\n","except Exception:\n","    print(df.head(10).to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"id":"Snh2mw2bYK3F","metadata":{"id":"Snh2mw2bYK3F"},"outputs":[],"source":["# Smoke test\n","import os, pandas as pd\n","assert os.path.exists(\"UTTERANCES.parquet\"), \"Missing UTTERANCES.parquet\"\n","df = pd.read_parquet(\"UTTERANCES.parquet\")\n","required = {\"video_id\",\"t_start\",\"t_end\",\"speaker\",\"text\"}\n","assert required.issubset(df.columns), f\"Missing cols: {required - set(df.columns)}\"\n","assert len(df) \u003e 0, \"No rows produced\"\n","print(\"‚úÖ ASR+Diarize smoke test passed. Rows:\", len(df))\n"]},{"cell_type":"code","execution_count":null,"id":"eSpWsoYAYK3F","metadata":{"id":"eSpWsoYAYK3F"},"outputs":[],"source":["# Snapshot\n","import json, time, os, subprocess, sys, torch, pandas as pd\n","snap = {\n","  \"ts\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n","  \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","  \"asr_model\": \"small.en\",\n","  \"pip_freeze\": subprocess.check_output([\"pip\",\"freeze\"], text=True).splitlines()[:150],\n","}\n","os.makedirs(\"snapshots\", exist_ok=True)\n","import time as _t\n","p = f\"snapshots/ASR_DIA_SNAPSHOT_{int(_t.time())}.json\"\n","with open(p,\"w\") as f: json.dump(snap,f,indent=2)\n","print(\"üì∏ Saved:\", p)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07481e8d60f04d3b9cbc8683c7f88fa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c81153779b8941a49bf25f8399f15fb3","placeholder":"‚Äã","style":"IPY_MODEL_cc9e7b0902e34f31ad21c8e51e8e1b5d","value":"‚Äá484M/484M‚Äá[00:13\u0026lt;00:00,‚Äá53.0MB/s]"}},"0e29b1c149d047839bedcd51d391714a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31c482f69be24ee9b854b300b18fae4c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fe3612a011b48c8bda53ef36a38d2c6","value":1}},"138ab98de9644cdbbf3c56058342ae18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89dcaa3ef3124b609d924aeb5736f337","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87b59a1eb2a6444e9021e6339c90822a","value":1}},"187e4ded87174be69918a0142728f91b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cafce3699894164954a88f1d65a489b","max":483545366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d56720fc741462cb376efb60f2a8c0e","value":483545366}},"245acd8ce25d49b398b395bb0be9245c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"294985991152465fa13568486100d651":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d3fa97976434378aca7f319c7326139","IPY_MODEL_0e29b1c149d047839bedcd51d391714a","IPY_MODEL_f9fd825052994a10bf5258e6dbf64a35"],"layout":"IPY_MODEL_f4f40509a9174471858b9ce3b7a81867"}},"2cafce3699894164954a88f1d65a489b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d3fa97976434378aca7f319c7326139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_585513a470b5416c8aaed00bb7b78457","placeholder":"‚Äã","style":"IPY_MODEL_86180a423c274bfaab0e8eb9cbf5e6c8","value":"tokenizer.json:‚Äá"}},"2e8e9ea2310045db8bdf4d345cf3cc6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c482f69be24ee9b854b300b18fae4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3fe3612a011b48c8bda53ef36a38d2c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"408edecc69664acd9b254663b638a2e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b97bf6e14b5f4b12b5648e45dde25fa4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f60f1589300245c8bf114800278ec35e","value":1}},"45d903ca59374943b092b35d5f8189e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a95e27901dd466e97f3fd0d5f3c7b11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"585513a470b5416c8aaed00bb7b78457":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cdbdd0ba6c744e4a4782b64eb988bf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efd0aa7a8af14fd89f1fb87fac81f517","IPY_MODEL_187e4ded87174be69918a0142728f91b","IPY_MODEL_07481e8d60f04d3b9cbc8683c7f88fa4"],"layout":"IPY_MODEL_70f6bff412cf45b88178ffef2f5db34b"}},"6fea0cdbde7e49ecba0f6470312588e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff307f24f002427aaa186a2b9655498e","placeholder":"‚Äã","style":"IPY_MODEL_dd328ec128b24d3daab62ba7c78588fd","value":"‚Äá2.66k/?‚Äá[00:00\u0026lt;00:00,‚Äá50.7kB/s]"}},"70f6bff412cf45b88178ffef2f5db34b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86180a423c274bfaab0e8eb9cbf5e6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"870fae2c32e2453fa29417b1bfa165f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed71409ac1ac42e283b6025d6b66f2ff","placeholder":"‚Äã","style":"IPY_MODEL_245acd8ce25d49b398b395bb0be9245c","value":"config.json:‚Äá"}},"87b59a1eb2a6444e9021e6339c90822a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89dcaa3ef3124b609d924aeb5736f337":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9afcb728ec8949e993b5679506274fd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d037ac3a25b8476a92015ce9eaced768","IPY_MODEL_138ab98de9644cdbbf3c56058342ae18","IPY_MODEL_c9c688d70f7e42d793230f44b0138fb9"],"layout":"IPY_MODEL_e0ca711e228c40a98751406fb1157124"}},"9d56720fc741462cb376efb60f2a8c0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0d0cab6871b44b186d342b3deb49ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaafed1849274ae1a3fe54ff3de689aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab64cd8e9f644db7843c971a4a2c7fef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b97bf6e14b5f4b12b5648e45dde25fa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c81153779b8941a49bf25f8399f15fb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9c688d70f7e42d793230f44b0138fb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45d903ca59374943b092b35d5f8189e5","placeholder":"‚Äã","style":"IPY_MODEL_e9a08368bf444037980e0c566cf830b7","value":"‚Äá422k/?‚Äá[00:00\u0026lt;00:00,‚Äá841kB/s]"}},"cc9e7b0902e34f31ad21c8e51e8e1b5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb7ef3d3f7a44b38596c55922d2c6e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d037ac3a25b8476a92015ce9eaced768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfb7ef3d3f7a44b38596c55922d2c6e1","placeholder":"‚Äã","style":"IPY_MODEL_f797e31151c24865ab8f8f4e96b9b2ef","value":"vocabulary.txt:‚Äá"}},"dcc294979f4b4e7a9f1897df4a44b48e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_870fae2c32e2453fa29417b1bfa165f4","IPY_MODEL_408edecc69664acd9b254663b638a2e5","IPY_MODEL_6fea0cdbde7e49ecba0f6470312588e6"],"layout":"IPY_MODEL_aaafed1849274ae1a3fe54ff3de689aa"}},"dd328ec128b24d3daab62ba7c78588fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0ca711e228c40a98751406fb1157124":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9a08368bf444037980e0c566cf830b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed71409ac1ac42e283b6025d6b66f2ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efd0aa7a8af14fd89f1fb87fac81f517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a95e27901dd466e97f3fd0d5f3c7b11","placeholder":"‚Äã","style":"IPY_MODEL_ab64cd8e9f644db7843c971a4a2c7fef","value":"model.bin:‚Äá100%"}},"f4f40509a9174471858b9ce3b7a81867":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f60f1589300245c8bf114800278ec35e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f797e31151c24865ab8f8f4e96b9b2ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9fd825052994a10bf5258e6dbf64a35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e8e9ea2310045db8bdf4d345cf3cc6f","placeholder":"‚Äã","style":"IPY_MODEL_a0d0cab6871b44b186d342b3deb49ef8","value":"‚Äá2.13M/?‚Äá[00:00\u0026lt;00:00,‚Äá4.63MB/s]"}},"ff307f24f002427aaa186a2b9655498e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}