{"cells":[{"cell_type":"markdown","metadata":{"id":"ZPtFl4zAtkfW"},"source":["Cell 1 — Title & overview (Markdown)\n","# Primary Source Import Helper v3.3 (adapter-based)\n","\n","**Goal:** ingest many different *raw* sources (JSONL / CSV / TXT / directory JSON) and normalize them into a **single, consistent JSONL schema** that your KB index notebook can ingest.\n","\n","### Target record schema (per passage)\n","\n","```json\n","{\n","  \"tradition\": \"Islam\" | \"Christianity\",\n","  \"genre\": \"scripture\" | \"hadith\" | \"tafsir\" | \"commentary\" | \"creed\" | \"...\",\n","  \"source\": \"Quran (EN: semarketir/quranjson)\" | \"World English Bible\" | \"spa5k/tafsir_api\" | \"...\",\n","  \"collection\": \"Quran\" | \"World English Bible\" | \"Sahih al-Bukhari\" | \"Tafsīr Ibn Kathīr\" | \"Tafsīr al-Jalālayn\" | \"...\" ,\n","  \"book\": \"Al-Fatiha\" | \"Genesis\" | \"Bukhari\" | \"Ibn Kathir\" | \"...\",\n","  \"chapter\": 1,\n","  \"verse\": 1,\n","  \"number\": null,\n","  \"grade\": null,\n","  \"lang\": \"en\" | \"ar\",\n","  \"ref\": \"Friendly ref e.g. “Qur’an 2:255”, “John 3:16”, “Bukhari 1:1”\",\n","  \"text\": \"Passage text…\",\n","  \"group_key\": \"Stable key used to align parallels (e.g., quran-2-255, bible-John-3-16, hadith:bukhari:1:1)\"\n","}\n","\n","### Workflow\n","\n","Drop raw files under data/raw/kb/<tradition>/<collection>/..., or point to git-cloned folders.\n","\n","Add a config in SOURCES (below) with kind = \"jsonl\" | \"csv\" | \"txt\" | \"bible_dir\" | \"hadith_dir\".\n","\n","Run Convert all → normalized JSONLs in _normalized/.\n","\n","(Optional) Run the Tafsīr fetcher to pull per-āyah commentary into normalized JSONL.\n","\n","Run your KB ingest notebook to rebuild the FAISS KB."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1763416947859,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"ZpNWMDEotcof","outputId":"838a473a-015e-46f5-daae-da452426a529"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROOT: /content/drive/MyDrive/FATCR\n","RAW_ROOT: /content/drive/MyDrive/FATCR/data/raw/kb\n","NORM_DIR: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized\n"]}],"source":["\n","# Cell 2 — Paths & artefacts\n","\n","import os, json, re, csv, glob, time\n","from pathlib import Path\n","\n","# --- Project root (adjust if needed) ---\n","ROOT = os.environ.get(\"FACTR_ROOT\", \"/content/drive/MyDrive/FATCR\")\n","DATA_DIR = f\"{ROOT}/data\"\n","RAW_ROOT = f\"{DATA_DIR}/raw/kb\"\n","NORM_DIR = f\"{RAW_ROOT}/_normalized\"\n","os.makedirs(NORM_DIR, exist_ok=True)\n","\n","print(\"ROOT:\", ROOT)\n","print(\"RAW_ROOT:\", RAW_ROOT)\n","print(\"NORM_DIR:\", NORM_DIR)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"cTOzTYIqjCfi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7T_wZFPt7wL"},"source":["## Cell 3 — Small helpers (writer, cleaning, group keys)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"XCL4Y6W3tg0v","executionInfo":{"status":"ok","timestamp":1763416952347,"user_tz":0,"elapsed":5,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}}},"outputs":[],"source":["def _clean(s):\n","    import re\n","    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n","\n","def quran_key(chapter:int, verse:int):\n","    return f\"quran-{int(chapter)}-{int(verse)}\"\n","\n","def bible_key(book:str, chapter:int, verse:int):\n","    import re\n","    b = re.sub(r\"\\s+\", \"_\", str(book).strip())\n","    return f\"bible-{b}-{int(chapter)}-{int(verse)}\"\n","\n","def hadith_key(collection:str, book, number):\n","    import re\n","    c = re.sub(r\"\\s+\", \"_\", str(collection).lower())\n","    return f\"hadith:{c}:{book}:{number}\"\n","\n","def write_jsonl_line(path, rec: dict):\n","    \"\"\"Strict writer that enforces required keys (including 'collection').\"\"\"\n","    required = {\"tradition\",\"genre\",\"source\",\"collection\",\"lang\",\"book\",\"chapter\",\"verse\",\"number\",\"grade\",\"text\",\"ref\",\"group_key\"}\n","    missing = required - set(rec.keys())\n","    if missing:\n","        raise ValueError(f\"Record missing required keys: {sorted(missing)}\")\n","    if not rec.get(\"collection\"):\n","        raise ValueError(\"Record has empty 'collection'. Adapter must set it.\")\n","    with open(path, \"a\", encoding=\"utf-8\") as f:\n","        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"DaFaZkXFuAb2"},"source":["## Cell 4 — Adapters: JSONL pass-through / CSV / TXT folder"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"L90GIcHIuCYh","executionInfo":{"status":"ok","timestamp":1763416957660,"user_tz":0,"elapsed":14,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}}},"outputs":[],"source":["def convert_jsonl(in_path:str, out_path:str, fixed:dict, keymap:dict, group_key_fn, post=None):\n","    wrote = 0\n","    with open(out_path, \"w\", encoding=\"utf-8\"): pass\n","    with open(in_path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            if not line.strip(): continue\n","            raw = json.loads(line)\n","            rec = {\n","                \"tradition\": fixed[\"tradition\"],\n","                \"genre\": fixed[\"genre\"],\n","                \"source\": fixed[\"source\"],\n","                \"collection\": fixed[\"collection\"],\n","                \"lang\": fixed[\"lang\"],\n","                \"book\": raw.get(keymap.get(\"book\",\"book\")),\n","                \"chapter\": int(raw.get(keymap.get(\"chapter\",\"chapter\"), 1)),\n","                \"verse\": int(raw.get(keymap.get(\"verse\",\"verse\"), 1)),\n","                \"number\": raw.get(\"number\"),\n","                \"grade\": raw.get(\"grade\"),\n","                \"text\": _clean(raw.get(keymap.get(\"text\",\"text\"), \"\")),\n","                \"ref\": raw.get(keymap.get(\"ref\",\"ref\")) or \"\",\n","                \"group_key\": \"\"\n","            }\n","            rec[\"group_key\"] = group_key_fn(rec, raw)\n","            if post: rec = post(rec, raw)\n","            write_jsonl_line(out_path, rec); wrote += 1\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n","\n","def convert_csv(in_path:str, out_path:str, fixed:dict, colmap:dict, group_key_fn, post=None):\n","    wrote = 0\n","    with open(out_path, \"w\", encoding=\"utf-8\"): pass\n","    with open(in_path, encoding=\"utf-8\") as f:\n","        reader = csv.DictReader(f)\n","        for raw in reader:\n","            rec = {\n","                \"tradition\": fixed[\"tradition\"],\n","                \"genre\": fixed[\"genre\"],\n","                \"source\": fixed[\"source\"],\n","                \"collection\": fixed[\"collection\"],\n","                \"lang\": fixed[\"lang\"],\n","                \"book\": raw.get(colmap.get(\"book\",\"book\")),\n","                \"chapter\": int(raw.get(colmap.get(\"chapter\",\"chapter\"), 1)),\n","                \"verse\": int(raw.get(colmap.get(\"verse\",\"verse\"), 1)),\n","                \"number\": raw.get(colmap.get(\"number\",\"number\")),\n","                \"grade\": raw.get(colmap.get(\"grade\",\"grade\")),\n","                \"text\": _clean(raw.get(colmap.get(\"text\",\"text\"), \"\")),\n","                \"ref\": raw.get(colmap.get(\"ref\",\"ref\")) or \"\",\n","                \"group_key\": \"\"\n","            }\n","            rec[\"group_key\"] = group_key_fn(rec, raw)\n","            if post: rec = post(rec, raw)\n","            write_jsonl_line(out_path, rec); wrote += 1\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n","\n","def convert_txt_folder(in_dir:str, out_path:str, fixed:dict, lang=\"en\", per_file_book=None, post=None):\n","    wrote = 0\n","    with open(out_path, \"w\", encoding=\"utf-8\"): pass\n","    for p in sorted(Path(in_dir).glob(\"*.txt\")):\n","        book = per_file_book(p) if per_file_book else p.stem\n","        with open(p, encoding=\"utf-8\") as fh:\n","            for i, raw_line in enumerate(fh, 1):\n","                t = _clean(raw_line)\n","                if not t: continue\n","                rec = {\n","                    \"tradition\": fixed[\"tradition\"],\n","                    \"genre\": fixed[\"genre\"],\n","                    \"source\": fixed[\"source\"],\n","                    \"collection\": fixed[\"collection\"],\n","                    \"lang\": lang,\n","                    \"book\": book,\n","                    \"chapter\": 1,\n","                    \"verse\": i,\n","                    \"number\": None,\n","                    \"grade\": None,\n","                    \"text\": t,\n","                    \"ref\": f\"{book} line {i}\",\n","                    \"group_key\": f\"txt-{book}-{i}\"\n","                }\n","                if post: rec = post(rec, None)\n","                write_jsonl_line(out_path, rec); wrote += 1\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n"]},{"cell_type":"markdown","metadata":{"id":"NoL3IXoXuE4K"},"source":["## Cell 5 — Bible directory adapter (WEB JSON books)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"42Ign3kCuGrY","executionInfo":{"status":"ok","timestamp":1763416963676,"user_tz":0,"elapsed":3,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}}},"outputs":[],"source":["def _iter_bible_from_obj(obj):\n","    \"\"\"\n","    Tries common shapes:\n","    A) {\"book\":\"Genesis\",\"chapters\":[{\"chapter\":1,\"verses\":[{\"verse\":1,\"text\":\"...\"}]}]}\n","    B) {\"chapters\": [{\"1\": {\"1\":\"text\", \"2\":\"text\", ...}}, ...]}\n","    C) {\"1\": {\"1\":\"text\", ...}, \"2\": {...}}  # direct map chapter -> verse map\n","    \"\"\"\n","    # A or B\n","    if isinstance(obj, dict) and \"chapters\" in obj:\n","        chs = obj[\"chapters\"]\n","        if isinstance(chs, list):\n","            for ch in chs:\n","                cnum = ch.get(\"chapter\")\n","                verses = ch.get(\"verses\")\n","                if isinstance(verses, list):\n","                    for it in verses:\n","                        v = it.get(\"verse\")\n","                        txt = it.get(\"text\") or it.get(\"content\") or \"\"\n","                        if cnum and v:\n","                            yield int(cnum), int(v), _clean(txt)\n","                elif isinstance(verses, dict):\n","                    for vk, tv in verses.items():\n","                        try: v = int(vk)\n","                        except: continue\n","                        txt = tv if isinstance(tv, str) else (tv.get(\"text\") if isinstance(tv, dict) else str(tv))\n","                        yield int(cnum), v, _clean(txt)\n","        elif isinstance(chs, dict):\n","            for ck, vdict in chs.items():\n","                try: c = int(ck)\n","                except: continue\n","                if isinstance(vdict, dict):\n","                    for vk, tv in vdict.items():\n","                        try: v = int(vk)\n","                        except: continue\n","                        txt = tv if isinstance(tv, str) else (tv.get(\"text\") if isinstance(tv, dict) else str(tv))\n","                        yield c, v, _clean(txt)\n","    # C\n","    elif isinstance(obj, dict):\n","        for ck, vdict in obj.items():\n","            try: c = int(ck)\n","            except: continue\n","            if isinstance(vdict, dict):\n","                for vk, tv in vdict.items():\n","                    try: v = int(vk)\n","                    except: continue\n","                    txt = tv if isinstance(tv, str) else (tv.get(\"text\") if isinstance(tv, dict) else str(tv))\n","                    yield c, v, _clean(txt)\n","\n","def convert_bible_dir(in_dir:str, out_path:str, fixed:dict, post=None):\n","    wrote = 0\n","    with open(out_path, \"w\", encoding=\"utf-8\"): pass\n","    for p in sorted(Path(in_dir).glob(\"*.json\")):\n","        try:\n","            obj = json.loads(Path(p).read_text(encoding=\"utf-8\"))\n","        except Exception as e:\n","            print(\"Skipping\", p, \"(\", e, \")\")\n","            continue\n","        book = obj.get(\"book\") or p.stem\n","        for c, v, txt in _iter_bible_from_obj(obj):\n","            rec = {\n","                \"tradition\": fixed[\"tradition\"],\n","                \"genre\": fixed[\"genre\"],\n","                \"source\": fixed[\"source\"],\n","                \"collection\": fixed[\"collection\"],\n","                \"lang\": fixed[\"lang\"],\n","                \"book\": book,\n","                \"chapter\": int(c),\n","                \"verse\": int(v),\n","                \"number\": None,\n","                \"grade\": None,\n","                \"text\": txt,\n","                \"ref\": f\"{book} {c}:{v}\",\n","                \"group_key\": bible_key(book, c, v)\n","            }\n","            if post: rec = post(rec, None)\n","            write_jsonl_line(out_path, rec); wrote += 1\n","        print(f\"{Path(p).name}: +{wrote}\")\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n"]},{"cell_type":"markdown","metadata":{"id":"qViRhnNguKMw"},"source":["## Cell 6 — Hadith directory adapter (AhmedBaset/hadith-json)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_0YfAChMuLls","executionInfo":{"status":"ok","timestamp":1763416970292,"user_tz":0,"elapsed":16,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}}},"outputs":[],"source":["def _extract_hadith_text(d):\n","    # Best-effort: prefer English, fall back to other fields\n","    for k in (\"english\",\"hadith_en\",\"hadith\",\"text_en\",\"text\"):\n","        if k in d and d[k]:\n","            return _clean(d[k])\n","    if \"text\" in d and isinstance(d[\"text\"], dict):\n","        for k in (\"en\",\"english\",\"arabic\"):\n","            if k in d[\"text\"] and d[\"text\"][k]:\n","                return _clean(d[\"text\"][k])\n","    return \"\"\n","\n","def convert_hadith_dir(in_dir:str, out_path:str, fixed:dict, collection_name_mapper=None):\n","    \"\"\"\n","    Expects JSON files containing lists of hadith dicts for each book/collection.\n","    We try to read: book, number/hadithNo, grade when present.\n","    \"\"\"\n","    wrote = 0\n","    with open(out_path, \"w\", encoding=\"utf-8\"): pass\n","\n","    for p in sorted(Path(in_dir).glob(\"*.json\")):\n","        try:\n","            arr = json.loads(Path(p).read_text(encoding=\"utf-8\"))\n","        except Exception as e:\n","            print(\"Skipping\", p, \"(\", e, \")\")\n","            continue\n","\n","        # Derive collection from filename (or mapper)\n","        coll = p.stem\n","        if collection_name_mapper:\n","            coll = collection_name_mapper(coll)\n","\n","        for d in arr if isinstance(arr, list) else []:\n","            book = d.get(\"book\") or d.get(\"book_number\") or 1\n","            number = d.get(\"hadithnumber\") or d.get(\"hadithNo\") or d.get(\"number\") or d.get(\"id\")\n","            grade = d.get(\"grade\") or d.get(\"grading\") or (d.get(\"metadata\",{}).get(\"grade\") if isinstance(d.get(\"metadata\"), dict) else None)\n","            text = _extract_hadith_text(d)\n","\n","            try: book_i = int(book)\n","            except: book_i = 1\n","            try: num_i = int(number) if number is not None else None\n","            except: num_i = None\n","\n","            rec = {\n","                \"tradition\": fixed[\"tradition\"],\n","                \"genre\": \"hadith\",\n","                \"source\": fixed[\"source\"],\n","                \"collection\": coll or fixed[\"collection\"],\n","                \"lang\": fixed[\"lang\"],\n","                \"book\": str(book),\n","                \"chapter\": 1,\n","                \"verse\": 1,\n","                \"number\": num_i,\n","                \"grade\": grade,\n","                \"text\": text,\n","                \"ref\": f\"{coll} {book}:{num_i}\" if num_i else f\"{coll} {book}\",\n","                \"group_key\": hadith_key(coll, book_i, num_i or 0)\n","            }\n","            write_jsonl_line(out_path, rec); wrote += 1\n","        print(f\"{Path(p).name}: +{wrote}\")\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n"]},{"cell_type":"markdown","metadata":{"id":"IDNmpPZ2uNt6"},"source":["## Cell 7 — Tafsīr fetcher (spa5k/tafsir_api → normalized JSONL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oftUHet_7mOY"},"outputs":[],"source":["# --- Improved Tafsir fetcher: tries multiple URL layouts & JSON shapes ---\n","import requests, time\n","\n","SURAH_LENGTHS = {\n","  1:7,2:286,3:200,4:176,5:120,6:165,7:206,8:75,9:129,10:109,11:123,12:111,13:43,14:52,15:99,16:128,17:111,18:110,19:98,20:135,\n","  21:112,22:78,23:118,24:64,25:77,26:227,27:93,28:88,29:69,30:60,31:34,32:30,33:73,34:54,35:45,36:83,37:182,38:88,39:75,40:85,\n","  41:54,42:53,43:89,44:59,45:37,46:35,47:38,48:29,49:18,50:45,51:60,52:49,53:62,54:55,55:78,56:96,57:29,58:22,59:24,60:13,61:14,\n","  62:11,63:11,64:18,65:12,66:12,67:30,68:52,69:52,70:44,71:28,72:28,73:20,74:56,75:40,76:31,77:50,78:40,79:46,80:42,81:29,82:19,\n","  83:36,84:25,85:22,86:17,87:19,88:26,89:30,90:20,91:15,92:21,93:11,94:8,95:8,96:19,97:5,98:8,99:8,100:11,101:11,102:8,103:3,\n","  104:9,105:5,106:4,107:7,108:3,109:6,110:3,111:5,112:4,113:5,114:6\n","}\n","\n","TAFSIR_EDITIONS = {\n","    # keep these codes; we’ll discover layout automatically\n","    \"en-tafsir-ibn-kathir\": {\"collection\":\"Tafsīr Ibn Kathīr\", \"slug\":\"en-tafsir-ibn-kathir\"},\n","    \"en-al-jalalayn\":      {\"collection\":\"Tafsīr al-Jalālayn\", \"slug\":\"en-al-jalalayn\"},\n","}\n","\n","def normalize_record(rec: dict) -> dict:\n","    required = {\"tradition\",\"genre\",\"source\",\"collection\",\"lang\",\"book\",\n","                \"chapter\",\"verse\",\"number\",\"grade\",\"text\",\"ref\",\"group_key\"}\n","    for k in required:\n","        rec.setdefault(k, None)\n","    return rec\n","\n","def _candidate_urls(base, slug, s, a):\n","    # try most common layouts (both raw GitHub and jsDelivr)\n","    return [\n","        f\"{base}/{slug}/{s}/{a}.json\",         # per-ayah JSON\n","        f\"{base}/{slug}/{s}.json\",             # per-surah JSON\n","        f\"{base}/en/{slug}/{s}/{a}.json\",      # extra en/ level\n","        f\"{base}/en/{slug}/{s}.json\",\n","        # jsDelivr fallbacks (comment out if you keep seeing 403s)\n","        f\"https://cdn.jsdelivr.net/gh/spa5k/tafsir_api@main/tafsir/{slug}/{s}/{a}.json\",\n","        f\"https://cdn.jsdelivr.net/gh/spa5k/tafsir_api@main/tafsir/{slug}/{s}.json\",\n","        f\"https://cdn.jsdelivr.net/gh/spa5k/tafsir_api@main/tafsir/en/{slug}/{s}/{a}.json\",\n","        f\"https://cdn.jsdelivr.net/gh/spa5k/tafsir_api@main/tafsir/en/{slug}/{s}.json\",\n","    ]\n","\n","def _extract_ayah_text_from_obj(obj, ayah_number):\n","    \"\"\"\n","    Given a JSON object, pull text for one ayah.\n","    Handles:\n","      - direct string\n","      - {'text': '...'}\n","      - {'ayahs': {'1': '...', '2': '...'}} or list-like\n","    \"\"\"\n","    if isinstance(obj, str):\n","        return obj\n","    if isinstance(obj, dict):\n","        # direct text\n","        if \"text\" in obj and isinstance(obj[\"text\"], (str,)):\n","            return obj[\"text\"]\n","        # nested ayahs map/dict\n","        if \"ayahs\" in obj:\n","            ayahs = obj[\"ayahs\"]\n","            if isinstance(ayahs, dict):\n","                v = ayahs.get(str(ayah_number)) or ayahs.get(ayah_number)\n","                if isinstance(v, str):\n","                    return v\n","                if isinstance(v, dict) and \"text\" in v:\n","                    return v[\"text\"]\n","            elif isinstance(ayahs, list):\n","                idx = ayah_number-1\n","                if 0 <= idx < len(ayahs):\n","                    v = ayahs[idx]\n","                    if isinstance(v, str):\n","                        return v\n","                    if isinstance(v, dict) and \"text\" in v:\n","                        return v[\"text\"]\n","        # maybe chapter dict: {'1': '...', '2': '...'}\n","        v = obj.get(str(ayah_number))\n","        if isinstance(v, str):\n","            return v\n","        if isinstance(v, dict) and \"text\" in v:\n","            return v[\"text\"]\n","    return None\n","\n","def fetch_tafsir_edition(\n","    code: str,\n","    out_path: str,\n","    fixed_meta: dict,\n","    start_surah=1,\n","    end_surah=114,\n","    sleep=0.0,\n","    verbose_probe=True\n","):\n","    \"\"\"\n","    Tries several directory layouts; supports per-ayah JSON and per-surah JSON.\n","    Uses raw.githubusercontent.com first (usually fewer 403s).\n","    \"\"\"\n","    if code not in TAFSIR_EDITIONS:\n","        raise ValueError(f\"Unknown tafsir edition code: {code}\")\n","    info = TAFSIR_EDITIONS[code]\n","    collection = info[\"collection\"]\n","    slug = info[\"slug\"]\n","\n","    with open(out_path, \"w\", encoding=\"utf-8\"):\n","        pass\n","\n","    base_raw = \"https://raw.githubusercontent.com/spa5k/tafsir_api/main/tafsir\"\n","\n","    wrote = 0\n","    chosen_layout = None  # remember which URL pattern worked first\n","\n","    for s in range(start_surah, end_surah+1):\n","        length = SURAH_LENGTHS.get(s, 0)\n","        if length <= 0:\n","            if s == start_surah:\n","                print(f\"{code} s{s}: unknown length — skipping\")\n","            continue\n","\n","        # If we haven’t identified a working layout yet, probe ayah 1\n","        if chosen_layout is None:\n","            for url in _candidate_urls(base_raw, slug, s, 1):\n","                try:\n","                    r = requests.get(url, timeout=15)\n","                except requests.exceptions.RequestException:\n","                    continue\n","                if r.status_code == 200:\n","                    chosen_layout = url.replace(str(s) + (\"/1.json\" if url.endswith(\"/1.json\") else \".json\"), \"{surah}{tail}\")\n","                    if verbose_probe:\n","                        print(f\"{code}: using layout like -> {url}\")\n","                    break\n","            if chosen_layout is None:\n","                # couldn't find a layout; continue to next surah\n","                print(f\"{code} s{s}: no working layout (404s); continuing\")\n","                continue\n","\n","        # Now fetch content using the chosen pattern\n","        # If the chosen URL was per-ayah, we keep per-ayah; if it was per-surah,\n","        # we reuse that pattern and then pick ayahs from the blob.\n","        is_per_ayah = chosen_layout.endswith(\"{surah}/1.json{tail}\") or \"/{tail}\" in chosen_layout\n","\n","        # Build surah JSON if per-surah\n","        surah_blob = None\n","        if not is_per_ayah:\n","            surah_url = chosen_layout.format(surah=str(s), tail=\"\")\n","            try:\n","                rs = requests.get(surah_url, timeout=20)\n","                if rs.status_code == 200:\n","                    surah_blob = rs.json()\n","                else:\n","                    if s == start_surah:\n","                        print(f\"{code} s{s}: per-surah fetch got {rs.status_code}\")\n","                    # skip this surah\n","                    continue\n","            except Exception as e:\n","                if s == start_surah:\n","                    print(f\"{code} s{s}: per-surah error {e}\")\n","                continue\n","\n","        # Iterate ayahs\n","        for a in range(1, length+1):\n","            text = None\n","            if is_per_ayah:\n","                ayah_url = chosen_layout.format(surah=str(s), tail=\"\").replace(\"1.json\", f\"{a}.json\")\n","                try:\n","                    ra = requests.get(ayah_url, timeout=15)\n","                    if ra.status_code == 200:\n","                        obj = ra.json()\n","                        # Accept 'text' directly or dict with 'text'\n","                        if isinstance(obj, str):\n","                            text = obj\n","                        elif isinstance(obj, dict):\n","                            text = obj.get(\"text\")\n","                            if text is None:\n","                                # some files might wrap in {'data': {...}}\n","                                if \"data\" in obj and isinstance(obj[\"data\"], dict):\n","                                    text = obj[\"data\"].get(\"text\")\n","                    else:\n","                        # If some ayah files are missing, we just skip\n","                        continue\n","                except Exception:\n","                    continue\n","            else:\n","                # per-surah blob\n","                text = _extract_ayah_text_from_obj(surah_blob, a)\n","\n","            if not text:\n","                continue\n","\n","            rec = {\n","                \"tradition\": fixed_meta.get(\"tradition\", \"Islam\"),\n","                \"genre\": \"tafsir\",\n","                \"source\": fixed_meta.get(\"source\", \"spa5k/tafsir_api\"),\n","                \"collection\": collection,\n","                \"lang\": fixed_meta.get(\"lang\", \"en\"),\n","                \"book\": collection,\n","                \"chapter\": s,\n","                \"verse\": a,\n","                \"number\": None,\n","                \"grade\": None,\n","                \"text\": _clean(text),\n","                \"ref\": f\"{collection} on Qur’an {s}:{a}\",\n","                \"group_key\": quran_key(s, a)\n","            }\n","            rec = normalize_record(rec)\n","            write_jsonl_line(out_path, rec)\n","            wrote += 1\n","\n","        if sleep:\n","            time.sleep(sleep)\n","\n","    print(f\"✅ Wrote {out_path} | rows: {wrote}\")\n"]},{"cell_type":"markdown","metadata":{"id":"pb5aJJ9MuUK4"},"source":["Cell 8 — Configure SOURCES (toggle by uncommenting)bold text"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1763416984564,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"za5MwuPxuWiQ","outputId":"5ef9444b-c0be-4d63-f7e1-a419d331abad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configured sources: ['quran_en', 'quran_ar', 'bible_web_en_dir', 'hadith_the9_dir']\n"]}],"source":["# Enable/disable by (un)commenting. Paths assume you've placed raw data under RAW_ROOT.\n","\n","SOURCES = [\n","    # Example: Qur'an EN pass-through JSONL (already normalized elsewhere)\n","    {\n","      \"name\": \"quran_en\",\n","      \"kind\": \"jsonl\",\n","      \"in\":  f\"{RAW_ROOT}/Islam/Quran/quran_en_semarketir.jsonl\",\n","      \"out\": f\"{NORM_DIR}/quran_en.jsonl\",\n","      \"fixed\": {\n","          \"tradition\":\"Islam\",\"genre\":\"scripture\",\"source\":\"Quran (EN: semarketir/quranjson)\",\n","          \"collection\":\"Quran\",\"lang\":\"en\"\n","      },\n","      \"keymap\": {\"book\":\"book\",\"chapter\":\"chapter\",\"verse\":\"verse\",\"text\":\"text\",\"ref\":\"ref\"},\n","      \"group_key_fn\": lambda rec, raw: quran_key(rec[\"chapter\"], rec[\"verse\"]),\n","    },\n","\n","    # Example: Qur'an AR pass-through JSONL\n","    {\n","      \"name\": \"quran_ar\",\n","      \"kind\": \"jsonl\",\n","      \"in\":  f\"{RAW_ROOT}/Islam/Quran/quran_ar_semarketir.jsonl\",\n","      \"out\": f\"{NORM_DIR}/quran_ar.jsonl\",\n","      \"fixed\": {\n","          \"tradition\":\"Islam\",\"genre\":\"scripture\",\"source\":\"Quran (AR)\",\n","          \"collection\":\"Quran\",\"lang\":\"ar\"\n","      },\n","      \"keymap\": {\"book\":\"book\",\"chapter\":\"chapter\",\"verse\":\"verse\",\"text\":\"text\",\"ref\":\"ref\"},\n","      \"group_key_fn\": lambda rec, raw: quran_key(rec[\"chapter\"], rec[\"verse\"]),\n","    },\n","\n","    # Example: Bible (WEB) book JSONs in a directory\n","    {\n","      \"name\": \"bible_web_en_dir\",\n","      \"kind\": \"bible_dir\",\n","      \"in\":  f\"{RAW_ROOT}/Christianity/Bible/WEB\",  # folder of *.json from TehShrike/world-english-bible\n","      \"out\": f\"{NORM_DIR}/bible_web_en.jsonl\",\n","      \"fixed\": {\n","          \"tradition\":\"Christianity\",\"genre\":\"scripture\",\"source\":\"World English Bible\",\n","          \"collection\":\"World English Bible\",\"lang\":\"en\"\n","      }\n","    },\n","\n","    # Example: Hadith directory (AhmedBaset/hadith-json) - set path to the_9_books\n","    {\n","      \"name\": \"hadith_the9_dir\",\n","      \"kind\": \"hadith_dir\",\n","      \"in\":  f\"{RAW_ROOT}/Islam/Hadith/the_9_books\",  # folder of collection files\n","      \"out\": f\"{NORM_DIR}/hadith_9books_en.jsonl\",\n","      \"fixed\": {\n","          \"tradition\":\"Islam\",\"genre\":\"hadith\",\"source\":\"AhmedBaset/hadith-json\",\n","          \"collection\":\"\", \"lang\":\"en\"\n","      }\n","    },\n","]\n","print(\"Configured sources:\", [s[\"name\"] for s in SOURCES])"]},{"cell_type":"markdown","source":["Cell 7a — Build WEB JSON (run once, before your current “Cell 7b”)\n","\n","Place this right before your existing WEB importer cell."],"metadata":{"id":"dH0ul4QLOb2W"}},{"cell_type":"markdown","source":["A) World English Bible (WEB) → bible_web_en.jsonl (handles JSON or USFM/TXT)\n","\n","Put this as a single new cell. It scans the WEB repo for *.json and *.usfm/*.txt, parses either format, and writes a unified JSONL.\n","It also reads your existing KJV JSONL to copy the same group_key book slugs, so WEB and KJV align perfectly."],"metadata":{"id":"x1AaxCiIGQDX"}},{"cell_type":"code","source":["# Cell — Bible (WEB) adapter (robust) → normalized JSONL\n","# Handles:\n","#  (A) {\"book\": \"...\", \"chapters\": {\"1\": {\"1\":\"...\", ...}, \"2\": {...}}}\n","#  (B) {\"book\": \"...\", \"chapters\": [{\"chapter\":1, \"verses\": {... or [...] }}, ...]}\n","#  (C) [ {\"chapter\":1,\"verse\":1,\"text\":\"...\"}, {\"chapter\":1,\"verse\":2,\"text\":\"...\"} , ... ]\n","\n","import os, json, re\n","from pathlib import Path\n","\n","# ---- Paths (keep consistent) ----\n","ROOT = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT = f\"{ROOT}/data/raw/kb\"\n","NORM_DIR = f\"{RAW_ROOT}/_normalized\"\n","WEB_IN   = f\"{RAW_ROOT}/Christianity/Bible/web/json\"   # where 1chronicles.json etc live\n","WEB_OUT  = f\"{NORM_DIR}/bible_web_en.jsonl\"\n","os.makedirs(NORM_DIR, exist_ok=True)\n","\n","# ---- Helpers ----\n","def _clean(s: str) -> str:\n","    return re.sub(r\"\\s+\", \" \", str(s or \"\")).strip()\n","\n","def _strip_tags(s: str) -> str:\n","    return re.sub(r\"<[^>]+>\", \"\", s or \"\")\n","\n","def _int_or_none(x):\n","    try:\n","        return int(x)\n","    except:\n","        return None\n","\n","def _friendly_book_from_stem(stem: str) -> str:\n","    st = stem.lower().replace(\"-\", \"\")\n","    m = re.match(r\"^([123])?(.*)$\", st)\n","    num, rest = m.groups() if m else (None, st)\n","    words = re.findall(r\"[a-z]+\", rest)\n","    title = \" \".join(w.capitalize() for w in words).strip() or stem\n","    return (num + \" \" + title).strip() if num else title\n","\n","def _emit(rows, book, ch, v, txt, fixed_meta):\n","    rows.append({\n","        **fixed_meta,\n","        \"book\": book,\n","        \"chapter\": int(ch),\n","        \"verse\": int(v),\n","        \"number\": None,\n","        \"grade\": None,\n","        \"text\": _clean(txt),\n","        \"ref\": f\"{book} {ch}:{v}\",\n","        \"group_key\": f\"bible-{book}-{int(ch)}-{int(v)}\",\n","    })\n","\n","fixed_meta_web = {\n","    \"tradition\": \"Christianity\",\n","    \"genre\": \"scripture\",\n","    \"source\": \"World English Bible (TehShrike/world-english-bible)\",\n","    \"collection\": \"Bible\",\n","    \"lang\": \"en\",\n","}\n","\n","pdir = Path(WEB_IN)\n","assert pdir.is_dir(), f\"WEB folder not found: {WEB_IN}\"\n","\n","files = sorted([p for p in pdir.glob(\"*.json\") if p.is_file()], key=lambda p: p.name.lower())\n","print(f\"WEB: scanning {len(files)} JSON files in {WEB_IN}\")\n","\n","rows = []\n","for i, f in enumerate(files, start=1):\n","    try:\n","        obj = json.loads(f.read_text(encoding=\"utf-8\"))\n","    except Exception as e:\n","        print(f\"  {i:2d}/{len(files)} {f.name}: JSON parse error → {e}\")\n","        continue\n","\n","    # Determine book name\n","    book = None\n","    if isinstance(obj, dict):\n","        book = obj.get(\"book\")\n","    if not book:\n","        book = _friendly_book_from_stem(f.stem)\n","\n","    added = 0\n","\n","    # ---------- Shape A: chapters as dict of dicts ----------\n","    if isinstance(obj, dict) and isinstance(obj.get(\"chapters\"), dict):\n","        for ch_k, ch_val in obj[\"chapters\"].items():\n","            ch = _int_or_none(ch_k)\n","            if ch is None:\n","                continue\n","            # verses may be dict {\"1\": \"In the beginning...\"} or list [\"v1\",\"v2\",...]\n","            if isinstance(ch_val, dict):\n","                for v_k, v_val in ch_val.items():\n","                    v = _int_or_none(v_k)\n","                    if v is None:\n","                        continue\n","                    if isinstance(v_val, str):\n","                        txt = v_val\n","                    elif isinstance(v_val, dict):\n","                        txt = v_val.get(\"text\") or v_val.get(\"content\") or json.dumps(v_val, ensure_ascii=False)\n","                    else:\n","                        txt = str(v_val)\n","                    _emit(rows, book, ch, v, _strip_tags(txt), fixed_meta_web); added += 1\n","            elif isinstance(ch_val, list):\n","                for idx, v_val in enumerate(ch_val, start=1):\n","                    txt = v_val if isinstance(v_val, str) else (v_val.get(\"text\") if isinstance(v_val, dict) else str(v_val))\n","                    _emit(rows, book, ch, idx, _strip_tags(txt), fixed_meta_web); added += 1\n","\n","    # ---------- Shape B: chapters as list of chapter objects ----------\n","    elif isinstance(obj, dict) and isinstance(obj.get(\"chapters\"), list):\n","        for ch_obj in obj[\"chapters\"]:\n","            if not isinstance(ch_obj, dict):\n","                continue\n","            ch = _int_or_none(ch_obj.get(\"chapter\") or ch_obj.get(\"chapterNumber\"))\n","            if ch is None:\n","                continue\n","            verses = ch_obj.get(\"verses\") or ch_obj.get(\"data\") or ch_obj.get(\"items\")\n","            if isinstance(verses, dict):\n","                for v_k, v_val in verses.items():\n","                    v = _int_or_none(v_k)\n","                    if v is None:\n","                        continue\n","                    txt = v_val if isinstance(v_val, str) else (v_val.get(\"text\") if isinstance(v_val, dict) else str(v_val))\n","                    _emit(rows, book, ch, v, _strip_tags(txt), fixed_meta_web); added += 1\n","            elif isinstance(verses, list):\n","                for idx, v_val in enumerate(verses, start=1):\n","                    txt = v_val if isinstance(v_val, str) else (v_val.get(\"text\") if isinstance(v_val, dict) else str(v_val))\n","                    _emit(rows, book, ch, idx, _strip_tags(txt), fixed_meta_web); added += 1\n","\n","    # ---------- Shape C: top-level list of verse objects ----------\n","    elif isinstance(obj, list):\n","        for rec in obj:\n","            if not isinstance(rec, dict):\n","                continue\n","            ch = _int_or_none(rec.get(\"chapter\") or rec.get(\"chapterNumber\") or rec.get(\"c\"))\n","            v  = _int_or_none(rec.get(\"verse\")   or rec.get(\"verseNumber\")   or rec.get(\"v\"))\n","            if ch is None or v is None:\n","                continue\n","            txt = rec.get(\"text\") or rec.get(\"content\") or rec.get(\"t\") or json.dumps({k:rec[k] for k in rec if k not in (\"chapter\",\"verse\")}, ensure_ascii=False)\n","            _emit(rows, book, ch, v, _strip_tags(txt), fixed_meta_web); added += 1\n","\n","    print(f\"  {i:2d}/{len(files)} {f.name}: +{added}\")\n","\n","# ---- Write JSONL ----\n","with open(WEB_OUT, \"w\", encoding=\"utf-8\") as fo:\n","    for r in rows:\n","        fo.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","print(f\"\\n✅ Wrote {WEB_OUT} | rows: {len(rows)}\")\n","\n","# Quick preview\n","try:\n","    with open(WEB_OUT, \"r\", encoding=\"utf-8\") as f:\n","        for _ in range(3):\n","            line = f.readline().strip()\n","            if not line: break\n","            print(\"Sample:\", line[:180], \"…\")\n","except Exception as e:\n","    print(\"Preview error:\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KH3od7Jfay2P","executionInfo":{"status":"ok","timestamp":1762470350543,"user_tz":0,"elapsed":3073,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"30aa91f0-783a-492d-b52c-cd639e3a54cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WEB: scanning 66 JSON files in /content/drive/MyDrive/FATCR/data/raw/kb/Christianity/Bible/web/json\n","   1/66 1chronicles.json: +985\n","   2/66 1corinthians.json: +444\n","   3/66 1john.json: +108\n","   4/66 1kings.json: +856\n","   5/66 1peter.json: +123\n","   6/66 1samuel.json: +910\n","   7/66 1thessalonians.json: +90\n","   8/66 1timothy.json: +120\n","   9/66 2chronicles.json: +838\n","  10/66 2corinthians.json: +268\n","  11/66 2john.json: +13\n","  12/66 2kings.json: +787\n","  13/66 2peter.json: +61\n","  14/66 2samuel.json: +849\n","  15/66 2thessalonians.json: +47\n","  16/66 2timothy.json: +91\n","  17/66 3john.json: +14\n","  18/66 acts.json: +1088\n","  19/66 amos.json: +420\n","  20/66 colossians.json: +95\n","  21/66 daniel.json: +406\n","  22/66 deuteronomy.json: +1164\n","  23/66 ecclesiastes.json: +298\n","  24/66 ephesians.json: +158\n","  25/66 esther.json: +172\n","  26/66 exodus.json: +1264\n","  27/66 ezekiel.json: +1682\n","  28/66 ezra.json: +295\n","  29/66 galatians.json: +152\n","  30/66 genesis.json: +1716\n","  31/66 habakkuk.json: +102\n","  32/66 haggai.json: +40\n","  33/66 hebrews.json: +377\n","  34/66 hosea.json: +630\n","  35/66 isaiah.json: +3492\n","  36/66 james.json: +108\n","  37/66 jeremiah.json: +2984\n","  38/66 job.json: +2319\n","  39/66 joel.json: +262\n","  40/66 john.json: +940\n","  41/66 jonah.json: +66\n","  42/66 joshua.json: +683\n","  43/66 jude.json: +25\n","  44/66 judges.json: +727\n","  45/66 lamentations.json: +549\n","  46/66 leviticus.json: +872\n","  47/66 luke.json: +1251\n","  48/66 malachi.json: +57\n","  49/66 mark.json: +716\n","  50/66 matthew.json: +1178\n","  51/66 micah.json: +385\n","  52/66 nahum.json: +47\n","  53/66 nehemiah.json: +422\n","  54/66 numbers.json: +1434\n","  55/66 obadiah.json: +21\n","  56/66 philemon.json: +25\n","  57/66 philippians.json: +105\n","  58/66 proverbs.json: +1973\n","  59/66 psalms.json: +5727\n","  60/66 revelation.json: +438\n","  61/66 romans.json: +492\n","  62/66 ruth.json: +93\n","  63/66 songofsolomon.json: +387\n","  64/66 titus.json: +46\n","  65/66 zechariah.json: +327\n","  66/66 zephaniah.json: +53\n","\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/bible_web_en.jsonl | rows: 44867\n","Sample: {\"tradition\": \"Christianity\", \"genre\": \"scripture\", \"source\": \"World English Bible (TehShrike/world-english-bible)\", \"collection\": \"Bible\", \"lang\": \"en\", \"book\": \"1 Chronicles\", \"c …\n","Sample: {\"tradition\": \"Christianity\", \"genre\": \"scripture\", \"source\": \"World English Bible (TehShrike/world-english-bible)\", \"collection\": \"Bible\", \"lang\": \"en\", \"book\": \"1 Chronicles\", \"c …\n","Sample: {\"tradition\": \"Christianity\", \"genre\": \"scripture\", \"source\": \"World English Bible (TehShrike/world-english-bible)\", \"collection\": \"Bible\", \"lang\": \"en\", \"book\": \"1 Chronicles\", \"c …\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"wwfYnhWsdjF9"}},{"cell_type":"markdown","source":["1) Compact WEB to one row per verse"],"metadata":{"id":"o7ZrCr4NdFuR"}},{"cell_type":"code","source":["# Cell — Compact Bible (WEB) to one row per (book, chapter, verse)\n","\n","import os, json\n","from collections import defaultdict\n","\n","ROOT = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT = f\"{ROOT}/data/raw/kb\"\n","NORM_DIR = f\"{RAW_ROOT}/_normalized\"\n","\n","INP = f\"{NORM_DIR}/bible_web_en.jsonl\"\n","OUT = f\"{NORM_DIR}/bible_web_en_compact.jsonl\"\n","\n","def clean(s):\n","    return \" \".join((s or \"\").split())\n","\n","buckets = defaultdict(list)\n","meta_example = None\n","\n","with open(INP, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        r = json.loads(line)\n","        # keep a sample of meta fields\n","        if meta_example is None:\n","            meta_example = {k: r.get(k) for k in (\"tradition\",\"genre\",\"source\",\"collection\",\"lang\")}\n","        key = (r[\"book\"], int(r[\"chapter\"]), int(r[\"verse\"]))\n","        txt = clean(r.get(\"text\",\"\"))\n","        if txt:\n","            buckets[key].append(txt)\n","\n","rows = []\n","for (book,ch,v), parts in buckets.items():\n","    text = clean(\" \".join(parts))\n","    if not text:\n","        continue\n","    rows.append({\n","        **(meta_example or {}),\n","        \"book\": book,\n","        \"chapter\": ch,\n","        \"verse\": v,\n","        \"number\": None,\n","        \"grade\": None,\n","        \"text\": text,\n","        \"ref\": f\"{book} {ch}:{v}\",\n","        \"group_key\": f\"bible-{book}-{ch}-{v}\",\n","    })\n","\n","rows.sort(key=lambda r: (r[\"book\"], r[\"chapter\"], r[\"verse\"]))\n","\n","with open(OUT, \"w\", encoding=\"utf-8\") as fo:\n","    for r in rows:\n","        fo.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","\n","print(f\"✅ Compacted → {OUT} | rows: {len(rows)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4YcX8uLdDkF","executionInfo":{"status":"ok","timestamp":1762470951601,"user_tz":0,"elapsed":2232,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"8413c4db-8efe-43df-ef7f-8d7a44a93c30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Compacted → /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/bible_web_en_compact.jsonl | rows: 31216\n"]}]},{"cell_type":"markdown","source":["B) English “Nine Books” → hadith_9books_en.jsonl (only if you have an English source)\n","\n","Your current source (AhmedBaset/hadith-json) is Arabic. That’s why hadith_9books_en.jsonl is empty. If you provide a compatible English set (same per-book JSON shape, or a parallel folder containing English text), the adapter below will pick it up.\n","\n","Put this as a new cell. It searches for any “en” folders under your nine-books tree. If found, it writes hadith_9books_en.jsonl. If not, it prints a clear message and leaves the file alone."],"metadata":{"id":"P-j35kR6Gspd"}},{"cell_type":"code","source":["import json, itertools, glob, os\n","for p in sorted(glob.glob(f\"{NORM_DIR}/hadith_9books_*.jsonl\")):\n","    size = os.path.getsize(p)\n","    with open(p, \"r\", encoding=\"utf-8\") as f:\n","        first = [json.loads(x) for x in itertools.islice(f, 3)]\n","    print(os.path.basename(p), \"| bytes:\", size, \"| sample refs:\", [r[\"ref\"] for r in first])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJLy75YmdRiV","executionInfo":{"status":"ok","timestamp":1762722670419,"user_tz":0,"elapsed":77,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"3c67f437-ed53-42e2-8431-15403f1f4378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hadith_9books_ar.jsonl | bytes: 77500273 | sample refs: ['Sunan Abi Dawud ?:?', 'Sunan Abi Dawud ?:?', 'Sunan Abi Dawud ?:?']\n","hadith_9books_en.jsonl | bytes: 27884965 | sample refs: ['Sunan Abi Dawud ?:?', 'Sunan Abi Dawud ?:?', 'Sunan Abi Dawud ?:?']\n"]}]},{"cell_type":"code","source":["# Cell 11 (15-11-2025)— Hadith 9 Books (AR+EN) → _normalized/\n","# Purpose: Read AhmedBaset/hadith-json (by_book + by_chapter), extract AR + EN,\n","#          normalise to JSONL with stable (chapter, number) when available.\n","\n","import os, json, re, hashlib, collections, itertools\n","from pathlib import Path\n","\n","# ---- Paths -------------------------------------------------------------------\n","ROOT      = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT  = f\"{ROOT}/data/raw/kb\"\n","NORM_DIR  = f\"{RAW_ROOT}/_normalized\"\n","os.makedirs(NORM_DIR, exist_ok=True)\n","\n","# IMPORTANT: point to the *repo root*, not a subfolder\n","H_ROOT = \"/content/drive/MyDrive/FATCR/data/raw/kb/Islam/Hadith/hadith-json\"\n","\n","# Force the canonical /db tree (this repo keeps the JSON there)\n","H_DB = os.path.join(H_ROOT, \"db\")\n","if not os.path.isdir(H_DB):\n","    raise RuntimeError(f\"Expected hadith-json /db at: {H_DB}\")\n","BASE = H_DB\n","\n","BY_BOOK_DIRS    = [os.path.join(BASE, \"by_book\",    \"the_9_books\")]\n","BY_CHAPTER_DIRS = [os.path.join(BASE, \"by_chapter\", \"the_9_books\")]\n","\n","print(\"Hadith root:\", H_ROOT)\n","print(\"by_book dirs:\", BY_BOOK_DIRS)\n","print(\"by_chapter dirs:\", BY_CHAPTER_DIRS)\n","\n","# ---- Config / helpers --------------------------------------------------------\n","BOOK_SLUGS = [\"abudawud\",\"ahmed\",\"bukhari\",\"darimi\",\"ibnmajah\",\"malik\",\"muslim\",\"nasai\",\"tirmidhi\"]\n","BOOK_NAME  = {\n","    \"abudawud\":\"Sunan Abi Dawud\",\n","    \"ahmed\":\"Musnad Ahmad\",\n","    \"bukhari\":\"Sahih al-Bukhari\",\n","    \"darimi\":\"Sunan al-Darimi\",\n","    \"ibnmajah\":\"Sunan Ibn Majah\",\n","    \"malik\":\"Muwatta Malik\",\n","    \"muslim\":\"Sahih Muslim\",\n","    \"nasai\":\"Sunan al-Nasa'i\",\n","    \"tirmidhi\":\"Jamiʿ al-Tirmidhi\",\n","}\n","\n","# ⛔ No English dataset for Dārimī in your mirror — skip EN rows for this slug\n","EN_DISABLED = {\"darimi\"}\n","\n","def _clean(s):\n","    return re.sub(r\"\\s+\", \" \", s).strip() if isinstance(s, str) else \"\"\n","\n","def _as_int(x):\n","    if x is None: return None\n","    if isinstance(x, int): return x\n","    m = re.search(r\"\\d+\", str(x))\n","    return int(m.group()) if m else None\n","\n","def _hash_text(t):  # de-dup helper\n","    return hashlib.md5(t.encode(\"utf-8\")).hexdigest()\n","\n","def _norm_record(lang, slug, chapter, number, text, grade=None):\n","    return {\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"hadith\",\n","        \"collection\": \"Nine Books\",\n","        \"source\": \"AhmedBaset/hadith-json\",\n","        \"lang\": lang,\n","        \"book\": BOOK_NAME.get(slug, slug),\n","        \"chapter\": int(chapter) if chapter is not None else None,\n","        \"number\": int(number) if number is not None else None,\n","        \"grade\": grade,\n","        \"text\": _clean(text),\n","        \"ref\": f\"{BOOK_NAME.get(slug, slug)} {chapter if chapter is not None else '?'}:{number if number is not None else '?'}\",\n","        \"group_key\": f\"hadith-{slug}-{chapter if chapter is not None else 'X'}-{number if number is not None else 'Y'}\",\n","    }\n","\n","# ---- file readers ------------------------------------------------------------\n","\n","def _iter_by_book(slug):\n","    \"\"\"Yield a list of hadith dicts from by_book/<slug>.json (handles common shapes).\"\"\"\n","    paths = [os.path.join(d, f\"{slug}.json\") for d in BY_BOOK_DIRS]\n","    for p in paths:\n","        if os.path.isfile(p):\n","            try:\n","                with open(p, \"r\", encoding=\"utf-8\") as f:\n","                    obj = json.load(f)\n","            except Exception:\n","                continue\n","            if isinstance(obj, list):\n","                return obj\n","            if isinstance(obj, dict):\n","                for k in (\"hadiths\",\"data\",\"items\"):\n","                    if k in obj and isinstance(obj[k], list):\n","                        return obj[k]\n","    return []\n","\n","def _iter_by_chapter(slug):\n","    \"\"\"Yield (chapter_no, list_of_items) from by_chapter/<slug>/<N>.json (handles common shapes).\"\"\"\n","    for base_dir in BY_CHAPTER_DIRS:\n","        slug_dir = os.path.join(base_dir, slug)\n","        if not os.path.isdir(slug_dir):\n","            continue\n","        entries = sorted(os.scandir(slug_dir), key=lambda d: _as_int(d.name) or float('inf'))\n","        for entry in entries:\n","            if not entry.is_file() or not entry.name.endswith(\".json\"):\n","                continue\n","            ch = _as_int(Path(entry.name).stem)\n","            try:\n","                with open(entry.path, \"r\", encoding=\"utf-8\") as f:\n","                    obj = json.load(f)\n","            except Exception:\n","                continue\n","            if isinstance(obj, list):\n","                yield ch, obj\n","            elif isinstance(obj, dict):\n","                for k in (\"hadiths\",\"data\",\"items\"):\n","                    if k in obj and isinstance(obj[k], list):\n","                        yield ch, obj[k]\n","                        break\n","\n","# ---- the key extractor (handles english as an object) ------------------------\n","def _extract_texts(item):\n","    # ---- Arabic ----\n","    ar = \"\"\n","    for k in (\"arabic\",\"ar\",\"text_ar\",\"textArabic\",\"arabic_text\",\"hadithArabic\",\"hadith_ar\",\"matn\"):\n","        if isinstance(item.get(k), str) and item[k].strip():\n","            ar = _clean(item[k]); break\n","    if not ar and isinstance(item.get(\"text\"), dict):\n","        for k in (\"ar\",\"arabic\",\"matn\"):\n","            v = item[\"text\"].get(k)\n","            if isinstance(v, str) and v.strip():\n","                ar = _clean(v); break\n","\n","    # ---- English ----\n","    en = \"\"\n","    eng = item.get(\"english\")\n","\n","    def _coerce_text(x):\n","        if isinstance(x, str):\n","            return _clean(x)\n","        if isinstance(x, list):\n","            parts = [str(t).strip() for t in x if isinstance(t, (str, int, float)) and str(t).strip()]\n","            return _clean(\" \".join(parts)) if parts else \"\"\n","        if isinstance(x, dict):\n","            parts = [str(v).strip() for v in x.values() if isinstance(v, (str, int, float)) and str(v).strip()]\n","            return _clean(\" \".join(parts)) if parts else \"\"\n","        return \"\"\n","\n","    if isinstance(eng, dict):\n","        txt = \"\"\n","        for k in (\"text\",\"body\",\"hadith\",\"content\",\"value\",\"translation\"):\n","            if k in eng:\n","                txt = _coerce_text(eng[k])\n","                if txt:\n","                    break\n","        narr = _clean(eng.get(\"narrator\"))\n","        if txt:\n","            en = f\"Narrated {narr}: {txt}\" if narr and not txt.lower().startswith((\"narrated\",\"reported\")) else txt\n","\n","    elif isinstance(eng, str) and eng.strip():\n","        en = _clean(eng)\n","\n","    elif isinstance(eng, list) and eng:\n","        cand = eng[0] if isinstance(eng[0], dict) else None\n","        if isinstance(cand, dict):\n","            txt = \"\"\n","            for k in (\"text\",\"body\",\"hadith\",\"content\",\"value\",\"translation\"):\n","                if k in cand:\n","                    txt = _coerce_text(cand[k])\n","                    if txt:\n","                        break\n","            narr = _clean(cand.get(\"narrator\"))\n","            if txt:\n","                en = f\"Narrated {narr}: {txt}\" if narr and not txt.lower().startswith((\"narrated\",\"reported\")) else txt\n","\n","    if not en:\n","        for k in (\"en\",\"text_en\",\"textEnglish\",\"english_text\",\"hadithEnglish\",\"hadith_en\",\"translation\"):\n","            v = item.get(k)\n","            if isinstance(v, (str, list, dict)):\n","                en = _coerce_text(v)\n","                if en:\n","                    break\n","    if not en and isinstance(item.get(\"text\"), dict):\n","        v = item[\"text\"].get(\"en\") or item[\"text\"].get(\"english\")\n","        if isinstance(v, (str, list, dict)):\n","            en = _coerce_text(v)\n","\n","    # narrator-only fallback\n","    if not en:\n","        narr = \"\"\n","        if isinstance(eng, dict):\n","            narr = _clean(eng.get(\"narrator\"))\n","        elif isinstance(eng, list) and eng and isinstance(eng[0], dict):\n","            narr = _clean(eng[0].get(\"narrator\"))\n","        if narr:\n","            en = f\"Narrated {narr}\"\n","\n","    return ar, en\n","\n","def _extract_numbers(item, default_ch=None, idx=None):\n","    \"\"\"Try to obtain (chapter, number) from item; fall back to defaults.\"\"\"\n","    ch = None\n","    for k in (\"chapter\",\"chapter_no\",\"chapterNumber\",\"chapter_id\",\"bookNumber\",\"book_id\"):\n","        if k in item:\n","            ch = _as_int(item[k]);\n","            if ch is not None: break\n","    if ch is None:\n","        ch = default_ch\n","\n","    num = None\n","    for k in (\"hadithnumber\",\"hadith_no\",\"hadithNumber\",\"number\",\"id\",\"hadith_id\",\"index\"):\n","        if k in item:\n","            num = _as_int(item[k]);\n","            if num is not None: break\n","    if num is None and isinstance(item.get(\"reference\"), dict):\n","        for k in (\"hadith\",\"hadithNo\",\"hadith_no\"):\n","            if k in item[\"reference\"]:\n","                num = _as_int(item[\"reference\"][k]);\n","                if num is not None: break\n","    if num is None and idx is not None:\n","        num = int(idx) + 1\n","    return ch, num\n","\n","# ---- build & write -----------------------------------------------------------\n","\n","def build_nine_books_jsonl():\n","    ar_rows, en_rows = [], []\n","    seen = set()  # (lang, slug, chapter, number, hash(text))\n","\n","    print(\"Scanning…\")\n","    for slug in BOOK_SLUGS:\n","        add_ar = add_en = 0\n","\n","        # Prefer richer by_chapter first\n","        bc_map = {}\n","        for ch, arr in _iter_by_chapter(slug):\n","            bc_map.setdefault(ch, []).extend(arr)\n","        for ch, arr in sorted(bc_map.items(), key=lambda kv: kv[0] if kv[0] is not None else float('inf')):\n","            for i, it in enumerate(arr):\n","                ar, en = _extract_texts(it)\n","                ch2, num2 = _extract_numbers(it, default_ch=ch, idx=i)\n","                if ar:\n","                    key = (\"ar\", slug, ch2, num2, _hash_text(ar))\n","                    if key not in seen:\n","                        ar_rows.append(_norm_record(\"ar\", slug, ch2, num2, ar))\n","                        seen.add(key); add_ar += 1\n","                # ⛔ Skip EN rows for slugs with no English dataset (e.g., darimi)\n","                if en and slug not in EN_DISABLED:\n","                    key = (\"en\", slug, ch2, num2, _hash_text(en))\n","                    if key not in seen:\n","                        en_rows.append(_norm_record(\"en\", slug, ch2, num2, en))\n","                        seen.add(key); add_en += 1\n","\n","        # Also ingest by_book to catch anything missing\n","        for it in _iter_by_book(slug):\n","            ar, en = _extract_texts(it)\n","            ch2, num2 = _extract_numbers(it, default_ch=None, idx=None)\n","            if ar:\n","                key = (\"ar\", slug, ch2, num2, _hash_text(ar))\n","                if key not in seen:\n","                    ar_rows.append(_norm_record(\"ar\", slug, ch2, num2, ar))\n","                    seen.add(key); add_ar += 1\n","            if en and slug not in EN_DISABLED:\n","                key = (\"en\", slug, ch2, num2, _hash_text(en))\n","                if key not in seen:\n","                    en_rows.append(_norm_record(\"en\", slug, ch2, num2, en))\n","                    seen.add(key); add_en += 1\n","\n","        print(f\"  {slug:8s}: +{add_ar:6d} AR, +{add_en:6d} EN\")\n","\n","    out_ar = os.path.join(NORM_DIR, \"hadith_9books_ar.jsonl\")\n","    out_en = os.path.join(NORM_DIR, \"hadith_9books_en.jsonl\")\n","    with open(out_ar, \"w\", encoding=\"utf-8\") as f:\n","        for r in ar_rows: f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","    with open(out_en, \"w\", encoding=\"utf-8\") as f:\n","        for r in en_rows: f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","\n","    print(f\"\\n✅ Wrote {out_ar} | rows: {len(ar_rows)}\")\n","    print(f\"✅ Wrote {out_en} | rows: {len(en_rows)}\")\n","\n","# ---- run ---------------------------------------------------------------------\n","build_nine_books_jsonl()\n","\n","# ---- quick preview -----------------------------------------------------------\n","def _preview(p, n=3):\n","    size = os.path.getsize(p) if os.path.exists(p) else 0\n","    try:\n","        with open(p, \"r\", encoding=\"utf-8\") as f:\n","            first = [json.loads(x) for x in itertools.islice(f, n)]\n","    except Exception:\n","        first = []\n","    refs  = [r.get(\"ref\") for r in first]\n","    books = sorted({r.get(\"book\") for r in first})\n","    print(os.path.basename(p), \"| bytes:\", size, \"| sample refs:\", refs or [], \"| sample books:\", books or [])\n","\n","_preview(os.path.join(NORM_DIR, \"hadith_9books_ar.jsonl\"))\n","_preview(os.path.join(NORM_DIR, \"hadith_9books_en.jsonl\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enri9xU70Xbq","executionInfo":{"status":"ok","timestamp":1763148300495,"user_tz":0,"elapsed":147413,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"5694c54a-9fa6-4d69-f256-5cbb55062dad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hadith root: /content/drive/MyDrive/FATCR/data/raw/kb/Islam/Hadith/hadith-json\n","by_book dirs: ['/content/drive/MyDrive/FATCR/data/raw/kb/Islam/Hadith/hadith-json/db/by_book/the_9_books']\n","by_chapter dirs: ['/content/drive/MyDrive/FATCR/data/raw/kb/Islam/Hadith/hadith-json/db/by_chapter/the_9_books']\n","Scanning…\n","  abudawud: + 10552 AR, + 10552 EN\n","  ahmed   : +  2748 AR, +  2718 EN\n","  bukhari : + 14554 AR, + 14554 EN\n","  darimi  : +  6812 AR, +     0 EN\n","  ibnmajah: +  8690 AR, +  8690 EN\n","  malik   : +  3720 AR, +  3946 EN\n","  muslim  : + 14918 AR, + 14916 EN\n","  nasai   : + 11536 AR, + 11536 EN\n","  tirmidhi: +  8106 AR, +  8106 EN\n","\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/hadith_9books_ar.jsonl | rows: 81636\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/hadith_9books_en.jsonl | rows: 75018\n","hadith_9books_ar.jsonl | bytes: 105606911 | sample refs: ['Sunan Abi Dawud 1:1', 'Sunan Abi Dawud 1:2', 'Sunan Abi Dawud 1:3'] | sample books: ['Sunan Abi Dawud']\n","hadith_9books_en.jsonl | bytes: 53456245 | sample refs: ['Sunan Abi Dawud 1:1', 'Sunan Abi Dawud 1:2', 'Sunan Abi Dawud 1:3'] | sample books: ['Sunan Abi Dawud']\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"op-iyfaFmWEQ"}},{"cell_type":"markdown","source":["## Christian commentaries\n","## *Slim version: sparse clone only the 4 Fathers*"],"metadata":{"id":"bqrbAeaMnYYK"}},{"cell_type":"code","source":["%%bash\n","# Go to the Commentary folder under Christianity\n","cd \"/content/drive/MyDrive/FATCR/data/raw/kb/Christianity/Commentary\"\n","\n","# Clone the repo if it isn't there yet\n","if [ ! -d \"Commentaries-Database\" ]; then\n","  git clone --filter=blob:none --sparse \\\n","    https://github.com/HistoricalChristianFaith/Commentaries-Database.git\n","fi\n","\n","cd Commentaries-Database\n","\n","# Initialise sparse-checkout\n","git sparse-checkout init --cone\n","\n","# Restrict to the four Fathers you want\n","git sparse-checkout set \\\n","  \"Irenaeus\" \\\n","  \"Origen of Alexandria\" \\\n","  \"John Chrysostom\" \\\n","  \"Augustine of Hippo\"\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDcVdgMEmu8d","executionInfo":{"status":"ok","timestamp":1763331019563,"user_tz":0,"elapsed":136779,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"80c95671-e9e9-4a45-e7aa-863147446a98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning into 'Commentaries-Database'...\n","Updating index flags:  70% (36919/52032)\rUpdating index flags:  71% (36943/52032)\rUpdating index flags:  72% (37464/52032)\rUpdating index flags:  73% (37984/52032)\rUpdating index flags:  74% (38504/52032)\rUpdating index flags:  75% (39024/52032)\rUpdating index flags:  76% (39545/52032)\rUpdating index flags:  77% (40065/52032)\rUpdating index flags:  78% (40585/52032)\rUpdating index flags:  79% (41106/52032)\rUpdating index flags:  80% (41626/52032)\rUpdating index flags:  81% (42146/52032)\rUpdating index flags:  82% (42667/52032)\rUpdating index flags:  83% (43187/52032)\rUpdating index flags:  84% (43707/52032)\rUpdating index flags:  85% (44228/52032)\rUpdating index flags:  86% (44748/52032)\rUpdating index flags:  87% (45268/52032)\rUpdating index flags:  88% (45789/52032)\rUpdating index flags:  89% (46309/52032)\rUpdating index flags:  90% (46829/52032)\rUpdating index flags:  91% (47350/52032)\rUpdating index flags:  92% (47870/52032)\rUpdating index flags:  93% (48390/52032)\rUpdating index flags:  94% (48911/52032)\rUpdating index flags:  95% (49431/52032)\rUpdating index flags:  96% (49951/52032)\rUpdating index flags:  97% (50472/52032)\rUpdating index flags:  98% (50992/52032)\rUpdating index flags:  99% (51512/52032)\rUpdating index flags: 100% (52032/52032)\rUpdating index flags: 100% (52032/52032), done.\n"]}]},{"cell_type":"code","source":["# === Patristic Christian Commentaries (Commentaries-Database) → FACTR KB ===\n","#\n","# This adapter ingests TOML files from the HistoricalChristianFaith\n","# Commentaries-Database repo into a unified JSONL KB file.\n","#\n","# It assumes:\n","#   - RAW_ROOT and NORM_ROOT are already defined\n","#   - bible_key(book, chapter, verse) exists and returns a canonical group_key\n","#   - write_jsonl_line(f_obj, record_dict) is available\n","#\n","# Upstream repo docs for format:\n","#   - File name:  [Father]/[Book] Chapter_Verse(-Verse...).toml\n","#   - Contents:   [[commentary]] with keys: quote, source_title, [source_url, append_to_author_name, time]\n","# See: Commentaries-Database README (File Contents Format / File Name Formats).\n","\n","from pathlib import Path\n","import json\n","import re # Added import for re module, used by bible_key\n","\n","# Helper functions from Cell 3, ensuring they are in scope\n","def _clean(s):\n","    # Re-import re for this specific function to ensure it's self-contained if needed\n","    # but it's already imported at the top of the cell for global scope.\n","    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n","\n","def bible_key(book:str, chapter:int, verse:int):\n","    # Re-import re for this specific function to ensure it's self-contained if needed\n","    # but it's already imported at the top of the cell for global scope.\n","    b = re.sub(r\"\\s+\", \"_\", str(book).strip())\n","    # Corrected f-string syntax here\n","    return f\"bible-{b}-{int(chapter)}-{int(verse)}\"\n","\n","def write_jsonl_line(path, rec: dict):\n","    \"\"\"Strict writer that enforces required keys (including 'collection').\"\"\"\n","    required = {\"tradition\",\"genre\",\"source\",\"collection\",\"lang\",\"book\",\"chapter\",\"verse\",\"number\",\"grade\",\"text\",\"ref\",\"group_key\"}\n","    missing = required - set(rec.keys())\n","    if missing:\n","        raise ValueError(f\"Record missing required keys: {sorted(missing)}\")\n","    if not rec.get(\"collection\"):\n","        raise ValueError(\"Record has empty 'collection'. Adapter must set it.\")\n","    with open(path, \"a\", encoding=\"utf-8\") as f:\n","        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","\n","# Try stdlib tomllib first (Python 3.11+), otherwise fall back to rtoml (pip install rtoml)\n","try:\n","    import tomllib as _toml  # Python 3.11+\n","    def _load_toml_bytes(b: bytes):\n","        return _toml.loads(b.decode(\"utf-8\"))\n","except ImportError:  # pragma: no cover\n","    import rtoml as _toml  # pip install rtoml\n","    def _load_toml_bytes(b: bytes):\n","        return _toml.loads(b.decode(\"utf-8\"))\n","\n","\n","# Root where YOU have cloned / copied Commentaries-Database\n","# Adjust this if you keep it somewhere else.\n","COMMENTARIES_DB_ROOT = Path(RAW_ROOT) / \"Christianity\" / \"Commentary\" / \"Commentaries-Database\"\n","# Directory names in Commentaries-Database for our 4 core Fathers.\n","# IMPORTANT: make sure these match the actual folder names in your clone.\n","PATristic_AUTHOR_DIRS = [\n","    \"Irenaeus\",\n","    \"Origen of Alexandria\",  # or \"Origen\" if that’s the actual folder name\n","    \"John Chrysostom\",\n","    \"Augustine of Hippo\",\n","]\n","\n","\n","\n","def parse_commentary_filename(path: Path):\n","    \"\"\"\n","    Parse a Commentaries-Database TOML filename into (book, chapter:int, verse:int, span_str).\n","\n","    File name formats (from the repo README):\n","        [Father-Name]/[Book-Name] Chapter_Verse.toml\n","        [Father-Name]/[Book-Name] Chapter_Verse-Verse.toml\n","        [Father-Name]/[Book-Name] Chapter_Verse-Chapter_Verse.toml\n","\n","    Examples:\n","        'Matthew 23_35.toml'\n","        'Matthew 23_35-41.toml'\n","        '1 Kings 19_10-20_3.toml'\n","\n","    We anchor each commentary record on the *first* verse of the span, but we keep the\n","    full span string (e.g. \"1 Corinthians 10:16-20:3\") in meta[\"span\"] and in ref.\n","    \"\"\"\n","    stem = path.stem  # e.g. '1 Corinthians 10_16' or 'Matthew 23_35-41'\n","\n","    # Split book vs chapter/verse part\n","    try:\n","        book_part, ref_part = stem.rsplit(\" \", 1)\n","    except ValueError as exc:\n","        raise ValueError(f\"Unexpected commentary filename format: {path.name}\") from exc\n","\n","    # Human-readable span string, converting underscores to ':' inside the reference part\n","    span_str = f\"{book_part} \" + ref_part.replace(\"_\", \":\")\n","\n","    # Anchor: only the start of the range, e.g. \"10_16\" from \"10_16-20_3\"\n","    range_start = ref_part.split(\"-\", 1)[0]\n","\n","    try:\n","        chap_str, verse_str = range_start.split(\"_\", 1)\n","        chapter = int(chap_str)\n","        verse = int(verse_str)\n","    except Exception as exc:\n","        raise ValueError(f\"Could not parse chapter/verse from {path.name}: {exc}\") from exc\n","\n","    return book_part, chapter, verse, span_str\n","\n","\n","def convert_commentaries_database(\n","    author_dirs=PATristic_AUTHOR_DIRS,\n","    out_path=None,\n","):\n","    \"\"\"\n","    Walk the Commentaries-Database clone and normalise TOML commentary files\n","    for the given author dirs into our KB JSONL format.\n","\n","    Returns: 혹은\n","        Path to the JSONL file produced.\n","    \"\"\"\n","    if out_path is None:\n","        out_path = Path(NORM_DIR) / \"christian_commentaries_patristic.jsonl\"\n","\n","    out_path = Path(out_path)\n","    out_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","    n_files = 0\n","    n_entries = 0\n","\n","    # Initialize the output file to be empty, so write_jsonl_line appends correctly.\n","    # This replaces the `with out_path.open(...) as f_out:` block.\n","    with out_path.open(\"w\", encoding=\"utf-8\") as f_init:\n","        f_init.truncate(0)\n","\n","    for author_dir_name in author_dirs:\n","        author_dir = COMMENTARIES_DB_ROOT / author_dir_name\n","\n","        if not author_dir.exists():\n","            print(f\"[COMMENTARIES][WARN] Author dir not found: {author_dir} (skipping)\")\n","            continue\n","\n","        print(f\"[COMMENTARIES] Scanning {author_dir_name} …\")\n","        for toml_path in sorted(author_dir.rglob(\"*.toml\")):\n","            # Skip metadata.toml files, as they don't contain commentary and break parsing\n","            if toml_path.stem == \"metadata\":\n","                print(f\"  [COMMENTARIES] Skipping non-commentary file: {toml_path.name}\")\n","                continue\n","\n","            n_files += 1\n","\n","            data = _load_toml_bytes(toml_path.read_bytes())\n","            entries = data.get(\"commentary\", [])\n","\n","            # Normalise degenerate case where there is a single [commentary] table\n","            if isinstance(entries, dict):\n","                entries = [entries]\n","\n","            book, chapter, verse, span_str = parse_commentary_filename(toml_path)\n","            group = bible_key(book, chapter, verse)\n","\n","            for entry in entries:\n","                quote = (entry.get(\"quote\") or \"\").strip()\n","                if not quote:\n","                    continue\n","\n","                eff_author = author_dir_name + (entry.get(\"append_to_author_name\") or \"\")\n","\n","                meta = {\n","                    \"author\": eff_author,\n","                    \"source_title\": entry.get(\"source_title\"),\n","                    \"source_url\": entry.get(\"source_url\"),\n","                    \"time\": entry.get(\"time\"),  # AD year or 9999 for unknown\n","                    \"span\": span_str,\n","                    \"filename\": toml_path.name,\n","                    \"collection\": \"Commentaries-Database\" # Explicitly set collection in meta\n","                }\n","\n","                record = {\n","                    \"tradition\": \"Christianity\",\n","                    \"genre\": \"commentary\",\n","                    \"source\": \"HistoricalChristianFaith-CommentariesDatabase\",\n","                    \"collection\": meta[\"collection\"], # Ensure collection is copied from meta\n","                    \"lang\": \"en\",                     # Set language to English\n","                    \"book\": book,\n","                    \"chapter\": chapter,\n","                    \"verse\": verse,\n","                    \"number\": None,                   # Set number to None as it's not applicable\n","                    \"grade\": None,                    # Set grade to None as it's not applicable\n","                    \"text\": quote,\n","                    \"ref\": span_str,\n","                    \"group_key\": group,\n","                    \"author\": eff_author,\n","                    # \"meta\": meta, # Removed, as it's not part of the standard schema\n","                }\n","\n","\n","                write_jsonl_line(out_path, record) # Pass the path, not the file object\n","                n_entries += 1\n","\n","    print(f\"[COMMENTARIES] Authors requested: {author_dirs}\")\n","    print(f\"[COMMENTARIES] Files scanned: {n_files}\")\n","    print(f\"[COMMENTARIES] Commentary entries written: {n_entries}\")\n","    print(f\"[COMMENTARIES] Output JSONL: {out_path}\")\n","    return out_path\n","\n","\n","# ---- Run once to generate the KB file + update MANIFEST ----\n","\n","commentary_out = convert_commentaries_database()\n","\n","# manifest_path = Path(NORM_DIR) / \"MANIFEST.json\"\n","# all_sources = [] # Initialize as a list to store all source entries\n","\n","# try:\n","#     loaded_manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n","#     if isinstance(loaded_manifest, list):\n","#         all_sources.extend(loaded_manifest)\n","#     elif isinstance(loaded_manifest, dict) and \"normalized_files\" in loaded_manifest:\n","#         # Handle manifest from Cell 9 (dict with 'normalized_files' list of paths)\n","#         for p_str in loaded_manifest[\"normalized_files\"]:\n","#             # Create a minimal structured entry for existing paths\n","#             all_sources.append({\n","#                 \"name\": Path(p_str).stem,\n","#                 \"path\": p_str,\n","#                 \"tradition\": \"unknown\", # Default placeholder\n","#                 \"genre\": \"unknown\",     # Default placeholder\n","#                 \"source\": \"unknown\",    # Default placeholder\n","#                 \"notes\": \"Generated from previous manifest entries\"\n","#             })\n","#     # If loaded_manifest is a dict but not the expected one from Cell 9, it's effectively ignored\n","# except FileNotFoundError:\n","#     pass # all_sources remains empty\n","\n","# # Add the new commentary entry\n","# all_sources.append({\n","#     \"name\": \"christian_commentaries_patristic\",\n","#     \"path\": str(commentary_out.relative_to(Path(NORM_DIR))),\n","#     \"tradition\": \"Christianity\",\n","#     \"genre\": \"commentary\",\n","#     \"source\": \"HistoricalChristianFaith-CommentariesDatabase\",\n","#     \"notes\": \"Patristic commentaries (Irenaeus, Origen, John Chrysostom, Augustine of Hippo) imported from Commentaries-Database\"\n","# })\n","\n","# # Deduplicate entries based on 'name' to avoid adding the same source multiple times\n","# seen_names = set()\n","# deduplicated_sources = []\n","# for source_entry in all_sources:\n","#     if source_entry[\"name\"] not in seen_names:\n","#         deduplicated_sources.append(source_entry)\n","#         seen_names.add(source_entry[\"name\"])\n","\n","# manifest_path.write_text(json.dumps(deduplicated_sources, indent=2), encoding=\"utf-8\") # Write the list\n","# print(f\"[MANIFEST] Updated: {manifest_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2xOWbO6nuG6","executionInfo":{"status":"ok","timestamp":1763334571312,"user_tz":0,"elapsed":289233,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"edfc0925-b431-4d2e-9885-9e24baa0c30a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[COMMENTARIES] Scanning Irenaeus …\n","  [COMMENTARIES] Skipping non-commentary file: metadata.toml\n","[COMMENTARIES] Scanning Origen of Alexandria …\n","  [COMMENTARIES] Skipping non-commentary file: metadata.toml\n","[COMMENTARIES] Scanning John Chrysostom …\n","  [COMMENTARIES] Skipping non-commentary file: metadata.toml\n","[COMMENTARIES] Scanning Augustine of Hippo …\n","  [COMMENTARIES] Skipping non-commentary file: metadata.toml\n","[COMMENTARIES] Authors requested: ['Irenaeus', 'Origen of Alexandria', 'John Chrysostom', 'Augustine of Hippo']\n","[COMMENTARIES] Files scanned: 13641\n","[COMMENTARIES] Commentary entries written: 17639\n","[COMMENTARIES] Output JSONL: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\n","[MANIFEST] Updated: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/MANIFEST.json\n"]}]},{"cell_type":"markdown","source":["Quick sanity-checks / 3 below (optional but nice)"],"metadata":{"id":"wsvvLqcu23Xm"}},{"cell_type":"code","source":["import json\n","from itertools import islice\n","from pathlib import Path\n","\n","path = Path(NORM_DIR) / \"christian_commentaries_patristic.jsonl\"\n","print(\"File:\", path)\n","\n","with path.open(\"r\", encoding=\"utf-8\") as f:\n","    for line in islice(f, 5):\n","        rec = json.loads(line)\n","        # Modified to print 'source' field (with fallback) and other keys\n","        print(f\"{rec.get('source', 'N/A Source')} → {rec.get('ref', 'N/A Ref')}\")\n","        print(\"  text:\", rec.get(\"text\", \"N/A Text\")[:160], \"…\")\n","        print(\"  group_key:\", rec.get(\"group_key\", \"N/A Group Key\"))\n","        print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ur4nQ8Bs25bm","executionInfo":{"status":"ok","timestamp":1763334589578,"user_tz":0,"elapsed":52,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"3bc081d0-e10b-4b13-8b11-95f449791c6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\n","HistoricalChristianFaith-CommentariesDatabase → 1 Corinthians 10:1\n","  text: ) is come. Wherefore let him that thinketh he standeth, take heed lest he fall.\" …\n","  group_key: bible-1_Corinthians-10-1\n","\n","HistoricalChristianFaith-CommentariesDatabase → 1 Corinthians 10:11\n","  text: For during forty days He was learning to keep …\n","  group_key: bible-1_Corinthians-10-11\n","\n","HistoricalChristianFaith-CommentariesDatabase → 1 Corinthians 10:16\n","  text: And adds, \"The cup of blessing which we bless, is it not the communion of the blood of Christ? \".\n","But if this indeed do not attain salvation, then neither did t …\n","  group_key: bible-1_Corinthians-10-16\n","\n","HistoricalChristianFaith-CommentariesDatabase → 1 Corinthians 10:4\n","  text: And as He was born of Mary in the last times, so did He also proceed from God as the First-begotten of every creature; and as He hungered, so did He satisfy …\n","  group_key: bible-1_Corinthians-10-4\n","\n","HistoricalChristianFaith-CommentariesDatabase → 1 Corinthians 10:5\n","  text: He thus clearly shows that the very same King who gathered from all quarters the faithful to the marriage of His Son, and who grants them the incorruptible banq …\n","  group_key: bible-1_Corinthians-10-5\n","\n"]}]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","\n","path = Path(NORM_DIR) / \"christian_commentaries_patristic.jsonl\"\n","with path.open(\"r\", encoding=\"utf-8\") as f:\n","    rec = json.loads(next(f))\n","print(rec.keys())\n","# Removed: print(rec[\"meta\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_AgPryk44HP","executionInfo":{"status":"ok","timestamp":1763334592807,"user_tz":0,"elapsed":21,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"ee968d96-0d6c-4902-ba03-91de84760d1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['tradition', 'genre', 'source', 'collection', 'lang', 'book', 'chapter', 'verse', 'number', 'grade', 'text', 'ref', 'group_key', 'author'])\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","from pathlib import Path\n","\n","path = Path(NORM_DIR) / \"christian_commentaries_patristic.jsonl\"\n","\n","author_counts = Counter()\n","with path.open(\"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        rec = json.loads(line)\n","        author_counts[rec.get(\"author\",\"<unknown>\")] += 1\n","\n","author_counts\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cx1Q2hSU8BeE","executionInfo":{"status":"ok","timestamp":1763334695067,"user_tz":0,"elapsed":1405,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"8df295a7-9793-4166-e3d9-1b272d5ad104"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Irenaeus': 721,\n","         'Origen of Alexandria': 2265,\n","         'Origen of Alexandria is referenced above by Jerome (AD 420)': 1,\n","         'Origen of Alexandria (as quoted by Aquinas, AD 1274)': 238,\n","         'John Chrysostom': 7323,\n","         'John Chrysostom (as quoted by Aquinas, AD 1274)': 657,\n","         'Augustine of Hippo': 5837,\n","         'Augustine of Hippo (as quoted by Aquinas, AD 1274)': 597})"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["Manafest fix cell - not needed for the final prod"],"metadata":{"id":"V7hYaJ0j9_eh"}},{"cell_type":"code","source":["# JUst a quick fix if the manifest is out of touch? Uncomment if required\n","\n","# import json\n","# from pathlib import Path\n","\n","# manifest_path = Path(NORM_DIR) / \"MANIFEST.json\"\n","# manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n","\n","# for entry in manifest:\n","#     if entry[\"name\"] == \"bible_web_en\":\n","#         entry.update({\n","#             \"tradition\": \"Christianity\",\n","#             \"genre\": \"scripture\",\n","#             \"source\": \"World English Bible\",\n","#             \"notes\": \"WEB (public domain) Bible, English\",\n","#         })\n","#     elif entry[\"name\"] == \"hadith_9books_en\":\n","#         entry.update({\n","#             \"tradition\": \"Islam\",\n","#             \"genre\": \"hadith\",\n","#             \"source\": \"AhmedBaset/hadith-json (the_9_books)\",\n","#             \"notes\": \"Nine canonical Sunni hadith collections (English translation)\",\n","#         })\n","#     elif entry[\"name\"] == \"christian_commentaries_patristic\":\n","#         entry.update({\n","#             \"path\": \"data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\",\n","#             \"tradition\": \"Christianity\",\n","#             \"genre\": \"commentary\",\n","#             \"source\": \"HistoricalChristianFaith-CommentariesDatabase\",\n","#         })\n","\n","# manifest_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n","# print(\"Updated manifest written to:\", manifest_path)\n","# print(json.dumps(manifest, indent=2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbPJp8p09YVW","executionInfo":{"status":"ok","timestamp":1763335052305,"user_tz":0,"elapsed":34,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"638aa1be-044c-48b7-9a8d-c67b396abc44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated manifest written to: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/MANIFEST.json\n","[\n","  {\n","    \"name\": \"bible_web_en\",\n","    \"path\": \"data/raw/kb/_normalized/bible_web_en.jsonl\",\n","    \"tradition\": \"Christianity\",\n","    \"genre\": \"scripture\",\n","    \"source\": \"World English Bible\",\n","    \"notes\": \"WEB (public domain) Bible, English\"\n","  },\n","  {\n","    \"name\": \"hadith_9books_en\",\n","    \"path\": \"data/raw/kb/_normalized/hadith_9books_en.jsonl\",\n","    \"tradition\": \"Islam\",\n","    \"genre\": \"hadith\",\n","    \"source\": \"AhmedBaset/hadith-json (the_9_books)\",\n","    \"notes\": \"Nine canonical Sunni hadith collections (English translation)\"\n","  },\n","  {\n","    \"name\": \"christian_commentaries_patristic\",\n","    \"path\": \"data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\",\n","    \"tradition\": \"Christianity\",\n","    \"genre\": \"commentary\",\n","    \"source\": \"HistoricalChristianFaith-CommentariesDatabase\",\n","    \"notes\": \"Patristic commentaries (Irenaeus, Origen, John Chrysostom, Augustine of Hippo) imported from Commentaries-Database\"\n","  }\n","]\n"]}]},{"cell_type":"markdown","source":["## clone creeds repo & ingest"],"metadata":{"id":"QXYz0TtTIJKA"}},{"cell_type":"code","source":["%%bash\n","# Go to the Commentary folder under Christianity\n","cd \"/content/drive/MyDrive/FATCR/data/raw/kb/Christianity/Creeds\"\n","\n","# mkdir -p _external\n","# cd _external\n","\n","REPO_URL=\"https://github.com/lukmaanviscomi/christian-creeds-kb.git\"\n","\n","if [ ! -d \"christian-creeds-kb\" ]; then\n","  git clone \"$REPO_URL\"\n","else\n","  cd christian-creeds-kb\n","  git pull --ff-only || echo \"[GIT] Pull failed; using existing copy.\"\n","fi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HM_w4zzEIUC9","executionInfo":{"status":"ok","timestamp":1763338169169,"user_tz":0,"elapsed":1310,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"4fb69f18-bf21-4fe3-ea9c-05e53e28b45f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning into 'christian-creeds-kb'...\n"]}]},{"cell_type":"markdown","source":["## Christian Creeds (TXT → FACTR KB JSONL)"],"metadata":{"id":"vag_wCocJ1cU"}},{"cell_type":"code","source":["# === Christian Creeds (TXT → FACTR KB JSONL) ===\n","#\n","# This adapter ingests a small set of core Christian creeds\n","# from plain-text files and normalises them into our KB schema.\n","#\n","# Files expected under:\n","#   RAW_ROOT / \"Christianity\" / \"Creeds\"\n","#\n","# You can rename the .txt files, but if you do, update CREEDS_SPEC\n","# to match.\n","\n","import json\n","from pathlib import Path\n","\n","CREEDS_DIR = Path(RAW_ROOT) / \"Christianity\" / \"Creeds\" / \"christian-creeds-kb\" / \"txt\"\n","\n","CREEDS_SPEC = [\n","    {\n","        \"filename\": \"nicene_381_en.txt\",\n","        \"book\": \"Nicene Creed\",\n","        \"short_name\": \"Niceno-Constantinopolitan Creed\",\n","        \"year\": 381,\n","        \"council\": \"First Council of Constantinople\",\n","        \"group_key\": \"creed-nicene-381\",\n","    },\n","    {\n","        \"filename\": \"apostles_creed_en.txt\",\n","        \"book\": \"Apostles' Creed\",\n","        \"short_name\": \"Apostles' Creed\",\n","        \"year\": None,  # early Western baptismal creed\n","        \"council\": \"Western baptismal creed\",\n","        \"group_key\": \"creed-apostles\",\n","    },\n","    {\n","        \"filename\": \"athanasian_creed_en.txt\",\n","        \"book\": \"Athanasian Creed\",\n","        \"short_name\": \"Athanasian Creed (Quicumque vult)\",\n","        \"year\": None,\n","        \"council\": \"Latin Western creed (c. 5th–6th C)\",\n","        \"group_key\": \"creed-athanasian\",\n","    },\n","    {\n","        \"filename\": \"chalcedon_definition_en.txt\",\n","        \"book\": \"Chalcedonian Definition\",\n","        \"short_name\": \"Definition of Chalcedon\",\n","        \"year\": 451,\n","        \"council\": \"Council of Chalcedon\",\n","        \"group_key\": \"creed-chalcedon-451\",\n","    },\n","]\n","\n","\n","def _normalize_text(s: str) -> str:\n","    \"\"\"Normalise line endings and trim trailing spaces.\"\"\"\n","    return \"\\n\".join(\n","        line.rstrip() for line in s.replace(\"\\r\\n\", \"\\n\").split(\"\\n\")\n","    ).strip()\n","\n","\n","def convert_creeds_txt(creeds_spec=CREEDS_SPEC, out_path=None):\n","    \"\"\"\n","    Read creed .txt files and write one JSONL file in KB schema.\n","\n","    We split each creed into paragraph-ish chunks on blank lines,\n","    so verses 1,2,3,... correspond to paragraphs within that creed.\n","    \"\"\"\n","    if out_path is None:\n","        out_path = Path(NORM_DIR) / \"christian_creeds.jsonl\"\n","    out_path = Path(out_path)\n","    out_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","    n_creeds = 0\n","    n_passages = 0\n","\n","    with out_path.open(\"w\", encoding=\"utf-8\") as f_out:\n","        for c in creeds_spec:\n","            path = CREEDS_DIR / c[\"filename\"]\n","            if not path.exists():\n","                print(f\"[CREEDS][WARN] Missing file: {path}\")\n","                continue\n","\n","            raw = path.read_text(encoding=\"utf-8\")\n","            text_norm = _normalize_text(raw)\n","\n","            # split on blank lines into paragraphs\n","            paragraphs = [\n","                p.strip() for p in text_norm.split(\"\\n\\n\") if p.strip()\n","            ]\n","            if not paragraphs:\n","                print(f\"[CREEDS][WARN] No paragraphs found in {path}\")\n","                continue\n","\n","            n_creeds += 1\n","            for idx, para in enumerate(paragraphs, start=1):\n","                # Build a human-readable ref string\n","                if c[\"year\"]:\n","                    ref_str = f\"{c['short_name']} ({c['year']}, {c['council']}) ¶{idx}\"\n","                else:\n","                    ref_str = f\"{c['short_name']} ({c['council']}) ¶{idx}\"\n","\n","                record = {\n","                    \"tradition\": \"Christianity\",\n","                    \"genre\": \"creed\",\n","                    \"source\": \"Wikisource\",\n","                    \"collection\": \"Ecumenical Creeds\",\n","                    \"lang\": \"en\",\n","                    \"book\": c[\"book\"],\n","                    \"chapter\": 1,\n","                    \"verse\": idx,\n","                    \"number\": None,\n","                    \"grade\": None,\n","                    \"text\": para,\n","                    \"ref\": ref_str,\n","                    \"group_key\": c[\"group_key\"],\n","                    # extra creed-specific metadata\n","                    \"creed_name\": c[\"short_name\"],\n","                    \"year\": c[\"year\"],\n","                    \"council\": c[\"council\"],\n","                }\n","\n","                json.dump(record, f_out, ensure_ascii=False)\n","                f_out.write(\"\\n\")\n","                n_passages += 1\n","\n","    print(f\"[CREEDS] Creeds processed: {n_creeds}\")\n","    print(f\"[CREEDS] Paragraph passages written: {n_passages}\")\n","    print(f\"[CREEDS] Output JSONL: {out_path}\")\n","    return out_path\n","\n","\n","# --- Run once to generate the file and update MANIFEST ---\n","\n","creeds_out = convert_creeds_txt()\n","\n","# manifest_path = Path(NORM_DIR) / \"MANIFEST.json\"\n","# try:\n","#     manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n","# except FileNotFoundError:\n","#     manifest = []\n","\n","# # Path relative to repo ROOT, to match your other entries\n","# rel_path = str(creeds_out.relative_to(Path(ROOT)))\n","\n","# # Remove any existing entry with the same name (idempotent)\n","# manifest = [m for m in manifest if m.get(\"name\") != \"christian_creeds\"]\n","\n","# manifest.append({\n","#     \"name\": \"christian_creeds\",\n","#     \"path\": rel_path,  # e.g. \"data/raw/kb/_normalized/christian_creeds.jsonl\"\n","#     \"tradition\": \"Christianity\",\n","#     \"genre\": \"creed\",\n","#     \"source\": \"Wikisource\",\n","#     \"notes\": \"Ecumenical Christian creeds (Nicene, Apostles, Athanasian, Chalcedon) in English.\",\n","# })\n","\n","# manifest_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n","# print(f\"[MANIFEST] Updated with christian_creeds → {manifest_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhBs8arQJwIi","executionInfo":{"status":"ok","timestamp":1763338759382,"user_tz":0,"elapsed":56,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"7123962f-a0b4-4740-bf91-7686eb1efda1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[CREEDS] Creeds processed: 4\n","[CREEDS] Paragraph passages written: 20\n","[CREEDS] Output JSONL: /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/christian_creeds.jsonl\n","[MANIFEST] Updated with christian_creeds → /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/MANIFEST.json\n"]}]},{"cell_type":"markdown","source":["## Quick sanity check (optional)"],"metadata":{"id":"3rn-GNrXLu-d"}},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","\n","path = Path(NORM_DIR) / \"christian_creeds.jsonl\"\n","with path.open(\"r\", encoding=\"utf-8\") as f:\n","    rec = json.loads(next(f))\n","print(rec.keys())\n","print(rec[\"ref\"])\n","print(rec[\"text\"][:160], \"…\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UO_R0EuwLtDm","executionInfo":{"status":"ok","timestamp":1763338835519,"user_tz":0,"elapsed":8,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"46ec5752-46e6-4906-d328-8d9cb3892a8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['tradition', 'genre', 'source', 'collection', 'lang', 'book', 'chapter', 'verse', 'number', 'grade', 'text', 'ref', 'group_key', 'creed_name', 'year', 'council'])\n","Niceno-Constantinopolitan Creed (381, First Council of Constantinople) ¶1\n","We believe in one God,\n","the Father Almighty,\n","maker of heaven and earth,\n","of all things visible and invisible. …\n"]}]},{"cell_type":"markdown","source":["## Optional tiny check: counts per creed\n","If you’re curious (and for the thesis stats), you can run:"],"metadata":{"id":"btTBqu3JMMvz"}},{"cell_type":"code","source":["import json\n","from collections import Counter\n","from pathlib import Path\n","\n","path = Path(NORM_DIR) / \"christian_creeds.jsonl\"\n","counts = Counter()\n","\n","with path.open(\"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        rec = json.loads(line)\n","        counts[rec[\"creed_name\"]] += 1\n","\n","counts\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyhV-88zMQiq","executionInfo":{"status":"ok","timestamp":1763338951812,"user_tz":0,"elapsed":45,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"1015fcfc-89fd-41c3-d1e0-5f28b055483b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Niceno-Constantinopolitan Creed': 4,\n","         \"Apostles' Creed\": 3,\n","         'Athanasian Creed (Quicumque vult)': 11,\n","         'Definition of Chalcedon': 2})"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"70zo120aubhe"},"source":["## Cell 9 — Convert all (writes MANIFEST.json)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1762465107938,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"cq5QBcxrucjR","outputId":"1b2a97a3-db33-419b-fe9a-a116d2594b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","== Converting: bible_web_en_dir ==\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/bible_web_en.jsonl | rows: 0\n","\n","== Converting: hadith_the9_dir ==\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/hadith_9books_en.jsonl | rows: 0\n","\n","Wrote MANIFEST: data/raw/kb/_normalized/MANIFEST.json\n"]}],"source":["# produced = []\n","# for s in SOURCES:\n","#     kind = s[\"kind\"]\n","#     print(f\"\\n== Converting: {s['name']} ==\")\n","#     if kind == \"jsonl\":\n","#         convert_jsonl(s[\"in\"], s[\"out\"], s[\"fixed\"], keymap=s.get(\"keymap\",{}),\n","#                       group_key_fn=s[\"group_key_fn\"], post=s.get(\"post\"))\n","#     elif kind == \"csv\":\n","#         convert_csv(s[\"in\"], s[\"out\"], s[\"fixed\"], colmap=s.get(\"colmap\",{}),\n","#                     group_key_fn=s[\"group_key_fn\"], post=s.get(\"post\"))\n","#     elif kind == \"txt\":\n","#         convert_txt_folder(s[\"in\"], s[\"out\"], s[\"fixed\"], s.get(\"lang\",\"en\"),\n","#                            per_file_book=s.get(\"per_file_book\"), post=s.get(\"post\"))\n","#     elif kind == \"bible_dir\":\n","#         convert_bible_dir(s[\"in\"], s[\"out\"], s[\"fixed\"], post=s.get(\"post\"))\n","#     elif kind == \"hadith_dir\":\n","#         def _mapper(stem):\n","#             # customize mapping to nice collection names if needed\n","#             m = {\"bukhari\":\"Sahih al-Bukhari\", \"muslim\":\"Sahih Muslim\"}\n","#             return m.get(stem.lower(), stem)\n","#         fixed = dict(s[\"fixed\"])\n","#         fixed.setdefault(\"collection\",\"\")  # adapter fills from filename if empty\n","#         convert_hadith_dir(s[\"in\"], s[\"out\"], fixed, collection_name_mapper=_mapper)\n","#     else:\n","#         print(\" ! Unknown kind:\", kind)\n","#         continue\n","#     produced.append(s[\"out\"])\n","\n","# # Write MANIFEST\n","# manifest = {\n","#     \"time\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n","#     \"normalized_files\": [os.path.relpath(p, ROOT) for p in produced]\n","# }\n","# with open(os.path.join(NORM_DIR, \"MANIFEST.json\"), \"w\", encoding=\"utf-8\") as f:\n","#     json.dump(manifest, f, ensure_ascii=False, indent=2)\n","\n","# print(\"\\nWrote MANIFEST:\", os.path.relpath(os.path.join(NORM_DIR, \"MANIFEST.json\"), ROOT))\n"]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","import os\n","\n","# Re-define ROOT, RAW_ROOT, and NORM_DIR as Path objects\n","ROOT = Path(os.environ.get(\"FACTR_ROOT\", \"/content/drive/MyDrive/FATCR\"))\n","DATA_DIR = ROOT / \"data\"\n","RAW_ROOT = DATA_DIR / \"raw\" / \"kb\"\n","NORM_DIR = RAW_ROOT / \"_normalized\"\n","os.makedirs(NORM_DIR, exist_ok=True)\n","\n","manifest_path = NORM_DIR / \"MANIFEST.json\"\n","\n","def rel_from_root(filename: str) -> str:\n","    \"\"\"Return path to NORM_DIR/filename relative to the repo ROOT.\"\"\"\n","    p = NORM_DIR / filename # This now works because NORM_DIR is a Path object\n","    if not p.exists():\n","        raise FileNotFoundError(p)\n","    return str(p.relative_to(ROOT))\n","\n","manifest = [\n","    # Qur'an – EN + AR\n","    {\n","        \"name\": \"quran_en\",\n","        \"path\": rel_from_root(\"quran_en.jsonl\"),\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"scripture\",\n","        \"collection\": \"Quran\",\n","        \"lang\": \"en\",\n","        \"source\": \"Quran (EN: semarketir/quranjson)\",\n","        \"notes\": \"English Qur'an translation from semarketir/quranjson.\",\n","    },\n","    {\n","        \"name\": \"quran_ar\",\n","        \"path\": rel_from_root(\"quran_ar.jsonl\"),\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"scripture\",\n","        \"collection\": \"Quran\",\n","        \"lang\": \"ar\",\n","        \"source\": \"Quran (Arabic text)\",\n","        \"notes\": \"Arabic Qur'an text aligned verse-by-verse with quran_en.\",\n","    },\n","\n","    # Bible – WEB\n","    {\n","        \"name\": \"bible_web_en\",\n","        \"path\": rel_from_root(\"bible_web_en.jsonl\"),\n","        \"tradition\": \"Christianity\",\n","        \"genre\": \"scripture\",\n","        \"collection\": \"World English Bible\",\n","        \"lang\": \"en\",\n","        \"source\": \"World English Bible\",\n","        \"notes\": \"Public-domain World English Bible (whole OT+NT).\",\n","    },\n","\n","    # Hadith – 9 books EN\n","    {\n","        \"name\": \"hadith_9books_en\",\n","        \"path\": rel_from_root(\"hadith_9books_en.jsonl\"),\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"hadith\",\n","        \"collection\": \"Nine Books (AhmedBaset/hadith-json)\",\n","        \"lang\": \"en\",\n","        \"source\": \"AhmedBaset/hadith-json (the_9_books)\",\n","        \"notes\": \"Nine Sunni hadith collections in English translation.\",\n","    },\n","\n","    # Tafsir – Ibn Kathir EN + Qurtubi AR\n","    {\n","        \"name\": \"tafsir_ibn_kathir_en\",\n","        \"path\": rel_from_root(\"tafsir_ibn_kathir_en.jsonl\"),\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"tafsir\",\n","        \"collection\": \"Tafsīr Ibn Kathīr\",\n","        \"lang\": \"en\",\n","        \"source\": \"spa5k/tafsir_api (local mirror)\",\n","        \"notes\": \"English excerpts from Tafsīr Ibn Kathīr.\",\n","    },\n","    {\n","        \"name\": \"tafsir_al_qurtubi_ar\",\n","        \"path\": rel_from_root(\"tafsir_al_qurtubi_ar.jsonl\"),\n","        \"tradition\": \"Islam\",\n","        \"genre\": \"tafsir\",\n","        \"collection\": \"Tafsīr al-Qurtubī\",\n","        \"lang\": \"ar\",\n","        \"source\": \"spa5k/tafsir_api (local mirror)\",\n","        \"notes\": \"Arabic excerpts from Tafsīr al-Qurtubī.\",\n","    },\n","\n","    # Patristic commentaries\n","    {\n","        \"name\": \"christian_commentaries_patristic\",\n","        \"path\": rel_from_root(\"christian_commentaries_patristic.jsonl\"),\n","        \"tradition\": \"Christianity\",\n","        \"genre\": \"commentary\",\n","        \"collection\": \"Patristic Commentaries\",\n","        \"lang\": \"en\",\n","        \"source\": \"HistoricalChristianFaith-CommentariesDatabase\",\n","        \"notes\": \"Irenaeus, Origen, John Chrysostom, Augustine of Hippo (verse-indexed excerpts).\",\n","    },\n","\n","    # Christian creeds\n","    {\n","        \"name\": \"christian_creeds\",\n","        \"path\": rel_from_root(\"christian_creeds.jsonl\"),\n","        \"tradition\": \"Christianity\",\n","        \"genre\": \"creed\",\n","        \"collection\": \"Ecumenical Creeds\",\n","        \"lang\": \"en\",\n","        \"source\": \"christian-creeds-kb\",\n","        \"notes\": \"Apostles', Nicene (381), Athanasian, and Chalcedon creeds (paragraph-level).\",\n","    },\n","]\n","\n","manifest_path.write_text(\n","    json.dumps(manifest, indent=2, ensure_ascii=False), encoding=\"utf-8\"\n",")\n","\n","print(f\"[MANIFEST] Wrote {len(manifest)} entries to {manifest_path}\")\n","for m in manifest:\n","    print(\" -\", m[\"name\"], \"→\", m[\"path\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfnXgabg1IZ9","executionInfo":{"status":"ok","timestamp":1763417173738,"user_tz":0,"elapsed":341,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"a0793372-9da5-4208-f6ce-f45ce51f047b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[MANIFEST] Wrote 8 entries to /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/MANIFEST.json\n"," - quran_en → data/raw/kb/_normalized/quran_en.jsonl\n"," - quran_ar → data/raw/kb/_normalized/quran_ar.jsonl\n"," - bible_web_en → data/raw/kb/_normalized/bible_web_en.jsonl\n"," - hadith_9books_en → data/raw/kb/_normalized/hadith_9books_en.jsonl\n"," - tafsir_ibn_kathir_en → data/raw/kb/_normalized/tafsir_ibn_kathir_en.jsonl\n"," - tafsir_al_qurtubi_ar → data/raw/kb/_normalized/tafsir_al_qurtubi_ar.jsonl\n"," - christian_commentaries_patristic → data/raw/kb/_normalized/christian_commentaries_patristic.jsonl\n"," - christian_creeds → data/raw/kb/_normalized/christian_creeds.jsonl\n"]}]},{"cell_type":"markdown","source":["## check after the manifest cell (optional but helpful)"],"metadata":{"id":"ipwauA1O1Wxh"}},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","\n","manifest_path = NORM_DIR / \"MANIFEST.json\"\n","manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n","\n","print(\"Manifest entries:\")\n","for m in manifest:\n","    full_path = ROOT / m[\"path\"]\n","    exists = full_path.exists()\n","    print(f\" - {m['name']:30s} lang={m.get('lang')} genre={m.get('genre')}  exists={exists}\")\n","    if not exists:\n","        print(\"   !!! Missing file:\", full_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26m1nk_p1ZK4","executionInfo":{"status":"ok","timestamp":1763417243846,"user_tz":0,"elapsed":24,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"beca201f-d57e-4082-b5ad-977fdac18f1b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Manifest entries:\n"," - quran_en                       lang=en genre=scripture  exists=True\n"," - quran_ar                       lang=ar genre=scripture  exists=True\n"," - bible_web_en                   lang=en genre=scripture  exists=True\n"," - hadith_9books_en               lang=en genre=hadith  exists=True\n"," - tafsir_ibn_kathir_en           lang=en genre=tafsir  exists=True\n"," - tafsir_al_qurtubi_ar           lang=ar genre=tafsir  exists=True\n"," - christian_commentaries_patristic lang=en genre=commentary  exists=True\n"," - christian_creeds               lang=en genre=creed  exists=True\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fth3t1JRCDmr"},"source":["## Cell 9a — Mirror the tafsir repo locally (run once, or when you want to refresh)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1375809,"status":"ok","timestamp":1760730507974,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"2nKyxzYXCGpI","outputId":"5c19792f-fe0c-4d42-b076-8e5e55be2e51"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors\n","Cloning into 'tafsir_api'...\n","remote: Enumerating objects: 141876, done.\u001b[K\n","remote: Counting objects: 100% (141876/141876), done.\u001b[K\n","remote: Compressing objects: 100% (140443/140443), done.\u001b[K\n","remote: Total 141876 (delta 2337), reused 140656 (delta 1306), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (141876/141876), 196.58 MiB | 10.51 MiB/s, done.\n","Resolving deltas: 100% (2337/2337), done.\n","Updating files: 100% (140816/140816), done.\n"]}],"source":["# # Cell 9a — Clone/mirror spa5k/tafsir_api locally (run once or when you want to refresh)\n","# # This avoids flaky 403/404 issues from CDNs.\n","\n","# !mkdir -p \"/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors\"\n","# %cd \"/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors\"\n","\n","# # If you need a clean refresh, uncomment the next line:\n","# # !rm -rf tafsir_api\n","\n","# !git clone --depth=1 https://github.com/spa5k/tafsir_api.git\n","\n","# # Return to project root (optional)\n","# #%cd \"/content/drive/MyDrive/FATCR\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8128,"status":"ok","timestamp":1761924568602,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"Pnb9v5tdyMsT","outputId":"9bd58738-93f8-46c4-e3b5-5776c885a918"},"outputs":[{"name":"stdout","output_type":"stream","text":["+ git fetch --depth=1 origin main\n","⚠️ Mirror refresh failed (will still try to use existing copy): Command '['git', 'fetch', '--depth=1', 'origin', 'main']' returned non-zero exit status 128.\n","✅ Local tafsir mirror ready at: /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api\n"]}],"source":["# Cell 9a — Clone/refresh spa5k/tafsir_api locally (idempotent)\n","\n","import os, subprocess, shlex\n","\n","ROOT = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT = f\"{ROOT}/data/raw/kb\"\n","MIR_DIR = f\"{RAW_ROOT}/_mirrors\"\n","REPO_DIR = f\"{MIR_DIR}/tafsir_api\"\n","\n","os.makedirs(MIR_DIR, exist_ok=True)\n","\n","def sh(cmd, cwd=None):\n","    print(\"+\", cmd)\n","    return subprocess.run(shlex.split(cmd), cwd=cwd, check=True)\n","\n","if not os.path.isdir(REPO_DIR):\n","    # fresh sparse clone, shallow\n","    sh(\"git clone --depth=1 https://github.com/spa5k/tafsir_api.git\", cwd=MIR_DIR)\n","    # enable sparse checkout (cone)\n","    sh(\"git sparse-checkout init --cone\", cwd=REPO_DIR)\n","    # only keep `tafsir/*` (saves space & makes ls faster)\n","    sh(\"git sparse-checkout set tafsir\", cwd=REPO_DIR)\n","else:\n","    # refresh existing mirror\n","    try:\n","        sh(\"git fetch --depth=1 origin main\", cwd=REPO_DIR)\n","        sh(\"git checkout main\", cwd=REPO_DIR)\n","        sh(\"git pull --ff-only\", cwd=REPO_DIR)\n","        # re-apply sparse in case upstream changed tree structure\n","        sh(\"git sparse-checkout init --cone\", cwd=REPO_DIR)\n","        sh(\"git sparse-checkout set tafsir\", cwd=REPO_DIR)\n","    except Exception as e:\n","        print(\"⚠️ Mirror refresh failed (will still try to use existing copy):\", e)\n","\n","print(\"✅ Local tafsir mirror ready at:\", REPO_DIR)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288394,"status":"ok","timestamp":1761924882684,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"WEd5qgPgG3v6","outputId":"7fe4ef01-37e7-4604-81e7-3068aef486fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["770M\t/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/1\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/10\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/100\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/101\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/102\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/103\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/104\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/105\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/106\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/107\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/108\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/109\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/11\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/110\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/111\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/112\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/113\n","/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi/114\n"]}],"source":["# Sanity check size & presence\n","!du -sh \"/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api\"\n","!find \"/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir\" -maxdepth 2 -type d | head -n 20\n"]},{"cell_type":"markdown","metadata":{"id":"D9-CHnqUCKlL"},"source":["## Cell 9b — Tell the notebook to use the local mirror + discover real edition folder names"]},{"cell_type":"markdown","metadata":{"id":"quP45NKDg61B"},"source":["Ckeck the local mirror"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1760731381012,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":-60},"id":"6WwFdfnjhGDJ","outputId":"85348fbb-f78b-410a-cbd5-008c18a14713"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api\n","en-al-jalalayn\n","en-al-qushairi-tafsir\n","en-asbab-al-nuzul-by-al-wahidi\n","en-kashani-tafsir\n","en-kashf-al-asrar-tafsir\n","en-tafisr-ibn-kathir\n","en-tafsir-al-tustari\n","en-tafsir-ibn-abbas\n","en-tafsir-maarif-ul-quran\n","en-tazkirul-quran\n"]}],"source":["# # inside the local mirror\n","# %cd /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api\n","# !git ls-tree -r --name-only HEAD | grep '^tafsir/en-' | cut -d/ -f2 | sort -u\n"]},{"cell_type":"markdown","metadata":{"id":"emQpNDowufmz"},"source":["## Cell 10 — Tafsīr — run selected editions (optional)"]},{"cell_type":"code","source":["# Cell 10 — Tafsīr (local mirror → normalized JSONL)\n","# Purpose: Convert selected editions in local mirror to a unified JSONL schema.\n","\n","import os, json, time, re, itertools, glob\n","from pathlib import Path\n","\n","# ---- CONFIG ----\n","ROOT = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT = f\"{ROOT}/data/raw/kb\"\n","NORM_DIR = f\"{RAW_ROOT}/_normalized\"\n","LOCAL_TAFSIR_DIR = f\"{RAW_ROOT}/_mirrors/tafsir_api/tafsir\"\n","os.makedirs(NORM_DIR, exist_ok=True)\n","\n","def _clean(s: str) -> str:\n","    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n","\n","def quran_key(ch:int, v:int) -> str:\n","    return f\"quran-{int(ch)}-{int(v)}\"\n","\n","# Optional: read ayah counts from your normalized English Qur'an (if present)\n","QURAN_INDEX = {}\n","try:\n","    src = f\"{RAW_ROOT}/_normalized/quran_en.jsonl\"\n","    if os.path.exists(src):\n","        counts = {}\n","        with open(src, \"r\", encoding=\"utf-8\") as f:\n","            for line in f:\n","                try:\n","                    r = json.loads(line)\n","                    s = int(r.get(\"chapter\", 0)); v = int(r.get(\"verse\", 0))\n","                    if s > 0 and v > 0:\n","                        counts[s] = max(counts.get(s, 0), v)\n","                except:\n","                    pass\n","        QURAN_INDEX = counts\n","except:\n","    pass\n","\n","def ayah_count(s):\n","    return QURAN_INDEX.get(s)\n","\n","def write_jsonl(out_path: str, rows: list):\n","    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","        for r in rows:\n","            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","    print(f\"✅ Wrote {out_path} | rows: {len(rows)}\")\n","\n","# ------------------------------\n","# Map edition → human-readable collection name (canonical keys)\n","COLLECTION_NAME = {\n","    # EN\n","    \"en-tafsir-ibn-kathir\": \"Tafsir Ibn Kathīr (EN)\",\n","    \"en-al-jalalayn\": \"Tafsir al-Jalalayn (EN)\",\n","    \"en-asbab-al-nuzul-by-al-wahidi\": \"Asbāb al-Nuzūl (al-Wāḥidī, EN)\",\n","    \"en-tafsir-al-tustari\": \"Tafsir al-Tustarī (EN)\",\n","    \"en-tafsir-ibn-abbas\": \"Tafsir Ibn ʿAbbās (EN)\",\n","    \"en-kashani-tafsir\": \"Tafsir al-Kāshānī (EN)\",\n","    \"en-kashf-al-asrar-tafsir\": \"Kashf al-Asrār (EN)\",\n","    \"en-tafsir-maarif-ul-quran\": \"Maʿārif al-Qurʾān (EN)\",\n","    \"en-tazkirul-quran\": \"Tazkirul Qurʾān (EN)\",\n","    \"en-al-qushairi-tafsir\": \"Qushayrī (EN)\",\n","    # AR\n","    \"ar-tafsir-ibn-kathir\": \"Tafsir Ibn Kathīr (AR)\",\n","    \"ar-tafsir-al-qurtubi\": \"Tafsir al-Qurṭubī (AR)\",\n","    \"ar-tafsir-al-tabari\": \"Tafsir al-Ṭabarī (AR)\",\n","    \"ar-tafseer-al-saddi\": \"Tafsir al-Suddī (AR)\",\n","    \"ar-tafseer-tanwir-al-miqbas\": \"Tanwīr al-Miqbās (AR)\",\n","    \"ar-tafsir-al-baghawi\": \"Tafsir al-Baghawī (AR)\",\n","    \"ar-tafsir-al-wasit\": \"Tafsir al-Wasīṭ (AR)\",\n","    \"ar-tafsir-muyassar\": \"Tafsir al-Muyassar (AR)\",\n","}\n","\n","# Local folder aliases (handle mis-spellings or legacy names on disk)\n","EDITION_ALIASES = {\n","    \"ar-tafsir-al-qurtubi\": \"ar-tafseer-al-qurtubi\",  # canonical -> on-disk alias\n","    \"en-tafsir-ibn-kathir\": \"en-tafisr-ibn-kathir\",   # if your mirror has the 'tafisr' typo\n","    # add more if you bump into others\n","}\n","\n","def _resolve_local_dir(base: Path, edition: str) -> Path:\n","    \"\"\"Return the directory to read for this edition, trying alias if needed.\"\"\"\n","    p = base / edition\n","    if p.is_dir():\n","        return p\n","    alias = EDITION_ALIASES.get(edition)\n","    if alias:\n","        q = base / alias\n","        if q.is_dir():\n","            print(f\"🔎 Using local alias for {edition} -> {alias}\")\n","            return q\n","    return p  # caller will warn if missing\n","\n","# ------------------------------\n","# Layout helpers (per-ayah / per-surah detection)\n","\n","def iter_tafsir_ayah_files(base: Path, edition: str):\n","    ed = _resolve_local_dir(base, edition)\n","    if not ed.is_dir():\n","        return\n","    for s_dir in ed.iterdir():\n","        if not s_dir.is_dir():\n","            continue\n","        try:\n","            s = int(s_dir.name)\n","        except:\n","            continue\n","        for f in s_dir.iterdir():\n","            if f.suffix.lower() == \".json\":\n","                try:\n","                    v = int(f.stem)\n","                except:\n","                    continue\n","                yield s, v, f\n","\n","def iter_tafsir_surah_files(base: Path, edition: str):\n","    ed = _resolve_local_dir(base, edition)\n","    if not ed.is_dir():\n","        return\n","    for f in ed.iterdir():\n","        if f.suffix.lower() != \".json\":\n","            continue\n","        m = re.match(r\"^s?(\\d+)\\.json$\", f.name)\n","        if not m:\n","            continue\n","        s = int(m.group(1))\n","        yield s, f\n","\n","def normalize_record(base_meta: dict, edition: str, lang: str, sura: int, ayah: int, text: str):\n","    coll = COLLECTION_NAME.get(edition, edition)\n","    return {\n","        **base_meta,\n","        \"collection\": coll,\n","        \"lang\": lang,\n","        \"book\": \"Qur'an\",\n","        \"chapter\": int(sura),\n","        \"verse\": int(ayah),\n","        \"number\": None,\n","        \"grade\": None,\n","        \"text\": _clean(text),\n","        \"ref\": f\"Qur'an {sura}:{ayah}\",\n","        \"group_key\": quran_key(sura, ayah),\n","    }\n","\n","def convert_tafsir_local(edition: str, out_path: str, fixed_meta: dict, sleep=0.0):\n","    base = Path(LOCAL_TAFSIR_DIR)\n","    ed_dir = _resolve_local_dir(base, edition)\n","    lang = \"en\" if edition.startswith(\"en-\") else \"ar\"\n","    rows = []\n","    wrote = 0\n","\n","    if not ed_dir.is_dir():\n","        print(f\"⚠️ Edition folder missing locally: {edition}\")\n","        write_jsonl(out_path, rows)\n","        return\n","\n","    found_any = False\n","\n","    # 1) per-ayah\n","    for s, v, p in iter_tafsir_ayah_files(base, edition):\n","        found_any = True\n","        if ayah_count(s) is not None and (v < 1 or v > ayah_count(s)):\n","            continue\n","        try:\n","            obj = json.loads(p.read_text(encoding=\"utf-8\"))\n","        except Exception as e:\n","            print(f\"{edition} s{s} v{v}: JSON parse error: {e}\")\n","            continue\n","        txt = obj.get(\"text\") or obj.get(\"tafsir\") or obj.get(\"Tafsir\") or obj.get(\"content\") or \"\"\n","        if txt:\n","            rows.append(normalize_record(fixed_meta, edition, lang, s, v, txt))\n","            wrote += 1\n","        if sleep > 0: time.sleep(sleep)\n","\n","    # 2) per-surah (fallback)\n","    if not wrote:\n","        for s, f in iter_tafsir_surah_files(base, edition):\n","            found_any = True\n","            try:\n","                obj = json.loads(f.read_text(encoding=\"utf-8\"))\n","            except Exception as e:\n","                print(f\"{edition} s{s}: JSON parse error: {e}\")\n","                continue\n","            if isinstance(obj, dict):\n","                for vk, vv in obj.items():\n","                    try:\n","                        v = int(vk)\n","                    except:\n","                        continue\n","                    if ayah_count(s) is not None and (v < 1 or v > ayah_count(s)):\n","                        continue\n","                    if isinstance(vv, str):\n","                        txt = vv\n","                    elif isinstance(vv, dict):\n","                        txt = vv.get(\"text\") or vv.get(\"tafsir\") or vv.get(\"content\") or \"\"\n","                    else:\n","                        txt = str(vv)\n","                    if txt:\n","                        rows.append(normalize_record(fixed_meta, edition, lang, s, v, txt))\n","                        wrote += 1\n","\n","    if not found_any:\n","        print(f\"⚠️ {edition}: no working layout detected (folder exists but no JSON matched)\")\n","    write_jsonl(out_path, rows)\n","\n","# ------------------------------\n","# ✅ Default pack only (fast & reliable)\n","# EN: Ibn Kathīr, Jalālayn, Asbāb al-Nuzūl\n","# AR: Ṭabarī, Qurṭubī, Ibn Kathīr, Muyassar\n","editions_to_run = [\n","    # # EN\n","    # \"en-tafsir-ibn-kathir\",\n","    # \"en-al-jalalayn\",\n","    # \"en-asbab-al-nuzul-by-al-wahidi\",\n","    # # AR\n","    # \"ar-tafsir-al-tabari\",\n","      \"ar-tafsir-al-qurtubi\",\n","    # \"ar-tafsir-ibn-kathir\",\n","    # \"ar-tafsir-muyassar\",\n","]\n","\n","# Output filename helper (nice, readable)\n","def out_name_for(edition: str) -> str:\n","    # e.g. \"en-tafsir-ibn-kathir\" -> \"tafsir_ibn_kathir_en.jsonl\"\n","    lang = \"en\" if edition.startswith(\"en-\") else \"ar\"\n","    stem = edition.split(\"-\", 1)[1]  # drop \"en-\" / \"ar-\"\n","    stem = stem.replace(\"-\", \"_\")\n","    return f\"tafsir_{stem}_{lang}.jsonl\"\n","\n","# Fixed meta applied to every record (collection set per edition)\n","fixed_tafsir_meta = {\n","    \"tradition\": \"Islam\",\n","    \"genre\": \"tafsir\",\n","    \"source\": \"spa5k/tafsir_api\",\n","    \"collection\": \"\",  # overridden dynamically in normalize_record\n","    \"lang\": \"en\",      # overridden per edition in normalize_record\n","}\n","\n","# ---- Run them\n","for ed in editions_to_run:\n","    out_path = os.path.join(NORM_DIR, out_name_for(ed))\n","    print(f\"→ Converting {ed} → {os.path.basename(out_path)}\")\n","    convert_tafsir_local(ed, out_path, fixed_tafsir_meta, sleep=0.0)\n","\n","# ---- Quick preview (sanity)\n","for p in glob.glob(f\"{NORM_DIR}/tafsir_*_*.jsonl\"):\n","    try:\n","        with open(p, \"r\", encoding=\"utf-8\") as f:\n","            first = next(f).strip()\n","        print(\"Preview:\", os.path.basename(p), \"→\", first[:140], \"…\")\n","    except StopIteration:\n","        print(\"Preview:\", os.path.basename(p), \"→ (empty)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ck19SmkOly78","executionInfo":{"status":"ok","timestamp":1762290697950,"user_tz":0,"elapsed":1957872,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"8b6c1c7c-c323-462e-9df4-152505bd29d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["→ Converting ar-tafsir-al-qurtubi → tafsir_tafsir_al_qurtubi_ar.jsonl\n","🔎 Using local alias for ar-tafsir-al-qurtubi -> ar-tafseer-al-qurtubi\n","🔎 Using local alias for ar-tafsir-al-qurtubi -> ar-tafseer-al-qurtubi\n","✅ Wrote /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/tafsir_tafsir_al_qurtubi_ar.jsonl | rows: 6236\n","Preview: tafsir_ibn_kathir_en.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api (local mirror)\", \"collection\": \"Tafsir Ibn Kathīr (EN)\", \"lang\": \"en\", …\n","Preview: tafsir_ibn_kathir_ar.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api (local mirror)\", \"collection\": \"Tafsir Ibn Kathīr (AR)\", \"lang\": \"ar\", …\n","Preview: tafsir_tafsir_ibn_kathir_en.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir Ibn Kathīr (EN)\", \"lang\": \"en\", \"book\": \"Qur'a …\n","Preview: tafsir_al_jalalayn_en.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Jalalayn (EN)\", \"lang\": \"en\", \"book\": \"Qur' …\n","Preview: tafsir_asbab_al_nuzul_by_al_wahidi_en.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Asbāb al-Nuzūl (al-Wāḥidī, EN)\", \"lang\": \"en\", \"book\" …\n","Preview: tafsir_tafsir_al_tabari_ar.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Ṭabarī (AR)\", \"lang\": \"ar\", \"book\": \"Qur'an …\n","Preview: tafsir_tafsir_al_qurtubi_ar.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Qurṭubī (AR)\", \"lang\": \"ar\", \"book\": \"Qur'a …\n","Preview: tafsir_tafsir_ibn_kathir_ar.jsonl → {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir Ibn Kathīr (AR)\", \"lang\": \"ar\", \"book\": \"Qur'a …\n"]}]},{"cell_type":"markdown","metadata":{"id":"m6WQbZw1YAEq"},"source":["sanity check"]},{"cell_type":"code","source":["# sanity check (alias-aware)\n","from pathlib import Path\n","\n","ROOT = \"/content/drive/MyDrive/FATCR\"\n","RAW_ROOT = f\"{ROOT}/data/raw/kb\"\n","LOCAL_TAFSIR_DIR = f\"{RAW_ROOT}/_mirrors/tafsir_api/tafsir\"\n","\n","# keep in sync with Cell 10\n","EDITION_ALIASES = {\n","    \"ar-tafsir-al-qurtubi\": \"ar-tafseer-al-qurtubi\",\n","    \"en-tafsir-ibn-kathir\": \"en-tafisr-ibn-kathir\",\n","}\n","\n","def resolve_dir(ed: str) -> Path:\n","    p = Path(LOCAL_TAFSIR_DIR) / ed\n","    if p.is_dir():\n","        return p\n","    alias = EDITION_ALIASES.get(ed)\n","    q = Path(LOCAL_TAFSIR_DIR) / alias if alias else None\n","    return q if (q and q.is_dir()) else p\n","\n","editions = [\"en-al-jalalayn\", \"en-tafsir-ibn-kathir\", \"ar-tafsir-ibn-kathir\", \"ar-tafsir-al-qurtubi\"]\n","for ed in editions:\n","    p = resolve_dir(ed)\n","    cnt = sum(1 for _ in p.rglob(\"*.json\")) if p.is_dir() else 0\n","    print(f\"{ed:>22} | exists: {str(p.is_dir()):5} | files: {cnt:4} | path: {p}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY92zMXw4Yn7","executionInfo":{"status":"ok","timestamp":1762461341948,"user_tz":0,"elapsed":17036,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"6ab7707e-d3cb-4887-e30b-217fccb17eb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        en-al-jalalayn | exists: True  | files: 6350 | path: /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/en-al-jalalayn\n","  en-tafsir-ibn-kathir | exists: True  | files: 6350 | path: /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/en-tafsir-ibn-kathir\n","  ar-tafsir-ibn-kathir | exists: True  | files: 6350 | path: /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafsir-ibn-kathir\n","  ar-tafsir-al-qurtubi | exists: True  | files: 6350 | path: /content/drive/MyDrive/FATCR/data/raw/kb/_mirrors/tafsir_api/tafsir/ar-tafseer-al-qurtubi\n"]}]},{"cell_type":"markdown","source":["file cleanup"],"metadata":{"id":"BItP3WF68FWk"}},{"cell_type":"code","source":["# keep the short names, remove doubles with \"tafsir_tafsir_\"\n","cd \"/content/drive/MyDrive/FATCR/data/raw/kb/_normalized\"\n","rm -f tafsir_tafsir_*.jsonl\n"],"metadata":{"id":"GliTutcS7BI1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["normalised sanity check"],"metadata":{"id":"w7l45dp28HhT"}},{"cell_type":"code","source":["import os, glob, json, itertools\n","NORM = \"/content/drive/MyDrive/FATCR/data/raw/kb/_normalized\"\n","\n","for p in sorted(glob.glob(f\"{NORM}/*.jsonl\")):\n","    size = os.path.getsize(p)\n","    with open(p, \"r\", encoding=\"utf-8\") as f:\n","        head = next(itertools.islice(f, 1), \"\").strip()\n","    print(os.path.basename(p), \"| bytes:\", size, \"| sample:\", head[:140], \"…\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSj9EF3u7pE4","executionInfo":{"status":"ok","timestamp":1762463405378,"user_tz":0,"elapsed":720,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"0cbaabd3-1922-4de2-cef5-321bc18bfe71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bible_kjv_en.jsonl | bytes: 15248000 | sample: {\"tradition\": \"Christianity\", \"genre\": \"scripture\", \"source\": \"KJV (aruljohn/Bible-kjv)\", \"collection\": \"Bible\", \"lang\": \"en\", \"book\": \"1 Ch …\n","bible_web_en.jsonl | bytes: 0 | sample:  …\n","hadith_9books_ar.jsonl | bytes: 52501348 | sample: {\"tradition\": \"Islam\", \"genre\": \"hadith\", \"collection\": \"Nine Books\", \"source\": \"hadith-json\", \"lang\": \"ar\", \"book\": \"Abudawud\", \"chapter\":  …\n","hadith_9books_en.jsonl | bytes: 0 | sample:  …\n","quran_ar.jsonl | bytes: 2923183 | sample: {\"tradition\": \"Islam\", \"genre\": \"scripture\", \"collection\": \"Quran\", \"source\": \"Quran (AR)\", \"lang\": \"ar\", \"book\": \"Al-Fatiha\", \"chapter\": 1, …\n","quran_en.jsonl | bytes: 2463646 | sample: {\"tradition\": \"Islam\", \"genre\": \"scripture\", \"collection\": \"Quran\", \"source\": \"Quran (EN: semarketir/quranjson)\", \"lang\": \"en\", \"book\": \"Al- …\n","tafsir_al_jalalayn_en.jsonl | bytes: 3824124 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Jalalayn (EN)\", \"lang\": \"en\", \"book\": \"Qur' …\n","tafsir_al_qurtubi_ar.jsonl | bytes: 21367582 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Qurṭubī (AR)\", \"lang\": \"ar\", \"book\": \"Qur'a …\n","tafsir_al_tabari_ar.jsonl | bytes: 36483588 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Tafsir al-Ṭabarī (AR)\", \"lang\": \"ar\", \"book\": \"Qur'an …\n","tafsir_asbab_al_nuzul_by_al_wahidi_en.jsonl | bytes: 2197716 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api\", \"collection\": \"Asbāb al-Nuzūl (al-Wāḥidī, EN)\", \"lang\": \"en\", \"book\" …\n","tafsir_ibn_kathir_ar.jsonl | bytes: 16146097 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api (local mirror)\", \"collection\": \"Tafsir Ibn Kathīr (AR)\", \"lang\": \"ar\", …\n","tafsir_ibn_kathir_en.jsonl | bytes: 41564813 | sample: {\"tradition\": \"Islam\", \"genre\": \"tafsir\", \"source\": \"spa5k/tafsir_api (local mirror)\", \"collection\": \"Tafsir Ibn Kathīr (EN)\", \"lang\": \"en\", …\n"]}]},{"cell_type":"markdown","source":["fix lost file bible web normalised"],"metadata":{"id":"-bxY3W0PAluc"}},{"cell_type":"code","source":["def safe_write_jsonl(out_path: str, rows: list):\n","    \"\"\"Never overwrite with 0 rows. If rows==0 and an older file exists, keep the old file.\"\"\"\n","    import os, json, tempfile, shutil\n","    if not rows:\n","        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:\n","            print(f\"⚠️  Skipping write of 0 rows to {out_path} (kept existing non-empty file).\")\n","            return\n","        else:\n","            print(f\"⚠️  Not writing {out_path}: 0 rows.\")\n","            return\n","    tmp = out_path + \".tmp\"\n","    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n","        for r in rows:\n","            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n","    shutil.move(tmp, out_path)\n","    print(f\"✅ Wrote {out_path} | rows: {len(rows)}\")\n"],"metadata":{"id":"K_XH5rkAA28x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Rebuild Bible WEB EN from TehShrike/world-english-bible ---\n","RAW_ROOT = \"/content/drive/MyDrive/FATCR/data/raw/kb\"\n","NORM_DIR = f\"{RAW_ROOT}/_normalized\"\n","WEB_ROOT = f\"{RAW_ROOT}/Christianity/world-english-bible\"  # adjust if needed\n","\n","import os, glob, json\n","rows = []\n","\n","# many WEB repos are one-file-per-book under e.g. translations/en/web/BOOK.json or similar\n","cands = glob.glob(os.path.join(WEB_ROOT, \"**\", \"*.json\"), recursive=True)\n","\n","def friendly_book(name):\n","    # crude clean-up for filenames into book names\n","    import re\n","    b = os.path.splitext(os.path.basename(name))[0]\n","    b = b.replace(\"_\", \" \").replace(\"-\", \" \").title()\n","    return b\n","\n","for fp in cands:\n","    try:\n","        with open(fp, \"r\", encoding=\"utf-8\") as f:\n","            obj = json.load(f)\n","    except Exception:\n","        continue\n","\n","    # accept common shapes:\n","    # 1) {\"book\":\"Genesis\",\"chapters\":{\"1\":{\"1\":\"In the beginning...\", ...}, ...}}\n","    # 2) {\"1\":{\"1\":\"...\",\"2\":\"...\"}, \"2\":{...}} with filename as book\n","    if isinstance(obj, dict) and \"chapters\" in obj and \"book\" in obj:\n","        book = obj[\"book\"]\n","        chapters = obj[\"chapters\"]\n","    elif isinstance(obj, dict) and all(k.isdigit() for k in obj.keys()):\n","        book = friendly_book(fp)\n","        chapters = obj\n","    else:\n","        continue\n","\n","    for ch_s, verses in chapters.items():\n","        try: ch = int(ch_s)\n","        except: continue\n","        if not isinstance(verses, dict): continue\n","        for v_s, text in verses.items():\n","            try: v = int(v_s)\n","            except: continue\n","            t = str(text).strip()\n","            if not t: continue\n","            rows.append({\n","                \"tradition\":\"Christianity\",\"genre\":\"scripture\",\"source\":\"WEB (TehShrike/world-english-bible)\",\n","                \"collection\":\"Bible\",\"lang\":\"en\",\"book\":book,\n","                \"chapter\":ch,\"verse\":v,\"number\":None,\"grade\":None,\n","                \"text\":t,\"ref\":f\"{book} {ch}:{v}\",\"group_key\":f\"{book}-{ch}-{v}\".lower().replace(\" \",\"_\")\n","            })\n","\n","safe_write_jsonl(os.path.join(NORM_DIR, \"bible_web_en.jsonl\"), rows)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyWaAKGHApwG","executionInfo":{"status":"ok","timestamp":1762465179248,"user_tz":0,"elapsed":49,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"}},"outputId":"544c12e3-faed-4376-c350-b5fafcfd039a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["⚠️  Not writing /content/drive/MyDrive/FATCR/data/raw/kb/_normalized/bible_web_en.jsonl: 0 rows.\n"]}]},{"cell_type":"markdown","metadata":{"id":"3teU3IPfoC3C"},"source":[]},{"cell_type":"markdown","metadata":{"id":"zxIsVnoIuj2L"},"source":["## Cell 11 — 1) Quick slice (see progress fast)\n","\n","Run this in Cell 10 after the function definitions. It writes tiny “slice” JSONLs so you see logs immediately."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867,"status":"ok","timestamp":1762118007829,"user":{"displayName":"Luca Viscomi","userId":"11057007974013554352"},"user_tz":0},"id":"A9gR83oMaunp","outputId":"b354f281-9c43-4126-befe-2f3fa8cbf287"},"outputs":[{"name":"stdout","output_type":"stream","text":["tafsir_ibn_kathir_en.jsonl size: 41564813\n","  Tafsir Ibn Kathīr (EN) en Qur'an 1:1 → Introduction to Fatihah Which was revealed in Makk …\n","  Tafsir Ibn Kathīr (EN) en Qur'an 1:2 → The Meaning of Al-Hamd Abu Ja`far bin Jarir said,  …\n","  Tafsir Ibn Kathīr (EN) en Qur'an 1:3 → Allah said next, الرَّحْمَـنِ الرَّحِيمِ (Ar-Rahma …\n","\n","tafsir_al_jalalayn_en.jsonl size: 3917664\n","  Tafsir al-Jalalayn (EN) en Qur'an 1:1 → In the Name of God the Compassionate the Merciful …\n","  Tafsir al-Jalalayn (EN) en Qur'an 1:2 → In the Name of God the name of a thing is that by  …\n","  Tafsir al-Jalalayn (EN) en Qur'an 1:3 → The Compassionate the Merciful that is to say the  …\n","\n","tafsir_ibn_kathir_ar.jsonl size: 16146097\n","  Tafsir Ibn Kathīr (AR) ar Qur'an 1:1 → بسم الله الرحمن الرحيم سورة الفاتحة . يقال لها الف …\n","  Tafsir Ibn Kathīr (AR) ar Qur'an 1:2 → القراء السبعة على ضم الدال في قوله الحمد لله هو مب …\n","  Tafsir Ibn Kathīr (AR) ar Qur'an 1:3 → وقوله تعالى \"الرحمن الرحيم\" تقدم الكلام عليه في ال …\n","\n"]}],"source":["import json, itertools, os, glob\n","for p in glob.glob(f\"{NORM_DIR}/tafsir_*_*.jsonl\"):\n","    print(os.path.basename(p), \"size:\", os.path.getsize(p))\n","    with open(p, \"r\", encoding=\"utf-8\") as f:\n","        for i, line in enumerate(itertools.islice(f, 3)):\n","            r = json.loads(line)\n","            # must exist:\n","            assert {\"tradition\",\"genre\",\"collection\",\"source\",\"lang\",\"book\",\n","                    \"chapter\",\"verse\",\"text\",\"ref\",\"group_key\"} <= r.keys()\n","            print(\" \", r[\"collection\"], r[\"lang\"], r[\"ref\"], \"→\", r[\"text\"][:50], \"…\")\n","    print()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1fp3sZwVQSI_7bmGkl81s2XRWMHaKDXfl","timestamp":1763339035198}],"mount_file_id":"1Mcv5ZWzf8at3FVWW4a73J8FY0leLEAXx","authorship_tag":"ABX9TyOWWPyHl1J6negmEmdrnbcA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}